[{"title":"LC-77-组合","url":"/posts/e3e1c4a3/","content":"\n## 组合\n\nLeetCode题目链接：[77. 组合 - 力扣（LeetCode）](https://leetcode.cn/problems/combinations/description/)\n\n难度：{% label 中等 orange %}\n\n\n\n### 分析\n\n本题属于典型的递归回溯的题型，遍历给定数组，递归回溯组合出所有可能的组合即可\n\n>   注意：组合需要进行去重（组成元素相同但是顺序不同仍然属于同种组合）\n\n\n### 思路\n\n>   1.  遍历数组，加入临时结果集（注意去重的判断逻辑）\n>   2.  递归遍历数组\n>   3.  临时结果集回溯后继续遍历\n>\n>   递归结束条件：当临时结果集中的元素个数符合条件时即遍历结束，加入最终结果集并退出递归\n\n![LC-77-组合](LC-77-组合.assets/LC-77-组合.svg)\n\n{% hideToggle 点我展开,, %}\n\n{% tabs 代码 %}\n\n<!-- tab Golang -->\n\n```go\n\nfunc recurve(idx int, n int, k int, cur *[]int, res *[][]int) {\n\tif len(*cur) == k {\n\t\ttmp := make([]int, len(*cur))\n\t\tcopy(tmp, *cur)\n\t\t*res = append(*res, tmp)\n\t\treturn\n\t}\n\tfor i := idx + 1; i <= n; i++ {\n\t\t*cur = append(*cur, i)\n\t\trecurve(i, n, k, cur, res)\n\t\t*cur = (*cur)[:len(*cur)-1]\n\t}\n}\n\nfunc Combine(n int, k int) [][]int {\n\tres := make([][]int, 0)\n\tcur := make([]int, 0, k)\n\trecurve(0, n, k, &cur, &res)\n\treturn res\n}\n\n```\n\n<!-- endtab -->\n\n<!-- tab Java -->\n\n```java\n\n```\n\n<!-- endtab -->\n\n{% endtabs %}\n\n{% endhideToggle %}\n\n\n### 提交\n\n![1738571973971](LC-77-组合.assets/1738571973971.png)\n\n\n### 参考资料\n\n>    [代码随想录](https://programmercarl.com/0077.组合.html)\n\n","tags":["LeetCode","算法-回溯"],"categories":["算法","回溯"]},{"title":"跳表-实现篇（Redis）","url":"/posts/a381e6f7/","content":"\n## 简介\n\n本文基于 {% label Redis3.0 orange %} 版本的源码解读跳表的实现\n\n{% label Redis3.0 orange %} 源码链接：[redis/redis at 3.0.0](https://github.com/redis/redis/tree/3.0.0)\n\n建议阅读：\n - [跳表-原理篇 | Crayonの博客](/posts/2e152a56/)\n\n本文按照以下顺序进行：\n\n- [简介](#简介)\n- [背景知识](#背景知识)\n- [源码解读](#源码解读)\n\t- [结构体定义](#结构体定义)\n\t- [随机函数](#随机函数)\n\t- [查找](#查找)\n\t- [插入](#插入)\n\t- [删除](#删除)\n\n## 背景知识\n\n{% label Redis orange %} 内置了多种数据结构，其中`zset`（有序集合，英文名：sorted set）兼具集合的元素唯一性以及有序性（元素有序性）两个特性，被广泛用在日常业务需求的开发中\n\n`zset`由多个数据结构组合实现的，而跳表（`zskiplist`）就是实现有序性的关键数据结构，{% label Redis orange %} 就是通过跳表实现了`zset`结构的排序、根据排名的范围获取等操作\n\n{% label Redis orange %} 自己实现了跳表结构，为符合自身业务操作的需要增加了一些额外的字段以及操作，虽然和原始论文中的结构不太一样，但基本的操作逻辑都是相同的\n\n## 源码解读\n\n### 结构体定义\n\n#### zset\n\n```c\ntypedef struct zset {\n    dict *dict;\n    zskiplist *zsl;\n} zset;\n```\n\n实现`zset`的结构体定义，从结构体中的成员\n\n-   `dict`（`dict`）：实现集合的特性\n-   `zsl`（`zskiplist`）：实现有序（排序）的特性\n\n就可以知道`zset`就是通过组合`dict`（ {% label Redis orange %} 底层数据结构之一，即哈希表）、`zskiplist`（跳表）两种数据结构实现的\n\n\n\n#### zskiplist\n\n```c\ntypedef struct zskiplist {\n    struct zskiplistNode *header, *tail;\n    unsigned long length;\n    int level;\n} zskiplist;\n```\n\n-   `header`、`tail`：头尾指针\n-   `length`：元素个数\n-   `level`：当前跳表的最高层级\n\n\n\n#### zskiplistNode\n\n```c\n/* ZSETs use a specialized version of Skiplists */\ntypedef struct zskiplistNode {\n    robj *obj;\n    double score;\n    struct zskiplistNode *backward;\n    struct zskiplistLevel {\n        struct zskiplistNode *forward;\n        unsigned int span;\n    } level[];\n} zskiplistNode;\n```\n\n-   `rojb`：元素值\n-   `score`：分数，也就是跳表原始论文中的`key`\n-   <span style=\"font-weight: bold; color: red;\">`backward`：回退指针，主要用于反向遍历使用</span>\n-   **`level`**\n    -   `forward`：前进指针\n    -   <span style=\"font-weight: bold; color: red;\">`span` ：前进指针的跨度（用来记录对应的前进指针向前时跨过的元素个数，基于这个字段可以很方便的计算排位）</span>\n\n\n\n![1738048075089](跳表-实现篇（Redis）.assets/1738048075089.png)\n\n\n\n### 常量定义\n\n```c\n#define ZSKIPLIST_MAXLEVEL 32 /* Should be enough for 2^32 elements */\n#define ZSKIPLIST_P 0.25      /* Skiplist P = 1/4 */\n```\n\n{% label Redis orange %} 跳跃表的最高层级是32层，层晋升概率为*0.25*\n\n\n\n### 随机函数\n\n\n\n```c\n/* Returns a random level for the new skiplist node we are going to create.\n * The return value of this function is between 1 and ZSKIPLIST_MAXLEVEL\n * (both inclusive), with a powerlaw-alike distribution where higher\n * levels are less likely to be returned. */\nint zslRandomLevel(void) {\n    int level = 1;\n    while ((random()&0xFFFF) < (ZSKIPLIST_P * 0xFFFF))\n        level += 1;\n    return (level<ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;\n}\n```\n\n\n\n### 初始化\n\n```c\nzskiplist *zslCreate(void) {\n    int j;\n    zskiplist *zsl;\n\n    zsl = zmalloc(sizeof(*zsl));\n    zsl->level = 1;\n    zsl->length = 0;\n    zsl->header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL);\n    for (j = 0; j < ZSKIPLIST_MAXLEVEL; j++) {\n        zsl->header->level[j].forward = NULL;\n        zsl->header->level[j].span = 0;\n    }\n    zsl->header->backward = NULL;\n    zsl->tail = NULL;\n    return zsl;\n}\n```\n\n通过`zslCreate`可以创建一个`zskiplist`指针\n\n\n\n### 插入\n\n{% label Redis orange %} 跳表引入了一些额外的字段/机制以符合实际业务操作的需要\n\n函数声明\n\n```c\nzskiplistNode *zslInsert(zskiplist *zsl, double score, robj *obj);\n```\n\n\n\n相比于原始论文跳表的实现而言多了以下两块逻辑：\n\n1.  `span`（跨度）的维护\n2.  `backward`（回退指针）的维护\n\n除了维护上述的两块逻辑，可以发现实际上代码的实现和论文伪代码基本相同\n\n也是分为三个步骤\n\n1.  遍历跳表，找到符合的节点位置，并记录每一层需要更新的节点（插入的节点对应的前驱节点）（也就是记录`update`数组）\n\n    -   增加`rank`数组记录每层的排位\n\n    ```c\n        x = zsl->header;\n        for (i = zsl->level-1; i >= 0; i--) {\n            /* store rank that is crossed to reach the insert position */\n            // 初始化排位信息，如果是最顶层，则初始化为0，其他情况就是上一层的rank的值\n            // 比如从4层开始遍历，rank[3]=0，rank[2]=rank[3]\n            // 其实也很好理解，当前层的排位应该基于上一层的排位接着计数\n            rank[i] = i == (zsl->level-1) ? 0 : rank[i+1];\n            while (x->level[i].forward &&\n                (x->level[i].forward->score < score ||\n                    (x->level[i].forward->score == score &&\n                    compareStringObjects(x->level[i].forward->obj,obj) < 0))) {\n                // 这里的比较除了根据score比较之外，还增加了score相同情况下根据obj（值）比较的场景\n                // 更新排位，增加跨度就是新的排位\n                rank[i] += x->level[i].span;\n                x = x->level[i].forward;\n            }\n            // 记录节点（这个节点就是插入新节点的每一层对应的前驱节点）\n            // 如果说新节点的层级超过当前跳表的最高层级，这里是一定记录不到的，所以才有下面单独判断并处理的逻辑\n            // 保证代码逻辑统一也让代码更具可读性\n            update[i] = x;\n        }\n    ```\n\n2.  调用随机函数生成新节点层级，如果新节点层级超过当前跳表最高层，则更新`update`数组（超过最高层的前驱节点就是头节点，但是遍历过程不会记录，为了让后续能够用统一代码逻辑处理，单独进行判断并更新`update`数组，还有同步更新跳表`level`字段\n\n    -   增加`span`字段的初始化逻辑\n\n    ```c\n        // 调用随机函数生成level\n        level = zslRandomLevel();\n        // 如果新节点level超过当前跳表最高层\n        if (level > zsl->level) {\n            // 只处理超出当前跳表最高层的部分\n            // （剩下的都会在遍历过程中被记录，只有超过的部分不会被记录，所以单独在这里处理）\n            for (i = zsl->level; i < level; i++) {\n                // 排位初始化，和上面遍历过程的初始化逻辑相同\n                rank[i] = 0;\n                // 新节点层级是最高的，所以只会有一个元素，前驱节点只能是header\n                update[i] = zsl->header;\n                // 同理，只有一个元素，所以跨度就是跳表长度（没更新前，跳表长度在最后才更新，所以这里就是原长度）\n                update[i]->level[i].span = zsl->length;\n            }\n            // 更新跳表的最高层级\n            zsl->level = level;\n        }\n    ```\n\n3.  创建新节点，更新跳表\n\n    -   增加`span`字段的更新\n\n    ```c\n    x = zslCreateNode(level,score,obj);\n        for (i = 0; i < level; i++) {\n            // 从下往上更新\n            // 以下两句和链表插入的是相同的，就是将新节点插入的逻辑\n            x->level[i].forward = update[i]->level[i].forward;\n            update[i]->level[i].forward = x;\n    \n            /* update span covered by update[i] as x is inserted here */\n            // 根据每层节点的排位推算出跨度\n            // 更新新节点的跨度\n            x->level[i].span = update[i]->level[i].span - (rank[0] - rank[i]);\n            // 更新每层前驱节点的跨度（考虑到前驱节点可能是那一层的最后一个节点，所以这里不能简单地直接自增1）\n            update[i]->level[i].span = (rank[0] - rank[i]) + 1;\n        }\n    ```\n\n4.  {% label Redis orange %} 多了最后一个步骤（其余字段的更新）\n\n    1.  更新`span`跨度\n    2.  更新`backward`\n    3.  更新`tail`\n    4.  更新`length`\n\n    ```c\n        /* increment span for untouched levels */\n        for (i = level; i < zsl->level; i++) {\n            // 对于新节点没有涉及到的层级，跨度直接自增1即可\n            update[i]->level[i].span++;\n        }\n        // 更新BW指针，BW指针没有多层的概念\n        x->backward = (update[0] == zsl->header) ? NULL : update[0];\n        if (x->level[0].forward)\n            // 如果新节点不是最后一个节点，那就要更新后继节点BW指向新节点\n            x->level[0].forward->backward = x;\n        else\n            // 新节点是最后一个节点，更新tail\n            zsl->tail = x;\n    // 跳表长度自增1\n        zsl->length++;\n        return x;\n    ```\n    \n\n\n\n#### 跨度更新\n\n以下面的跳表插入**score=8的节点**为例\n\n![insert.svg](跳表-实现篇（Redis）.assets/insert.svg)\n\n**rank**数组：`[4, 4, 2, 2]`\n\n**update**数组：`[B, B, A, A]`（`A`、`B`为节点代号）\n\n**新节点**\n\n```c\nx->level[i].span = update[i]->level[i].span - (rank[0] - rank[i]);\n```\n\n针对新节点，需要更新新节点对应的每一层的前进指针的跨度\n\n1.  $i=0$，更新新节点第一层的跨度\n\n    $update[0] = B$\n\n    $update[0]->level[0].span = 1$\n\n    $rank[0] - rank[0] = 4 - 4 = 0$\n\n    $x->level[0].span =  1 - 0 = 1$\n\n2.  $i=1$，更新新节点第二层的跨度\n\n    $update[1] =  B$\n\n    $update[1]->level[1].span = 1$\n\n    $rank[0] - rank[1] = 0$\n\n    $x->level[1].span = 1 - 0 = 1$\n\n3.  $i=2$，更新新节点第三层的跨度\n\n    $update[2] = A$\n\n    $update[2]->level[2].span = 3$\n\n    $rank[0] -rank[2] = 4 - 2 = 2$\n\n    $x->level[2].span = 3 - 2 = 1$\n\n4.  $i=3$，更新新节点第四层的跨度\n\n    $update[3] = A$\n\n    $update[3]->level[3].span = 3$\n\n    $rank[0] - rank[3] = 4 - 2 = 2$\n\n    $x->level[3].span = 3 - 2 = 1$\n\n**前驱节点**\n\n**新节点层级内的节点**\n\n```c\nupdate[i]->level[i].span = (rank[0] - rank[i]) + 1;\n```\n\n1.  $i=0$，更新第一层节点（节点`A`）\n\n    $update[0]->level[0].span = (rank[0] - rank[0]) + 1 = (4 - 4) + 1 = 1$\n\n2.  $i=1$，更新第二层节点（节点`A`）\n\n    $update[1]->level[0].span = (rank[0] - rank[1]) + 1 = (4 - 4) + 1 = 1$\n\n3.  $i=2$，更新第三层节点（节点`B`）\n\n    $update[2]->level[2].span = (rank[0] - rank[2]) + 1 = (4 - 2) + 1 = 3$\n\n4.  $i=3$，更新第三层节点（节点`B`）\n\n    $update[3]->level[3].span = (rank[0] - rank[3]) + 1 = (4 - 2) + 1 = 3$\n\n**超过新节点层级的节点**\n\n```c\n    for (i = level; i < zsl->level; i++) {\n        // 对于新节点没有涉及到的层级，跨度直接自增1即可\n        update[i]->level[i].span++;\n    }\n```\n\n对于这些节点（超过新节点）的层级由于直接跳过新节点，上层能感知到的就是多跨过了一个节点，所以直接进行遍历并自增*1*即可\n\n\n\n最终插入结果如下图\n\n>   蓝色标注即为新增的指针\n\n![insert-result.svg](跳表-实现篇（Redis）.assets/insert-result.svg)\n\n\n\n### 查找\n\n函数声明\n\n```c\n// zslGetRank 根据给定的分数以及值返回节点的排位\nunsigned long zslGetRank(zskiplist *zsl, double score, robj *o);\n```\n\n函数实现\n\n```c\n/* Find the rank for an element by both score and key.\n * Returns 0 when the element cannot be found, rank otherwise.\n * Note that the rank is 1-based due to the span of zsl->header to the\n * first element. */\nunsigned long zslGetRank(zskiplist *zsl, double score, robj *o) {\n    zskiplistNode *x;\n    unsigned long rank = 0;\n    int i;\n\n    x = zsl->header;\n    for (i = zsl->level-1; i >= 0; i--) {\n        while (x->level[i].forward &&\n            (x->level[i].forward->score < score ||\n                (x->level[i].forward->score == score &&\n                compareStringObjects(x->level[i].forward->obj,o) <= 0))) {\n            rank += x->level[i].span;\n            x = x->level[i].forward;\n        }\n\n        /* x might be equal to zsl->header, so test if obj is non-NULL */\n        if (x->obj && equalStringObjects(x->obj,o)) {\n            return rank;\n        }\n    }\n    return 0;\n}\n```\n\n\n\n### 删除\n\n删除操作和插入操作类似，只是在找到删除节点后，需要将各层节点的前驱节点更新，然后删除节点\n\n函数声明\n\n```c\nint zslDelete(zskiplist *zsl, double score, robj *obj);\n```\n\n函数实现\n\n```c\n/* Delete an element with matching score/object from the skiplist. */\nint zslDelete(zskiplist *zsl, double score, robj *obj) {\n    zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;\n    int i;\n\n    x = zsl->header;\n    for (i = zsl->level-1; i >= 0; i--) {\n        while (x->level[i].forward &&\n            (x->level[i].forward->score < score ||\n                (x->level[i].forward->score == score &&\n                compareStringObjects(x->level[i].forward->obj,obj) < 0)))\n            x = x->level[i].forward;\n        update[i] = x;\n    }\n    /* We may have multiple elements with the same score, what we need\n     * is to find the element with both the right score and object. */\n    x = x->level[0].forward;\n    if (x && score == x->score && equalStringObjects(x->obj,obj)) {\n        zslDeleteNode(zsl, x, update);\n        zslFreeNode(x);\n        return 1;\n    }\n    return 0; /* not found */\n}\n```\n\n\n\n\n\n## 参考资料\n\n>-   《Redis设计与实现》—— 第5章：跳跃表\n>-   [huangzworks/redis-3.0-annotated: 带有详细注释的 Redis 3.0 代码（annotated Redis 3.0 source code）。 (github.com)](https://github.com/huangzworks/redis-3.0-annotated)\n\n","tags":["数据结构","跳表","Redis"],"categories":["数据结构","跳表"]},{"title":"跳表-实现篇（Golang）","url":"/posts/b1617a14/","content":"\n## 简介\n\n本文将参照论文使用Golang语言实现跳表\n\n建议阅读：[跳表-原理篇 | Crayonの博客](/posts/2e152a56/)\n\n本文按照以下顺序进行：\n\n- [简介](#简介)\n- [编码实现](#编码实现)\n\t- [结构体定义](#结构体定义)\n\t- [随机函数](#随机函数)\n\t- [查找](#查找)\n\t- [插入](#插入)\n\t- [删除](#删除)\n- [代码测试](#代码测试)\n\t- [性能对比](#性能对比)\n\t\t- [数据量1k](#数据量1k)\n\t\t- [数据量1w](#数据量1w)\n\t\t- [数据量10w](#数据量10w)\n- [Leetcode](#leetcode)\n\n## 编码实现\n\n本次实现和论文一样，节点顺序以升序排序\n\n### 结构体定义\n\n```go\ntype (\n\tNode struct {\n\t\tKey      float64\n\t\tValue    interface{}\n\t\tForwards []*Node\n\t}\n\n\tSkipList struct {\n\t\tHead     *Node\n\t\tLevel    int\n\t\t// MaxLevel 跳表的最大层级，这样可以很方便的实现不同最高层级的跳表\n\t\tMaxLevel int\n\t\t// P 层级上升的概率\n\t\tP        float64\n\t}\n)\n```\n\n### 随机函数\n\n和论文如出一辙，这里使用了golang的rand包来生成随机数\n\n```go\nfunc (s *SkipList) randomLevel() int {\n\tlevel := 1\n\tfor level < s.MaxLevel && rand.Float64() < s.P {\n\t\tlevel += 1\n\t}\n\treturn level\n}\n```\n\n### 查找\n\n```go\nfunc (s *SkipList) Search(key float64) (interface{}, bool) {\n    // 从头节点出发\n\tx := s.Head\n    // 外层循环，控制从上到下的层级搜索\n\tfor i := s.Level - 1; i >= 0; i-- {\n        // 内层循环，控制从左到右的前进搜索\n\t\tfor x.Forwards[i] != nil && x.Forwards[i].Key < key {\n\t\t\tx = x.Forwards[i]\n\t\t}\n\t}\n    // 一直搜索到最后一层，不小于目标key的前一个节点\n    // 获取下一个节点（因为遇到NIL会提前返回，不会返回NIL，所以可以不用判空）\n\tx = x.Forwards[0]\n\tif x == nil || x.Key != key {\n\t\treturn nil, false\n\t}\n\treturn x.Value, true\n}\n```\n\n### 插入\n\n插入操作和search操作类似，只是在找到插入位置后，需要将新节点插入到各层的前面\n\n而论文中的伪代码可以发现，其实遍历节点的逻辑是相同的，只是多了一步记录各层节点的操作（需要记录下当前节点在各层的前驱节点，后续插入时才能同步更新）\n\n并且在删除操作我们也需要进行遍历，所以我们可以把遍历的代码封装起来\n\n```go\nfunc (s *SkipList) findPrev(key float64) (x *Node, update []*Node) {\n\tupdate = make([]*Node, s.MaxLevel)\n\tx = s.Head\n\tfor i := s.Level - 1; i >= 0; i-- {\n\t\tfor x.Forwards[i] != nil && x.Forwards[i].Key < key {\n\t\t\tx = x.Forwards[i]\n\t\t}\n\t\tupdate[i] = x\n\t}\n\treturn\n}\n```\n\n**插入函数**\n\n```go\nfunc (s *SkipList) Insert(key float64, value interface{}) {\n\tx, update := s.findPrev(key)\n\tx = x.Forwards[0]\n\tif x != nil && x.Key == key {\n\t\tx.Value = value\n\t\treturn\n\t}\n\n\tlevel := s.randomLevel()\n\tif level > s.Level {\n\t\tfor i := s.Level; i < level; i++ {\n\t\t\tupdate[i] = s.Head\n\t\t}\n\t\ts.Level = level\n\t}\n\n\tx = makeNode(key, value, level)\n\tfor i := 0; i < level; i++ {\n\t\tx.Forwards[i] = update[i].Forwards[i]\n\t\tupdate[i].Forwards[i] = x\n\t}\n}\n```\n\n**查找函数**\n\n不要忘记更新下查找函数的代码\n\n```go\nfunc (s *SkipList) Search(key float64) (interface{}, bool) {\n\tx, _ := s.findPrev(key)\n\tx = x.Forwards[0]\n\tif x == nil || x.Key != key {\n\t\treturn nil, false\n\t}\n\treturn x.Value, true\n}\n```\n\n### 删除\n\n删除操作和插入操作类似，只是在找到删除节点后，需要将各层节点的前驱节点更新，然后删除节点\n\n```go\nfunc (s *SkipList) Delete(key float64) bool {\n\tx, update := s.findPrev(key)\n\tx = x.Forwards[0]\n\tif x == nil || x.Key != key {\n\t\treturn false\n\t}\n\n\tfor i := 0; i < s.Level; i++ {\n\t\tif update[i].Forwards[i] != x {\n\t\t\tbreak\n\t\t}\n\t\tupdate[i].Forwards[i] = x.Forwards[i]\n\t}\n\n\tfor i := s.Level - 1; i >= 0; i-- {\n\t\tif s.Head.Forwards[i] != nil {\n\t\t\tbreak\n\t\t}\n\t\ts.Level--\n\t}\n\n\treturn true\n}\n```\n\n## 代码测试\n\n由于跳表存在随机的因素，所以这里通过多次的运行来测试跳表的正确性\n\n![1737798614731](跳表-实现篇（Golang）.assets/1737798614731.png)\n\n通过配置文件指定执行的操作\n\n配置文件样例\n\n```yaml\n# 批量插入0-9999的kv\n# ot（operation type）：操作类型\n- ot: insert_range\n  # input：输入参数\n  input:\n    # 最终插入的数据范围：0-9999\n    # range_start：范围起点\n    range_start: 0\n\t# range_end：范围终点\n    range_end: 10000\n# k=-1，不存在\n- ot: search\n  input:\n    key: -1\n  output:\n    ok: false\n# k=3377，存在且v=3377\n- ot: search\n  input:\n    key: 3377\n  output:\n    ok: true\n    value: 3377\n```\n\n具体的测试代码可以查看\n[demo-bucket/algorithm/algorithm-golang/skiplist/skiplist_test.go at master · SuCrayon/demo-bucket](https://github.com/SuCrayon/demo-bucket/blob/master/algorithm/algorithm-golang/skiplist/skiplist_test.go)\n\n### 性能对比\n\n通过设置层级为1我们可以用同样的代码模拟有序单链表（也就是BST退化成链表的那种情况）的查找性能\n\n\n\n{% note info %}\n\n以下测试使用的benchmark参数\n\n```bash\n-test.benchmem -test.benchtime=5s\n```\n\n{% endnote %}\n\n\n\n#### 数据量1k\n\n**跳表（MaxLevel=16，P=0.5）**\n\n```csv\nopCount,nsPerOp,bytePerOp,allocPerOp\n34254062,179.8,384,3\n```\n\n\n\n**跳表（MaxLevel=32，P=0.25）**\n\n```csv\nopCount,nsPerOp,bytePerOp,allocPerOp\n29570007,215.7,768,3\n```\n\n\n\n**跳表（MaxLevel=32，P=0.5）**\n\n```csv\nopCount,nsPerOp,bytePerOp,allocPerOp\n24861520,237.4,768,3\n```\n\n\n\n**单链表（MaxLevel=1，P=0）**\n\n```csv\nopCount,nsPerOp,bytePerOp,allocPerOp\n786034,7536,24,3\n```\n\n\n\n#### 数据量1w\n\n**跳表（MaxLevel=16，P=0.5）**\n\n```csv\nopCount,nsPerOp,bytePerOp,allocPerOp\n25082064,292.0,384,3\n21268509,252.2,384,3\n19541179,270.8,384,3\n24443103,234.1,384,3\n23645776,236.2,384,3\n```\n\n**跳表（MaxLevel=32，P=0.25）**\n\n```csv\nopCount,nsPerOp,bytePerOp,allocPerOp\n15089992,403.9,768,3\n18066450,392.1,768,3\n16331352,439.7,768,3\n```\n\n**跳表（MaxLevel=32，P=0.5）**\n\n```csv\nopCount,nsPerOp,bytePerOp,allocPerOp\n15095322,430.9,768,3\n```\n\n**单链表（MaxLevel=1，P=0）**\n\n```csv\nopCount,nsPerOp,bytePerOp,allocPerOp\n36655,166034,24,3\n```\n\n\n\n\n\n#### 数据量10w\n\n**单链表（MaxLevel=1，P=0）**\n\n![1737800600781](跳表-实现篇（Golang）.assets/1737800600781.png)\n\n可以看到在这个数据量下的操作非常地慢\n\n\n\n**跳表（MaxLevel=32，P=0.5）**\n\n![1737800664852](跳表-实现篇（Golang）.assets/1737800664852.png)\n\n而跳表则和**1w**数据量时一样，没有明显地性能下降\n\n\n\n具体的测试代码可以查看\n[demo-bucket/algorithm/algorithm-golang/skiplist/benchmark_test.go at master · SuCrayon/demo-bucket](https://github.com/SuCrayon/demo-bucket/blob/master/algorithm/algorithm-golang/skiplist/benchmark_test.go)\n\n\n\n## Leetcode\n\n正好`Leetcode`上就有一道手写跳表的题目\n\n稍微改造下代码实现即可提交测试了\n\n题目链接：[1206. 设计跳表 - 力扣（LeetCode）](https://leetcode.cn/problems/design-skiplist/description/)\n\n![1737801773560](跳表-实现篇（Golang）.assets/1737801773560.png)\n\n\n\n\n\n","tags":["数据结构","跳表","Golang"],"categories":["数据结构","跳表"]},{"title":"跳表-原理篇","url":"/posts/2e152a56/","content":"\n\n## 什么是跳表\n\n跳表（也可以叫跳跃表，英文名：*Skip List*）是由*William Pugh*发明的一种查找数据结构，支持对数据的快速查找、插入和删除\n\nOI Wiki：[跳表 - OI Wiki](https://oi-wiki.org/ds/skiplist/)\n\n论文地址：[skiplists](https://15721.courses.cs.cmu.edu/spring2018/papers/08-oltpindexes1/pugh-skiplists-cacm1990.pdf)\n\n论文开篇就说明了这是一种可以用来代替平衡树的数据结构（平衡树的实现实在是太复杂了😩）\n\n与平衡树相比，跳表的插入和删除算法要简单得多\n\n\n\n### BST存在的问题\n\n>   Binary trees can be used for representing abstract data types such as dictionaries and ordered lists. They work well when the elements are inserted in a random order. Some sequences of operations, such as inserting the elements in order, produce degenerate data structures that give very poor performance. If it were possible to randomly permute the list of items to be in serted, trees would work well with high probability for any in put sequence. In most cases queries must be answered on-line, so randomly permuting the input is impractical. Balanced tree algorithms re-arrange the tree as operations are performed to maintain certain balance conditions and assure good perfor mance.\n\n论文中提到，对于二叉搜索树而言，当插入的数据是顺序的时候，会产生退化\n\n二叉搜索树（`BST`，*Binary Search Tree*），是一种具有特殊排序性质的二叉树，通过在插入数据时保证顺序以便后续能快速检索\n\n理想情况下`BST`呈现类似以下的结构，能够达到类似二分查找的效果\n\n\n```mermaid\ngraph TD;\n    A[7] --> B[3];\n    A --> C[9];\n    B --> D[1];\n    B --> E[5];\n    E --> F[4];\n    E --> G[6];\n    C --> H[8];\n    C --> I[10];\n```\n\n但是当插入的数据序列就是有序的时候，可能会出现退化成链表的情况\n\n\n```mermaid\ngraph TD;\n    A[2] --> B[1];\n    A --> C[3];\n    C --> D[4];\n    D --> E[5];\n    E --> F[6];\n```\n\n[二叉搜索树可视化](https://gallery.selfboot.cn/zh/algorithms/binarysearchtree)\n\n\n\n关于退化的问题也可以看看小灰的漫画讲解\n\n[漫画：什么是跳跃表？](https://mp.weixin.qq.com/s?__biz=MzIxMjE5MTE1Nw==&mid=2653190879&idx=1&sn=1916d0f6e72f34408261d70d13eecf5b&chksm=8c990805bbee81137dd6cadbe7b69cf84020233385cc5d7cee778d10977b6f9b28ea235b93e0&scene=21#wechat_redirect)\n\n\n\n## 跳表的结构\n\n针对`BST`会退化成链表的问题，或者说针对链表我们想要提高查询效率，使用二分查找的思想我们可以建立多级索引的概念\n\n![1737649458888](跳表-原理篇.assets/1737649458888.png)\n\n原论文中就有提到像`AVL`等强制平衡（结构定义比较复杂，每次操作都要保证结构的正确性），导致可能最终的性能很好，但是代码的实现难度可能直接导致其他人无法维护和扩展\n\n论文原文是这么描述的：\n\n> Second, if the algorithm is complex, programmers are de terred from implementing optimizations. For example, bal anced tree algorithms are normally described using recursive insert and delete procedures, since that is the most simple and intuitive method of describing the algorithms. A recursive in sert or delete procedure incurs a procedure call overhead. By using non-recursive insert and delete procedures, some of this overhead can be eliminated. However, the complexity of non recursive algorithms for insertion and deletion in a balanced tree is intimidating and this complexity deters most program mers from eliminating recursion in these routines.\n>\n>   ...\n>\n> From a theoretical point of view, there is no need for skip lists. Balanced trees can do everything that can be done with skip lists and have good worst-case time bounds (unlike skip lists). However, implementing balanced trees is an exacting task and as a result balanced tree algorithms are rarely imple mented except as part of a programming assignment in a data structures class. Skip lists are a simple data structure that can be used in place of balanced trees for most applications. Skip lists algo rithms are very easy to implement, extend and modify. Skip lists are about as fast as highly optimized balanced tree algo rithms and are substantially faster than casually implemented balanced tree algorithms.\n\n\n\n跳表设计上的一个巧妙的点就在于不强制维护索引层级（就是这个设计既兼顾了性能也简化了代码实现）\n\n插入节点的时候随机生成索引层级数\n\n### Initialization（初始化）\n\n>   An element NIL is allocated and given a key greater than any legal key. All levels of all skip lists are terminated with NIL. A new list is initialized so that the the level of the list is equal to 1 and all forward pointers of the list’s header point to NIL.\n\n![1737706482282](跳表-原理篇.assets/1737706482282.png)\n\n分配一个`NIL`节点（这个节点的键大于任何元素），所有的节点的所有级别的指针最终都以`NIL`为终点\n\n### Search（查找）\n\n通过遍历前进指针来搜索元素\n\n{% note warning %}\n\n注意：遍历时不会越过正在搜索的元素的节点，当当前层级无法找到指定元素时，需要向下一层级搜索\n\n{% endnote %}\n\n#### 算法伪代码\n\n![1737706994096](跳表-原理篇.assets/1737706994096.png)\n\n```plaintext\nfor i := list->level downto 1 do\n\t// 第一层循环，从上到下的层级遍历\n\twhile x->forward[i]->key < searchKey do\n\t\t// 第二层循环，从左到右遍历，只有节点小于searchKey才能前进（因为是从上到下遍历，节点小于说明searchKey对应的节点一定在该节点 之后，所以可以前进）\n\t\tx := x->forward[i]\n\n```\n\n#### 逐步解析\n\n以搜索12节点为例子\n\n![1737708513748](跳表-原理篇.assets/1737708513748.png)\n\n{% note info %}\n**符号说明**\n`NIL`：终点（表示无穷大，搜索到这个节点表示必须向下搜索，即本层遍历结束）\n`HEAD`：头节点\n`x`：当前节点\n`x.forward[i]`：表示x的第i+1层的下一个节点（i+1层的前进指针）\n`x.forward[i].key`：表示x的第i+1层的下一个节点的key\n{% endnote %}\n\n0.  初始化`x=HEAD`\n\n1.  `x.forward[3].key`（也就是节点【6】），6小于12，`x = x.forward[3]`（前进）\n2.  `x.forward[3].key`（也就是节点【`NIL`】），`NIL`表示终点（无穷大），`i--`（向下搜索）\n3.  `x.forward[2].key`（也就是节点【25】），25大于12，`i--`（向下搜索）\n4.  `x.forward[1].key`（也就是节点【9】），9小于12，`x = x.forward[1]`（前进）\n5.  `x.forward[1].key`（也就是节点【25】），25大于12，`i--`（向下搜索）\n6.  `x.forward[0].key`（也就是节点【12】），12等于12，`i--`（向下搜索）\n7.  `i<0`表示没有在下一层了，遍历（循环）结束，`x`停留在节点【12】的前一个节点（也就是节点【9】）\n8.  `x.forward[0].key`是否等于12，如果是则说明找到目标，不是则表示目标不在跳表内\n\n\n\n可以看到，整个遍历的过程是一个找前驱节点的过程，找到等于目标值的节点的前一个节点\n\n### 随机函数（Random Level）\n\n跳表使用随机的方式来生成新节点的层高\n\n![1737712483120](跳表-原理篇.assets/1737712483120.png)\n\n### Insertion（插入）\n\n理解了搜索的过程，插入操作也很好理解，本质就是找到前一个节点并将值插入的过程（不熟悉的建议复习下链表的插入操作😁）\n\n#### 算法伪代码\n\n先上论文的伪代码\n\n![1737709368360](跳表-原理篇.assets/1737709368360.png)\n\n```plaintext\nInsert(list, searchKey, newValue)\n\tlocal update[1...MaxLevel]\n\tx := list->header\n\t// 这一步和搜索的代码一样，找到前驱节点\n\tfor i := list->level downto 1 do\n\t\twhile x->forward[i].key < searchKey do\n\t\t\tx := x->forward[i]\n\t\t-- x->key < searchKey <= x->forward[i]->key\n\t\t// 记录了遍历路径中每层的最后一个节点\n\t\tupdate[i] := x\n\tx := x->forward[i]\n\t// 如果相同则直接更新值\n\tif x->key = searchKey then x->value := newValue\n\telse\n\t\t// 随机生成新节点的层级\n\t\t|v| := randomLevel()\n\t\t// 如果新节点的层级大于当前跳表的最高层级\n\t\t// 记录相应的信息方便后面统一更新节点\n\t\t// 还要更新当前跳表的最高层级\n\t\tif |v| > list->level then\n\t\t\tfor i := list->level+1 to |v| do\n\t\t\t\tupdate[i] := list->header\n\t\t\tlist->level := |v|\n\t\tx := makeNode(|v|, searchKey, value)\n\t\t// 和常规的链表插入操作类似\n\t\t// 1. 新节点连接前驱节点的下一个节点\n\t\t// 2. 前驱节点在连接新节点\n\t\tfor i := 1 to level do\n\t\t\tx->forward[i] := update[i]->forward[i]\n\t\t\tupdate[i]->forward[i] := x\n```\n\n#### 逐步解析\n\n以下是论文中关于插入节点【17】的示意图\n\n![1737706980365](跳表-原理篇.assets/1737706980365.png)\n\n对着论文的示意图我们逐步分析代码的执行过程\n\n{% note info %}\n**符号说明**\n`NIL`：终点（表示无穷大，搜索到这个节点表示必须向下搜索，即本层遍历结束）\n`HEAD`：头节点\n`x`：当前节点\n`x.forward[i]`：表示x的第i+1层的下一个节点（i+1层的前进指针）\n`x.forward[i].key`：表示x的第i+1层的下一个节点的key\n`update`：update数组，记录了遍历过程中每一层的最后一个节点（从哪个节点往下遍历的，这些节点是需要同步更新的）\n{% endnote %}\n\n\n\n0.  初始化`x=HEAD`，初始化`update数组`（直接初始化最大的层级数的大小，后续不用动态扩缩）\n\n遍历过程中与搜索的一样，只是在向下搜索之前将节点记录到`update`\n\n##### |V| \\<= list->level\n\n**新节点层级不超过当前跳表的最高层级**\n\n这种情况下我们只需要更新新节点对应的层级上的前驱节点即可\n\n![insert-case1](跳表-原理篇.assets/insert-case1.svg)\n\n\n\n##### |V| \\> list->level\n\n**新节点层级超过当前跳表的最高层级**\n\n遍历过程中由于并不经过`HEAD`所以`update`中不会有记录，而当新节点的层级超过当前跳表最高层级的时候又需要更新`HEAD`的前进指针，为了后续操作逻辑统一，单独执行一遍循环赋值，这就是以下代码的含义\n\n![1737712286704](跳表-原理篇.assets/1737712286704.png)\n\n\n\n![insert-case2](跳表-原理篇.assets/insert-case2.svg)\n\n\n\n### Deletion（删除）\n\n#### 算法伪代码\n\n![1737712378629](跳表-原理篇.assets/1737712378629.png)\n\n\n\n#### 逐步解析\n\n跳表节点的删除也非常的简单，和链表的删除操作相同，只是多了多层级节点的更新的操作\n\n1.  搜索前驱节点\n\n2.  更新所有相关层级（`update`）的指针（断开与被删除节点的连接）\n\n    ```plaintext\n    ...\n    for i := 1 to list->level do\n    \t// 判断是否需要更新，如果前一个节点连接的不是被删除节点，那就不需要更新，可以提前中止循环\n    \tif update[i]->forward[i] != x then break\n    \tupdate[i]->forward[i] := x->forward[i]\n    // 显式释放\n    free(x)\n    ...\n    ```\n\n3.  从上到下更新`HEAD`指针，跳表层级更新\n\n    ```plaintext\n    ...\n    // 通过另一个循环来更新当前跳表的最高层级\n    // 职责单一（一个循环更新节点指针，一个循环更新层级数），代码可读性更好\n    while list->level > 1 and\n    \tlist->header->forward[list->level] = NIL do\n    \tlist->level := list->level-1\n    ```\n\n\n\n## 参考资料\n\n>   [跳表可视化：https://gallery.selfboot.cn/zh/algorithms/skiplist](https://gallery.selfboot.cn/zh/algorithms/skiplist)\n>\n>   [跳表论文：https://15721.courses.cs.cmu.edu/spring2018/papers/08-oltpindexes1/pugh-skiplists-cacm1990.pdf](https://15721.courses.cs.cmu.edu/spring2018/papers/08-oltpindexes1/pugh-skiplists-cacm1990.pdf)\n>\n>   [跳表 - OI Wiki](https://oi-wiki.org/ds/skiplist/)\n>\n>   [漫画：什么是跳跃表？](https://mp.weixin.qq.com/s?__biz=MzIxMjE5MTE1Nw==&mid=2653190879&idx=1&sn=1916d0f6e72f34408261d70d13eecf5b&chksm=8c990805bbee81137dd6cadbe7b69cf84020233385cc5d7cee778d10977b6f9b28ea235b93e0&scene=21#wechat_redirect)","tags":["数据结构","跳表"],"categories":["数据结构","跳表"]},{"title":"Redis-字典","url":"/posts/eca128ac/","content":"\n\n## 概述\n\n**字典**，又称为符号表（*symbol table*）、关联数组（*associative array*）或映射（*map*），是一种用于保存键值对（*key-value pair*）的抽象数据结构\n\n\n\n> 和{% label Java purple %} 的`HashMap`， {% label Python green %} 的`dict`以及 {% label Golang blue %} 的`map`类似\n\n\n\n**字典**在{% label Redis green %} 中的应用相当广泛，比如{% label Redis green %} 的数据库就是使用**字典**来作为底层实现的，对数据库的增删改查操作也是构建在对**字典**的操作之上的\n\n除了用来表示数据库之外，**字典**还是哈希键的底层实现之一，当一个哈希键包含的键值对比较多，又或者键值对中的元素都是比较长的字符串时， {% label Redis green %} 就会使用**字典**作为哈希键的底层实现\n\n\n## 字典的实现\n\n`Redis`的**字典**使用*哈希表*作为底层实现，一个*哈希表*里面可以有多个哈希表节点，而每个哈希表节点就保存了**字典**中的一个键值对\n\n### 哈希表\n\n`Redis`的**字典**所使用的哈希表由`dict.h/dictht`结构定义：\n\n```c\n\n/* This is our hash table structure. Every dictionary has two of this as we\n * implement incremental rehashing, for the old to the new table. */\n/*\n * 哈希表\n *\n * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。\n */\ntypedef struct dictht {\n    \n    // 哈希表数组\n    dictEntry **table;\n\n    // 哈希表大小\n    unsigned long size;\n    \n    // 哈希表大小掩码，用于计算索引值\n    // 总是等于 size - 1\n    unsigned long sizemask;\n\n    // 该哈希表已有节点的数量\n    unsigned long used;\n\n} dictht;\n\n```\n\n\n{% note info %}\n\n- `table`属性是一个数组，数组中的每个元素都是一个指向`dict.h/dictEntry`结构的指针，每个`dictEntry`结构保存着一个键值对\n- `size`属性记录了哈希表的大小，也就是`table`数组的大小\n- `used`属性记录了哈希表目前已有节点的数量\n- `sizemask`属性的值总是等于`size-1`，这个属性和哈希值一起决定了一个键应该被放到`table`数组的哪个索引上面\n\n{% endnote %}\n\n![1720094241571](字典.assets/1720094241571.png)  \n\n### 哈希表节点\n\n哈希表节点使用`dictEntry`结构表示，每个`dictEntry`结构都保存着一个键值对\n\n```c\n\n/*\n * 哈希表节点\n */\ntypedef struct dictEntry {\n    \n    // 键\n    void *key;\n\n    // 值\n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n    } v;\n\n    // 指向下个哈希表节点，形成链表\n    struct dictEntry *next;\n\n} dictEntry;\n\n```\n\n{% note info %}\n\n- `key`属性保存着键值对中的键\n- `v`属性则保存着键值对中的值，其中键值对的值可以是一个指针，或者是一个`uint64_t`整数又或者是一个`int64_t`整数\n- `next`属性指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对连接在一起，以此来解决键冲突（*collision*）的问题\n\n> 从`next`指针可以知道{% label Redis green %}使用的就是拉链法解决哈希冲突的\n\n{% endnote %}\n\n\n![1720094523892](字典.assets/1720094523892.png)  \n\n### 字典\n\n`Redis`中的**字典**由`dict.h/dict`结构表示\n\n```c\n\n/*\n * 字典\n */\ntypedef struct dict {\n\n    // 类型特定函数\n    dictType *type;\n\n    // 私有数据\n    void *privdata;\n\n    // 哈希表\n    dictht ht[2];\n\n    // rehash 索引\n    // 当 rehash 不在进行时，值为 -1\n    int rehashidx; /* rehashing not in progress if rehashidx == -1 */\n\n} dict;\n\n```\n\n{% note info %}\n\n- `type`属性和`privdata`属性是针对不同类型的键值对，为创建多态字典而设置的\n  - `type`属性是一个指向`dictType`结构的指针，每个`dictType`结构保存了一组用于操作特定类型键值对的函数，`Redis`会为用途不同的字典设置不同的类型特定函数\n  - `privdata`属性则保存了需要传给那些类型特定函数的可选参数\n\n`dict.h/dictType`\n\n{% hideBlock dictType定义,, %}\n\n```c\n\n/*\n * 字典类型特定函数\n */\ntypedef struct dictType {\n\n    // 计算哈希值的函数\n    unsigned int (*hashFunction)(const void *key);\n\n    // 复制键的函数\n    void *(*keyDup)(void *privdata, const void *key);\n\n    // 复制值的函数\n    void *(*valDup)(void *privdata, const void *obj);\n\n    // 对比键的函数\n    int (*keyCompare)(void *privdata, const void *key1, const void *key2);\n\n    // 销毁键的函数\n    void (*keyDestructor)(void *privdata, void *key);\n    \n    // 销毁值的函数\n    void (*valDestructor)(void *privdata, void *obj);\n\n} dictType;\n\n```\n\n{% endhideBlock %}\n\n- `ht`属性是一个包含两个项的数组，数组中的每个项都是一个`dictht`哈希表，一般情况下，字典只是用`ht[0]`的哈希表，`ht[1]`哈希表只会在对`ht[0]`哈希表进行*rehash*时使用\n\n- `rehashidx`也和*rehash*有关，它记录了*rehash*的进度，如果目前没有在进行*rehash*，那么它的值为-1\n\n{% endnote %}\n\n普通状态下（没有进行*rehash*）的字典：\n\n![1720096568065](字典.assets/1720096568065.png)  \n\n## 哈希算法\n\n当要将一个新的键值对添加到字典里面的时候，程序需要先根据键值对的键计算出哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引位置上面\n\n\n\n`Redis`计算哈希值和索引值的方法如下：\n\n>   1.  使用字典设置的哈希函数，计算键的哈希值\n>\n>       `hash = dict -> type -> hashFunction(key);`\n>\n>   2.  使用哈希表的`sizemask`属性和哈希值计算出索引值\n>\n>       根据情况不同，`ht[x]`可以是`ht[0]`或者是`ht[1]`\n>\n>       `index = hash & dict -> ht[x].sizemask;`\n\n\n\n当字典被用作数据库的底层实现，或者哈希键的底层实现时，`Redis`使用`MurmurHash2`算法来计算键的哈希值\n\n>   资料：http://code.google.com/p/smhasher/\n\n## 解决键冲突\n\n当有两个或以上数量的键被分配到了哈希表数组的同一个索引上面 时，我们称这些键发生了冲突（*collision*）\n\n\n\n`Redis`的哈希表使用拉链法（链地址法/*separate chaining*）来解决键冲突\n\n\n\n每个哈希表节点都有一个`next`指针，多个哈希表节点可以用`next`指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，这就解决了键冲突问题\n\n\n\n![1720283556269](字典.assets/1720283556269.png)\n\n\n{% hideToggle 源码分析,, %}\n\n```c\n\ndictEntry *dictAddRaw(dict *d, void *key)\n{\n    // ...\n    // 前置代码，暂时不需要关注，只需要看以下的关键代码即可\n    // ...\n\n    // T = O(1)\n    /* Allocate the memory and store the new entry */\n    // 如果字典正在 rehash ，那么将新键添加到 1 号哈希表\n    // 否则，将新键添加到 0 号哈希表\n    ht = dictIsRehashing(d) ? &d->ht[1] : &d->ht[0];\n    // 为新节点分配空间\n    entry = zmalloc(sizeof(*entry));\n    // 将新节点插入到链表表头\n    entry->next = ht->table[index];\n    ht->table[index] = entry;\n    // 更新哈希表已使用节点数量\n    ht->used++;\n\n    /* Set the hash entry fields. */\n    // 设置新节点的键\n    // T = O(1)\n    dictSetKey(d, entry, key);\n\n    return entry;\n}\n\n```\n\n新节点加入的逻辑中，是直接将新节点的`next`指向当前索引位置的节点，然后更新索引位置的指针为当前新加入的节点\n\n这个过程即为头插法的实现，即每次新节点都会放在链表的头部，这种方式将插入的复杂度固定在`O(1)`\n\n\n\n![1720284337818](字典.assets/1720284337818.png)\n\n{% endhideToggle %}\n\n## rehash\n\n随着操作的不断执行，哈希表保存的键值对会逐渐地增多或者减少，为了让哈希表的负载因子（*load factor*）维持在一个合理的范围之内，当哈希表保存的键值对数量太多或者太少时，程序需要对哈希表的大小进行相应的扩展或者收缩\n\n\n\n扩展和收缩哈希表的工作可以通过执行`rehash`（重新散列）操作来完成，`Redis`对字典的哈希表执行`rehash`的步骤如下：\n\n1.  为字典的`ht[1]`哈希表分配空间，这个哈希表的空间大小取决于要执行的操作和`ht[0]`当前包含的键值对数量（也就是`ht[0].used`属性的值）\n\n    -   如果执行的是扩展操作，那么`ht[1]`的大小为第一个大于等于$ht[0].used * 2$的$2^n$\n\n    -   如果执行的是收缩操作，那么`ht[1]`的大小为第一个大于等于$ht[0].used$的$2^n$\n\n        \n\n2.  将保存在`ht[0]`中的所有键值对`rehash`到`ht[1]`上面\n\n    >   `rehash`指的是重新计算键的哈希值和索引值，然后将键值对放置到`ht[1]`哈希表的指定位置上\n\n3.  当`ht[0]`包含的所有键值对都迁移到了`ht[1]`之后（`ht[0]`变为空表），释放`ht[0]`，将`ht[1]`设置为`ht[0]`（交换指针），并在`ht[1]`新创建一个空白哈希表，为下一次`rehash`做准备\n\n**举个栗子🌰**\n\n假设程序要对下图所示的字典的`ht[0]`进行扩展操作\n\n![1720334001176](字典.assets/1720334001176.png)\n\n1.  `ht[0].used`当前的值为$4$，$4*2=8$，而$8$（$2^3$）恰好是第一个大于等于$4$的$2$的$n$次方，所以程序会将`ht[1]`哈希表的大小设置为$8$\n\n    ![1720334215791](字典.assets/1720334215791.png)\n\n2.  将`ht[0]`包含的四个键值对都`rehash`到`ht[1]`\n\n    ![1720334249824](字典.assets/1720334249824.png)\n\n3.  释放`ht[0]`，并将`ht[1]`设置为`ht[0]`，然后为`ht[1]`分配一个空白哈希表\n\n    至此，对哈希表的扩展操作执行完毕，程序成功将哈希表的大小从原来的$4$扩大到了现在的$8$\n\n    ![1720334335665](字典.assets/1720334335665.png)\n\n\n\n### 哈希表的扩展与收缩\n\n#### 扩展\n\n当以下条件中的任意一个被满足时，程序会自动开始对哈希表执行扩展操作\n\n-   服务器目前没有在执行`BGSAVE`命令或者`BGREWRITEAOF`命令，并且哈希表的负载因子大于等于$1$\n-   服务器目前正在执行`BGSAVE`命令或者`BGREWRITEAOF`命令，并且哈希表的负载因子大于$5$\n\n其中，哈希表负载因子的计算公式为：\n$$\nLoadFactor = ht[0].used / ht[0].size\n$$\n\n\n>   根据`BGSAVE`或者`BGREWRITEAOF`命令是否正在执行，服务器执行扩展操作所需的负载因子并不相同，这是因为在执行`BGSAVE`或者`BGREWRITEAOF`命令的过程中，`Redis`需要创建当前服务器进程的子进程，而大多数操作系统都是采用写时复制（*copy-on-write*）技术来优化子进程的使用效率，所以在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而尽可能地避免在子进程存在期间进行哈希表扩展操作，这可以 避免不必要的内存写入操作，最大限度地节约内存\n\n{% hideToggle 源码分析,, %}\n\n`dict.c/_dictExpandIfNeeded`\n\n```c\n\nstatic int _dictExpandIfNeeded(dict *d)\n{\n    // ...\n\n    /* If we reached the 1:1 ratio, and we are allowed to resize the hash\n     * table (global setting) or we should avoid it but the ratio between\n     * elements/buckets is over the \"safe\" threshold, we resize doubling\n     * the number of buckets. */\n    // 一下两个条件之一为真时，对字典进行扩展\n    // 1）字典已使用节点数和字典大小之间的比率接近 1：1\n    //    并且 dict_can_resize 为真\n    // 2）已使用节点数和字典大小之间的比率超过 dict_force_resize_ratio\n    if (d->ht[0].used >= d->ht[0].size &&\n        (dict_can_resize ||\n         d->ht[0].used/d->ht[0].size > dict_force_resize_ratio))\n    {\n        // 新哈希表的大小至少是目前已使用节点数的两倍\n        // T = O(N)\n        return dictExpand(d, d->ht[0].used*2);\n    }\n\n    return DICT_OK;\n}\n\n```\n\n- 当`dict_can_resize`开关处于启用状态，并且负载因子大于等于1时，会进行扩容\n- 当负载因子大于`dict_force_resize_ratio`时，会强制进行扩容\n\n当`Redis`执行`BGSAVE`或者`BGREWRITEAOF`命令时，会使用`dictDisableResize`函数关闭`dict_can_resize`开关，尽可能不进行扩容；而当哈希表的负载因子超过了强制扩容的上限（目前这个值设置的是$5$）时，也会强制进行扩容以保证哈希表的性能\n\n```c\n\n/*\n * 开启自动 rehash\n *\n * T = O(1)\n */\nvoid dictEnableResize(void) {\n    dict_can_resize = 1;\n}\n\n/*\n * 关闭自动 rehash\n *\n * T = O(1)\n */\nvoid dictDisableResize(void) {\n    dict_can_resize = 0;\n}\n\n```\n\n{% endhideToggle %}\n\n#### 收缩\n\n当哈希表的负载因子小于$0.1$时，程序自动开始对哈希表执行收缩操作\n\n\n\n\n\n### 渐进式rehash\n\n扩展或收缩哈希表需要将`ht[0]`里面的所有键值对`rehash`到`ht[1]`里面，但是，这个`rehash`动作并不是一次性、集中式完成的，而是分多次、渐进式完成的\n\n\n{% note info %}\n\n原因在于，如果`ht[0]`里面只保存着四个键值对，那么服务器可以在瞬间就将这些键值对全部`rehash`到`ht[1]`；但是，如果哈希表里面保存着上万上千万甚至上亿个键值对的时候，那么一次性将这些键值对全部`rehash`到`ht[1]`的话，庞大的计算量可能会导致服务器在一段时间内停止服务\n\n{% endnote %}\n\n因此，为了避免`rehash`对服务器性能造成影响，服务器不是一次性将`ht[0]`里面的键值对全部`rehash`到`ht[1]`，而是分多次、渐进式地将`ht[0]`里面的键值对慢慢地`rehash`到`ht[1]`上\n\n\n\n以下是哈希表渐进式`rehash`的详细步骤：\n\n1.  为`ht[1]`分配空间，让字典同时持有`ht[0]`和`ht[1]`两个哈希表\n2.  在字典中维持一个索引计数器变量`rehashidx`，并将它的值设置为$0$，表示`rehash`工作正式开始\n3.  在`rehash`进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将`ht[0]`哈希表在`rehashidx`索引上的所有键值对`rehash`到`ht[1]`上，当`rehash`工作完成之后，程序将rehashidx`属性的值增一\n4.  随着字典操作的不断执行，最终在某个时间点上，`ht[0]`的所有键值对都会被`rehash`到`ht[1]`，这时程序将`rehashidx`属性的值设为$-1$，表示`rehash`操作已完成\n\n\n\n>   渐进式`rehash`的好处在于它采取了分而治之的方式，将`rehash`键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式`rehash`带来的庞大计算量\n\n\n\n#### 渐进式rehash执行期间的哈希表操作\n\n因为在进行渐进式`rehash`的过程中，字典会同时使用`ht[0]`和`ht[1]`两个哈希表，所以在渐进式`rehash`进行期间，字典的删除、查找、更新等操作会在两个哈希表上进行\n\n-   要在字典里面查找一个键的话，程序会现在`ht[0]`里面进行查找，如果没找到的话 ，就会继续到`ht[1]`里面进行查找\n-   新添加到字典的键值对一律会被保存到`ht[1]`里面，而`ht[0]`则不会再进行任何添加操作，这一措施保证了`ht[0]`包含的键值对数量只减不增，并随着`rehash`操作的执行而最终变成空表\n\n{% hideToggle 源码分析,, %}\n\n`dict.c/dictGenericDelete`\n\n```c\n\nstatic int dictGenericDelete(dict *d, const void *key, int nofree)\n{\n    // ...\n\n    // 遍历哈希表\n    // T = O(1)\n    for (table = 0; table <= 1; table++) {\n\n        // 计算索引值 \n        idx = h & d->ht[table].sizemask;\n        // 指向该索引上的链表\n        he = d->ht[table].table[idx];\n        prevHe = NULL;\n        // 遍历链表上的所有节点\n        // T = O(1)\n        while(he) {\n        \n            if (dictCompareKeys(d, key, he->key)) {\n\n                // ...\n\n                // 更新已使用节点数量\n                d->ht[table].used--;\n\n                // 返回已找到信号\n                return DICT_OK;\n            }\n\n            prevHe = he;\n            he = he->next;\n        }\n\n        // 如果执行到这里，说明在 0 号哈希表中找不到给定键\n        // 那么根据字典是否正在进行 rehash ，决定要不要查找 1 号哈希表\n        if (!dictIsRehashing(d)) break;\n    }\n\n    // 没找到\n    return DICT_ERR; /* not found */\n}\n\n```\n\n{% endhideToggle %}\n\n## 总结\n\n-   字典被广泛用于实现`Redis`的各种功能，其中包括数据库和哈希键\n-   `Redis`中的字典使用哈希表作为底层实现，每个字典带有两个哈希表，一个平时使用，另一个仅在进行`rehash`时使用\n-   当字典被用作数据库的底层实现，或者哈希键的底层实现时，`Redis`使用`MurmurHash2`算法来计算键的哈希值\n-   哈希表使用链地址法解决哈希冲突，被分配到同一个索引上的多个键值对会连接成一个单向链表\n-   在对哈希表进行扩展或者收缩操作时，程序需要将现有哈希表包含的所有键值对`rehash`到新哈希表里面，并且这个`rehash`过程并不是一次性完成，而是渐进式完成地\n\n\n\n## 参考资料\n\n>   《Redis设计与实现》—— 第四章：字典\n>\n>    [huangzworks/redis-3.0-annotated: 带有详细注释的 Redis 3.0 代码（annotated Redis 3.0 source code）。 (github.com)](https://github.com/huangzworks/redis-3.0-annotated) \n>\n\n\n\n\n\n\n\n\n\n","tags":["Redis","数据库","NoSQL"],"categories":["Redis"]},{"title":"Redis-简单动态字符串（SDS）","url":"/posts/79e7fc4f/","content":"\n\n\n\n## 概述\n\n{% label Redis purple %}没有直接使用C语言的传统字符串表示，而是自己构建了一种名为简单动态字符串（Simple dynamic string，SDS）的抽象类型，并将{% label SDS green %}用作{% label Redis purple %}默认的字符串表示\n\n> C语言传统字符串通常用以空字符结尾的字符数组表示\n\n\n在{% label Redis purple %}中，C字符串只会作为字符串字面量用在一些无须对字符串值进行修改的地方，比如打印日志\n\n当{% label Redis purple %}需要的是一个可以被修改的字符串值的时候，{% label Redis purple %}就会使用{% label SDS green %}来表示字符串值\n\n{% note %}\n\n比如在{% label Redis purple %}的数据库里面，包含字符串值的键值对在底层都是有{% label SDS green %}实现的\n\n{% endnote %}\n\n\n除了用来保存数据库中的字符串值之外，{% label SDS green %}还被用作缓冲区\n\n{% note %}\n\n- `AOF`模块中的`AOF`缓冲区\n- 客户端状态中的输入缓冲区\n\n{% endnote %}\n\n\n\n## SDS的定义\n\n每个`sds.h/sdshdr`结构表示一个{% label SDS green %}值\n\n```c\n\n/*\n * 保存字符串对象的结构\n */\nstruct sdshdr {\n    \n    // buf 中已占用空间的长度\n    int len;\n\n    // buf 中剩余可用空间的长度\n    int free;\n\n    // 数据空间\n    char buf[];\n};\n\n```\n\n\n![1719648860531](简单动态字符串（SDS）.assets/1719648860531.png)  \n\n\n{% note info %}\n\n`free`属性的值为0，表示这个{% label SDS green %}没有剩余可用空间了\n\n`len`属性的值为5，表示这个{% label SDS green %}保存了一个五字节长的字符串\n\n`buf`属性是一个`char`类型的数组，数组的前五个字节分别保存`R`、`e`、`d`、`i`、`s`五个字符，而最后一个字节则保存了空字符`'\\0'`\n\n{% endnote %}\n\n\n{% note info %}\n\n{% label SDS green %}遵循了C字符串以空字符结尾的惯例，**保存空字符的1字节空间不计算在{% label SDS green %}的`len`属性里面**\n\n为空字符分配额外的1字节空间，以及添加空字符到字符串末尾等操作，都是有{% label SDS green %}函数自动完成的，所以这个空字符对于{% label SDS green %}的使用者（上层调用方）来说是完全透明的\n\n{% hideToggle 部分函数解析,, %}\n\n![1719674373325](简单动态字符串（SDS）.assets/1719674373325.png)  \n\n如下图，`sdscatlen`函数是用于拼接（追加）字符串到已有{% label SDS green %}的函数，可以看到在函数返回前的最后一步，会在结尾自动填充`'\\0'`\n\n包括在{% label SDS green %}扩容的时候，也会自动多分配1字节的空间留给最后的`'\\0'`使用\n\n如下图，`sdsMakeRoomFor`函数是用于{% label SDS green %}扩容的函数\n\n![1719674571768](简单动态字符串（SDS）.assets/1719674571768.png)  \n\n{% endhideToggle %}\n\n遵循空字符结尾这一惯例的好处是，{% label SDS green %}可以直接复用一部分C字符串函数库里面的函数\n\n{% hideToggle 函数复用例子,, %}\n\n可以直接使用`<stdio.h>/printf`函数打印{% label SDS green %}保存的字符串的值\n\n```c\n\nprintf(\"%s\", s->buf);\n\n```\n\n{% endhideToggle %}\n\n{% endnote %}\n\n\n## SDS与C字符串的区别\n\n### 常数复杂度获取字符串长度\n\n`C`字符串不会记录长度信息，每次获取一个`C`字符串的长度都必须遍历整个字符串，对遇到的每个字符串进行计数，直到遇到代表字符串结尾的空字符为止，这个操作的复杂度为*O(N)*\n\n\n\n而{% label SDS green %}只需要访问`len`属性即可\n\n![1719733950042](简单动态字符串（SDS）.assets/1719733950042.png)\n\n{% note info %}\n\n{% label SDS green %}`len`和`free`属性的设置和更新工作都是由{% label SDS green %}的**API**在执行时自动完成的（通过在写操作冗余存储长度的信息来实现快速读取）\n\n{% endnote %}\n\n\n\n### 杜绝缓冲区溢出\n\n`C`字符串不记录自身长度带来的另一个问题就是容易造成缓冲区溢出（buffer overflow）\n\n如`<string.h>/strcat`函数可以将`src`字符串中的内容拼接到`dest`字符串的末尾（一个字符串拼接函数）\n\n```c\nchar *strcat(char *dest, const char *src);\n```\n\n\n\n因为`C`字符串不记录自身的长度，所以`strcat`假定用户在执行这个函数之前，已经为`dest`分配了足够的内存了，可以容纳`src`字符串中的所有内容，而一旦`src`没有预留足够的空间，就会产生缓冲区溢出\n\n\n\n比如下图中的两个字符串，假设这两个字符串在内存中是紧邻的\n\n![1719734881193](简单动态字符串（SDS）.assets/1719734881193.png)\n\n此时执行以下代码进行字符串拼接的操作\n\n```c\nstrcat(s1, \" Cluster\");\n```\n\n由于`s1`没有预留足够的空间以容纳拼接的`Cluster`字符串（空间不足也没有提前进行扩容），那么在执行完`strcat`函数之后，`s2`的内容会被意外修改，如下图所示\n\n![1719735008040](简单动态字符串（SDS）.assets/1719735008040.png)\n\n\n\n而{% label SDS green %}则在**API**层面就会进行空间检查，发现空间不足时会自动进行扩容，所以不存在缓冲区溢出问题\n\n以下是{% label SDS green %}字符串拼接的**API**——`sdscatlen`函数源码\n\n![1719735247877](简单动态字符串（SDS）.assets/1719735247877.png)\n\n\n\n### 减少修改字符串时带来的内存重分配次数\n\n对于一个包含**N**个字符的`C`字符串来说，底层实现总是一个**N+1**个字符长的数组（额外的一个字符空间用于保存空字符）\n\n这导致每次增长或缩短一个`C`字符串时，程序总是要对保存这个`C`字符串的数组进行一次内存重分配操作\n\n-   对于增长字符串的操作（比如拼接操作）——执行这个操作之前，程序需要通过内存重分配来扩展底层数组的空间大小（如果忘了这一步就会造成缓冲区溢出）\n-   对于缩短字符串的操作（比如截断操作）——执行这个操作之后，程序需要通过内存重分配来释放字符串不在使用的那部分空间（如果忘了这一步就会造成内存泄漏）\n\n\n\n`SDS`通过`len`和`free`属性解除了字符串长度和底层数组长度之间的关联：`buf`数组的长度不一定就是字符数量+1，数组里面可以包含未使用的字节，而这些字节的数量就由`SDS`的`free`属性记录\n\n\n\n通过未使用空间，{% label SDS green %} 实现了**空间预分配**和**惰性空间释放**两种优化策略，减少了修改字符串时内存重分配的次数\n\n进行**N**次字符串操作：\n\n-   `C`字符串必须进行**N**次内存重分配\n-   `SDS`则降低到最多需要进行**N**次内存重分配（空间预留）\n\n\n\n#### 空间预分配\n\n当需要对{% label SDS green %} 进行扩容的时候，会额外分配未使用的空间\n\n扩容规则\n\n{% note info %}\n\n注：Redis3.0源码的扩容规则，可能不适用于其他版本\n\n{% endnote %}\n\n\n\n-   如果修改之后的长度小于1MB，那么会分配和`len`属性同样大小的未使用空间（即`free`属性和`len`属性相同）\n\n    比如，修改后的`len`为13，那么程序也会分配13字节的未使用空间，{% label SDS green %} 的`buf`数组的实际长度将变成13+13+1=27字节（额外1字节用于保存空字符，这1字节是申请内存时自动添加的）\n\n-   如果修改之后的长度大于等于1MB，那么会分配1MB的未使用空间\n\n{% hideToggle 扩容源码,, %}\n\n![1719742759110](简单动态字符串（SDS）.assets/1719742759110.png)  \n\n{% endhideToggle %}\n\n\n\n#### 惰性空间释放\n\n这个策略用于优化{% label SDS green %}的字符串缩短的操作\n\n当{% label SDS green %} 的**API**需要缩短{% label SDS green %}保存的字符串时，程序不会立即使用内存重分配来回收缩短后的多出来的字节，而是使用`free`属性将这些字节数量记录起来，并等待将来使用\n\n\n\n`sdstrim`函数接受一个{% label SDS green %} 和一个`C`字符串作为参数，移除{% label SDS green %}前后前缀中所有在`C`字符串中出现过的字符\n\n![1719744670422](简单动态字符串（SDS）.assets/1719744670422.png)  \n\n```c\nsdstrim(s, \"XY\"); // 移除SDS字符串中的前后前缀中所有'X'和'Y'\n```\n\n![1719744758517](简单动态字符串（SDS）.assets/1719744758517.png)  \n\n{% hideToggle 代码验证,, %}\n\n```c\n\nint main(int argc, char const *argv[])\n{\n    sds s = sdsnew(\"XYXabcXYYX\");\n    printf(\"s: %s, s->len: %ld, s->free: %ld\\n\", s, sdslen(s), sdsavail(s));\n\n    s = sdstrim(s, \"XY\");\n    printf(\"s: %s, s->len: %ld, s->free: %ld\\n\", s, sdslen(s), sdsavail(s));\n\n    return 0;\n}\n\n```\n\n执行结果：\n\n![1719744803261](简单动态字符串（SDS）.assets/1719744803261.png)  \n\n{% endhideToggle %}\n\n\n\n### 二进制安全\n\n`C`字符串中的字符必须符合某种编码（比如**ASCII**），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为字符串的结尾，这些限制使得`C`字符串只能保存文本数据，而不能保存像图片、音频、视频这样的二进制数据\n\n如果有一种使用空字符来分割多个单词的特殊数据格式，那么这种格式就不能使用`C`字符串来保存\n\n而`SDS`使用`len`属性来判断字符串长度的，所以不存在此问题\n\n\n\n### 兼容部分C字符串函数\n\n`SDS`底层的数据结构中使用`buf`属性存储实际的字符串数据，本身的存储还是遵循`C`字符串的惯例，这使得`SDS`可以复用部分`C`字符串的库函数\n\n\n\n\n### 总结\n\n| 场景           | C 字符串                                                     | SDS                                                          |\n| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 字符串长度获取 | 慢（复杂度为`O(N)`）                                         | 快（复杂度为`O(1)`）                                         |\n| **API**安全性  | 低（字符串拼接操作需要使用者自行考虑字符串扩容，否则可能会出现缓冲区溢出） | 高（字符串拼接操作预先检查容量，不会造成缓冲区溢出）         |\n| 字符串修改效率 | 较低（修改字符串**N**次必然需要执行**N**次内存重分配）       | 高（修改字符串**N**次最多需要执行**N**次内存重分配）         |\n| 数据内容       | 只能保存文本数据                                             | 二进制安全的，也适用于二进制数据的保存                       |\n| 库函数兼容性   | 不存在兼容问题                                               | 可以使用部分库函数（底层字符串存储仍然保持`C`字符串的惯例是得以复用部分库函数的关键） |\n\n\n\n\n\n## 参考资料\n\n>   -   《Redis设计与实现》—— 第2章：简单动态字符串\n>   -   [huangzworks/redis-3.0-annotated: 带有详细注释的 Redis 3.0 代码（annotated Redis 3.0 source code）。 (github.com)](https://github.com/huangzworks/redis-3.0-annotated) ","tags":["Redis","数据库","NoSQL"],"categories":["Redis"]},{"title":"Golang-逃逸分析","url":"/posts/cb05bf87/","content":"\n\n\n## 逃逸分析\n\n\n\n### 什么是逃逸分析\n\n\n\n在`C`、`C++`这类需要手动管理内存的编程语言中，对象或结构体具体分配到堆还是栈上是由工程师自主决定的，如果能够精准地为每一个变量分配合理的空间，那么程序的运行效率和内存使用效率一定是最高的，但是手动分配会导致以下两个问题：\n\n-   不需要分配到堆上的对象分配到堆上 —— 浪费内存空间、且可能忘记释放导致内存泄漏\n-   需要分配到堆上的对象分配到栈上 —— 悬挂指针、影响内存安全\n\n\n\n#### 悬挂指针\n\n在`C`语言中，栈上的变量被函数作为返回值返回给调用方是一个常见的错误\n\n如以下代码\n\n```c\nint *foo ( void )   \n{   \n    int t = 3;\n    return &t;\n}\n```\n\n当 `foo`函数返回后，它的本地变量会被编译器回收，调用方获取的是一个悬挂指针，不确定当前指针指向的值是否还能正常使用（可能都已经被回收了）\n\n\n\n>   什么是逃逸分析？\n>\n>   在编译器优化中，*逃逸分析*是用来决定指针动态作用域的方法，是一种静态分析下方法\n>\n>   `Go`语言的编译器使用逃逸分析决定变量应该在栈上分配还是在堆上分配\n\n\n\n`Go`语言中的逃逸分析是编译器执行静态代码分析后，对内存管理进行的优化和简化，它可以决定一个变量是分配到栈上还是堆上\n\n\n\n### 逃逸策略\n\n如果一个函数返回一个变量的引用，那么它就会发生逃逸\n\n编译器根据变量是否被外部引用来决定是否逃逸\n\n>   -   如果函数外部没有引用，则优先放到栈中（不是一定放在栈中）\n>   -   如果函数外部存在引用，则必定放在堆中\n\n\n\n#### 解读\n\n-   函数外部没有引用，则优先放在栈中\n\n    >   栈空间\n    >\n    >   优点：栈内存的分配非常的快，只需要两个`CPU`指令——`PUSH`和`RELEASE`，对应分配和释放，栈会在函数调用结束后自动回收\n    >\n    >   缺点：栈空间有限，不像堆一样空间充足，这就是为什么在不存在外部引用的情况下也只是优先栈，而不是绝对分配在栈上，对于那些不可预知大小的变量，依然要分配在堆上\n    >\n    >   \n    >\n    >   堆空间\n    >\n    >   优点：堆空间充足（相较于栈空间而言）\n    >\n    >   缺点：堆不像栈那样可以自动清理，在`C`、`C++`这类没有`GC`机制的语言中就必须手动释放内存，否则容易发生内存泄漏\n\n-   如果函数外部存在引用，则必定放在堆中\n\n    当外部存在引用时，将变量分配到栈上势必会出现悬挂指针，所以这类变量必须分配到堆中\n\n\n\n通过逃逸分析，从代码层面分析后尽量将那些不需要分配到堆上的变量直接分配到栈上，堆上的变量少了，会减轻分配堆内存的开销，同时也减少`GC`的压力，提高程序的运行速度\n\n\n\n### 如何查看逃逸分析结果\n\n比如以下代码栗子🌰\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc foo() *int {\n\tt := 3\n\treturn &t;\n}\n\nfunc main() {\n\tx := foo()\n\tfmt.Println(*x)\n}\n```\n\n\n\n#### 查看编译时的输出结果\n\n使用以下命令编译可以知道逃逸分析的结果\n\n```go\ngo build -gcflags '-m -l' main.go\n```\n\n>   `-gcflags`：是`Go`编译器选项，具体有哪些选项及含义可以使用以下命令查看\n>\n>   ```go\n>   go tool compile -h\n>   ```\n>\n>   命令输出\n>\n>   ```bash\n>   usage: compile [options] file.go...\n>   ...\n>    -l    disable inlining\n>    -m    print optimization decisions\n>   ...\n>   ```\n>\n>   `-l`：关闭内联优化\n>\n>   `-m`：打印优化决策结果\n\n\n\n![1711871015189](逃逸分析.assets/1711871015189.png)\n\n\n\n#### 查看汇编代码\n\n也可以通过汇编代码知道逃逸分析的结果\n\n```go\ngo tool compile -S escape_analysis.go\n```\n\n\n\n![1711871320525](逃逸分析.assets/1711871320525.png)\n\n这里说明`t`是通过`runtime.newobject()`在堆上分配的对象\n\n\n\n\n\n### 常见的逃逸场景\n\n#### 指针逃逸\n\n最典型的一种场景，当函数外部存在对函数内变量的引用的时候，就会发生逃逸，将变量分配到堆上（不然不就出现悬挂指针了嘛）\n\n看一段平时最常见的指针逃逸代码\n\n```go\npackage main\n\ntype Student struct {\n    Name string\n    Age  int\n}\n\nfunc NewStudent(name string, age int) *Student {\n    return &Student{\n        Name: name,\n        Age:  age,\n    }\n}\n\nfunc main() {\n    NewStudent(\"Crayon\", 24)\n}\n```\n\n这段代码的意义很简单，就是提供了一个`NewStudent`的创建者函数，有时候为了避免大结构体作为函数出入参时的值拷贝的性能开销，会使用指针类型的结构体\n\n`NewStudent`函数内部创建了一个`Student`结构体，并将该结构体指针返回给外部，`Go`编译器认为这是一种指针逃逸行为，需要将变量分配到堆上以避免悬挂指针的问题的产生，尽管函数外部（`main`函数）中目前还没有使用到`NewStudent`函数返回的结构体指针\n\n\n\n#### 栈空间不足逃逸\n\n栈的空间是有限的，所以当变量所需要的内存大小超过栈所能分配的空间的时候，就会将变量分配到堆上\n\n```go\npackage main\n\nfunc Slice() {\n    s := make([]int, 0, 1000)\n\n    for i, _ := range s {\n        s[i] = i\n    }\n}\n\nfunc main() {\n    Slice()\n}\n```\n\n查看编译的结果，此时并不会发生逃逸\n\n![1711876383880](逃逸分析.assets/1711876383880.png)\n\n\n\n但是我们加大切片的容量大小，就会发生逃逸\n\n```go\npackage main\n\nfunc Slice() {\n    s := make([]int, 0, 10000)\n\n    for i, _ := range s {\n        s[i] = i\n    }\n}\n\nfunc main() {\n    Slice()\n}\n```\n\n将切片容量扩大到10000，此时再执行编译，可以看到发生了逃逸\n\n![1711876465962](逃逸分析.assets/1711876465962.png)\n\n\n\n##### 容量未知也会导致导致\n\n当切片的容量为变量（即编译期还是未知的）的时候，也会发生逃逸\n\n```go\npackage main\n\nimport \"math/rand\"\n\nfunc Slice() {\n    n := rand.Intn(10)\n    _ = make([]int, n)\n}\n\nfunc main() {\n    Slice()\n}\n```\n\n\n\n![1712202550858](逃逸分析.assets/1712202550858.png)\n\n\n\n#### 闭包引用对象逃逸\n\n```go\npackage main\n\nfunc Fibonacci() func() int {\n    a, b := 0, 1\n    return func() int {\n        a, b = b, a+b\n        return a\n    }\n}\n\nfunc main() {\n    f := Fibonacci()\n    for i := 0; i < 10;i++ {\n        f()\n    }\n}\n```\n\n\n\n![1711877883619](逃逸分析.assets/1711877883619.png)\n\n可见函数内部`a`、`b`都发生了逃逸\n\n\n\n#### 动态类型逃逸？\n\n这块应该是有一定的误区，至少我在`1.17`版本测试时，空接口类型的参数不会发生逃逸\n\n```go\npackage main\n\nfunc test(v interface{}) interface{} {\n    return v\n}\n\nfunc main() {\n    s := \"Crayon\"\n    test(s)\n}\n```\n\n这里`test`函数的入参是空接口（动态类型），但是并没有发生逃逸\n\n\n\n但是使用`fmt.Println`函数时就会发生逃逸\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc test(v interface{}) interface{} {\n    return v\n}\n\nfunc main() {\n    s := \"Crayon\"\n    // test(s)\n    fmt.Println(s)\n}\n```\n\n\n\n使用`fmt.Println`打印变量就发生了逃逸\n\n![1711879475952](逃逸分析.assets/1711879475952.png)\n\n\n\n分析`fmt.Println`的源码，参考其他文章发现一个有意思的点\n\n那就是`reflect`系列的方法，如`reflect.ValueOf`，调用该类方法会触发逃逸\n\n\n\n```go\npackage main\n\nimport \"reflect\"\n\nfunc main() {\n    s := \"Crayon\"\n    reflect.TypeOf(s)\n    reflect.TypeOf(s).Kind()\n    reflect.ValueOf(s)\n    reflect.ValueOf(s).Kind()\n}\n```\n\n\n\n![1712207034963](逃逸分析.assets/1712207034963.png)\n\n\n\n##### `reflect.ValueOf`导致逃逸？\n\n这里先看下`reflect.ValueOf`函数，点进源码就能直接看到为什么逃逸了\n\n![1712207129918](逃逸分析.assets/1712207129918.png)\n\n显示的调用`escapes`函数让变量逃逸，这里是有意为之，具体为什么有待深入研究下，这里就不往下展开了\n\n\n\n##### `reflect.TypeOf`导致逃逸？\n\n从实验的结果来看，只是调用`reflect.TypeOf`函数并不会触发逃逸，而是在接着调用`Type`接口（`reflect.TypeOf`函数的返回值）的方法的时候才会发生逃逸\n\n![1712207287284](逃逸分析.assets/1712207287284.png)\n\n查看`TypeOf`的源码，简单画了一下涉及的几个结构体/接口的类图\n\n![1712208272189](逃逸分析.assets/1712208272189.svg)\n\n`Type`是一个顶层的接口，`rtype`是`Type`接口的一个实现，`emptyInterface`和`rtype`则是组合的关系，存在一个`typ`的成员变量引用`rtype`\n\n![1712208451934](逃逸分析.assets/1712208451934.png)\n\n`toType`的实现很简单，就是将具体实现转化成更抽象的接口类型\n\n\n\n###### 场景复现\n\n分别模拟了`reflect.TypeOf`函数的源码行为以及结构体抽象成接口的方法调用的场景\n\n```go\npackage main\n\nimport \"unsafe\"\n\ntype MyInterface interface {\n    Do()\n}\n\ntype Pointer struct {\n}\n\nfunc (s *Pointer) Do() {\n\n}\n\nfunc Pointer2MyInterface(s *Pointer) MyInterface {\n    return s\n}\n\ntype emptyInterface struct {\n    typ  *Pointer\n    word unsafe.Pointer\n}\n\nfunc TypeOf(i interface{}) MyInterface {\n    eface := (*emptyInterface)(unsafe.Pointer(&i))\n    return Pointer2MyInterface(eface.typ)\n}\n\nfunc TypeOf0(i interface{}) *Pointer {\n    eface := (*emptyInterface)(unsafe.Pointer(&i))\n    return eface.typ\n}\n\nfunc TypeOf1(i interface{}) Pointer {\n    eface := (*emptyInterface)(unsafe.Pointer(&i))\n    return *eface.typ\n}\n\nfunc main() {\n    p1 := Pointer{}\n    TypeOf(p1)\n    TypeOf(p1).(*Pointer).Do()\n    TypeOf(p1).Do()\n\n    TypeOf0(p1)\n    TypeOf0(p1).Do()\n\n    TypeOf1(p1)\n    pp1 := TypeOf1(p1)\n    pp1.Do()\n\n    p2 := &Pointer{}\n    Pointer2MyInterface(p2)\n\n    p3 := &Pointer{}\n    Pointer2MyInterface(p3).Do()\n\n    p4 := &Pointer{}\n    Pointer2MyInterface(p4).(*Pointer).Do()\n}\n```\n\n逃逸分析结果\n\n```bash\n$ go tool compile -m -l escape_analysis.go\nescape_analysis.go:12:7: s does not escape\nescape_analysis.go:16:26: leaking param: s to result ~r1 level=0\nescape_analysis.go:25:13: leaking param: i to result ~r1 level=0\nescape_analysis.go:30:14: leaking param: i to result ~r1 level=0\nescape_analysis.go:35:14: i does not escape\nescape_analysis.go:42:11: p1 does not escape\nescape_analysis.go:43:11: p1 does not escape\nescape_analysis.go:44:11: p1 escapes to heap\nescape_analysis.go:46:12: p1 does not escape\nescape_analysis.go:47:12: p1 does not escape\nescape_analysis.go:49:12: p1 does not escape\nescape_analysis.go:50:19: p1 does not escape\nescape_analysis.go:53:11: &Pointer{} does not escape\nescape_analysis.go:56:11: &Pointer{} escapes to heap\nescape_analysis.go:59:11: &Pointer{} does not escape\n<autogenerated>:1: leaking param: .this\n```\n\n\n\n###### 结论\n\n从逃逸分析的结果可以说明，接口方法的调用会导致逃逸\n\n大概的原因可能是接口属于动态的类型，只要实现了接口的结构体都可能是结构体的实现，而编译期间我们并不能知道调用方法的变量属于哪类实现，为避免指针引用以及栈空间大小可能不足的问题，就直接将变量逃逸分配到堆上了\n\n\n\n\n\n#### slice、map、chan元素为指针类型，元素逃逸\n\n```go\npackage main\n\nfunc main() {\n    s1 := make([]*string, 0, 10)\n    str1 := \"str1\"\n    s1 = append(s1, &str1)\n\n    s2 := make([]string, 0, 10)\n    str2 := \"str2\"\n    s2 = append(s2, str2)\n\n    m1 := make(map[*string]string, 8)\n    mkey1 := \"mkey1\"\n    mvalue1 := \"mvalue1\"\n    m1[&mkey1] = mvalue1\n\n    m2 := make(map[string]*string, 8)\n    mkey2 := \"mkey2\"\n    mvalue2 := \"mvalue2\"\n    m2[mkey2] = &mvalue2\n\n    m3 := make(map[*string]*string, 8)\n    mkey3 := \"mkey3\"\n    mvalue3 := \"mvalue3\"\n    m3[&mkey3] = &mvalue3\n\n    m4 := make(map[string]string, 8)\n    mkey4 := \"mkey4\"\n    mvalue4 := \"mvalue4\"\n    m4[mkey4] = mvalue4\n\n    ch1 := make(chan *string, 10)\n    chStr1 := \"chStr1\"\n    ch1 <- &chStr1\n\n    ch2 := make(chan string, 10)\n    chStr2 := \"chStr2\"\n    ch2 <- chStr2\n}\n```\n\n逃逸分析结果\n\n```bash\n$ go tool compile -m -l escape_analysis.go\nescape_analysis.go:5:5: moved to heap: str1\nescape_analysis.go:13:5: moved to heap: mkey1\nescape_analysis.go:19:5: moved to heap: mvalue2\nescape_analysis.go:23:5: moved to heap: mkey3\nescape_analysis.go:24:5: moved to heap: mvalue3\nescape_analysis.go:33:5: moved to heap: chStr1\nescape_analysis.go:4:15: make([]*string, 0, 10) does not escape\nescape_analysis.go:8:15: make([]string, 0, 10) does not escape\nescape_analysis.go:12:15: make(map[*string]string, 8) does not escape\nescape_analysis.go:17:15: make(map[string]*string, 8) does not escape\nescape_analysis.go:22:15: make(map[*string]*string, 8) does not escape\nescape_analysis.go:27:15: make(map[string]string, 8) does not escape\n```\n\n\n\n结论：指针类型元素会发生逃逸\n\n\n\n### 案例分析\n\n#### 案例一\n\n```go\npackage main\ntype S struct {}\n\nfunc main() {\n  var x S\n  _ = identity(x)\n}\n\nfunc identity(x S) S {\n  return x\n}\n```\n\n\n\n{% hideBlock 查看分析 %}\n\n{% label 没有发生逃逸 green %}\n\n由于`Go`语言中参数是值传递，输入输出都是值拷贝，所以此处不会发生逃逸，变量`x`还是分配在栈上\n\n{% endhideBlock %}\n\n\n\n#### 案例二\n\n```go\npackage main\n\ntype S struct {}\n\nfunc main() {\n  var x S\n  y := &x\n  _ = identity(y)\n}\n\nfunc identity(z *S) *S {\n  return z\n}\n```\n\n\n\n{% hideBlock 查看分析 %}\n\n{% label 没有发生逃逸 green %}\n\n变量`x`被变量`y`引用，但是都没有超出`main`函数的作用域，所以没有发生逃逸\n\n而`identity`函数输入直接作为返回值返回，没有将变量`z`的引用返回到函数外部，所以变量`z`没有发生逃逸\n\n{% endhideBlock %}\n\n\n\n#### 案例三\n\n```go\npackage main\n\ntype S struct {\n  M *int\n}\n\nfunc main() {\n  var i int\n  refStruct(i)\n}\n\nfunc refStruct(y int) (z S) {\n  z.M = &y\n  return z\n}\n```\n\n\n\n{% hideBlock 查看分析 %}\n\n{% label 发生逃逸 orange %}\n\n变量`y`属于`refStruct`函数的局部变量（形参），将`y`的引用赋给`z.M`这个结构体内的变量再返回给函数外部，函数外部想要访问`M`（获取`M`引用地址对应的值），`y`就不能分配在栈上，必须逃逸分配到堆上\n\n{% endhideBlock %}\n\n\n\n### 总结\n\n-   栈上分配内存比在堆中分配内存有更高的效率\n-   栈上分配的内存不需要`GC`处理，回收的效率高（用完即回收）\n-   堆上分配的内存使用完毕会交给`GC`处理\n-   逃逸分析的目的是决定内存分配在栈还是堆上，正确的内存方式能够提高分配效率和回收效率，提升程序性能\n-   `Go`语言逃逸分析在编译阶段完成\n\n\n\n### 参考资料\n\n>   [Go 语言的栈内存和逃逸分析 | Go 语言设计与实现 (draveness.me)](https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-stack-management/)\n>\n>   [逃逸分析是怎么进行的 | Go 程序员面试笔试宝典 (golang.design)](https://golang.design/go-questions/compile/escape/)\n>\n>   [golang的fmt包引发的变量逃逸到堆的问题_golang fmt.sprintf out of memory-CSDN博客](https://blog.csdn.net/weixin_44531174/article/details/116173347)\n>\n>   [golang变量逃逸分析小探 - 声zzz (reusee.github.io)](https://reusee.github.io/post/escape_analysis/)\n>\n>   [通过实例理解Go逃逸分析 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/374991282)\n>\n>   [通过实例理解Go逃逸分析 | Tony Bai](https://tonybai.com/2021/05/24/understand-go-escape-analysis-by-example/)","tags":["Golang","编程语言"],"categories":["编程语言","Golang"]},{"title":"Golang-数组与切片","url":"/posts/a8e92d53/","content":"\n\n\n## 数组与切片\n\n### 数组与切片有什么异同\n\n切片的底层数据就是数组，是对数组的封装，描述一个数组的片段\n\n相同点在于两者都是对顺序数据结构的一种表达，可以通过下标来访问元素\n\n\n\n**数组**\n\n数组是定长的，在初始化之后就无法改变\n\n`Go`语言中只有**存储元素类型**和**数组大小**都相同才认为是同一类型\n\n\n\n**切片**\n\n切片可以理解为是动态数组，切片的类型与长度无关\n\n\n\n数组就是一片连续的内存，切片实际上是一个结构体，包含三个字段：长度、容量、底层数组指针\n\n\n\n```go\n// runtime/slice.go\ntype slice struct {\n    // 底层数组的指针\n\tarray unsafe.Pointer\n    // 长度\n\tlen   int\n    // 容量\n\tcap   int\n}\n```\n\n\n\n`slice`结构示意图\n\n![1711180039754](数组与切片/1711180039754.png)\n\n\n\n{% note warning %}\n\n底层数组是可以被多个`slice`同时引用的，因此，对一个`slice`的元素进行操作可能影响其他`slice`\n\n{% endnote %}\n\n\n\n#### 代码分析\n\n\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\tslice := []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\ts1 := slice[2:5]\n\ts2 := s1[2:6:7]\n\n\ts2 = append(s2, 100)\n\ts2 = append(s2, 200)\n\n\ts1[2] = 20\n\n\tfmt.Println(s1)\n\tfmt.Println(s2)\n\tfmt.Println(slice)\n}\n```\n\n以上代码的输出结果\n\n{% hideBlock 查看答案 %}\n\n```\n[2 3 20]\n[4 5 6 7 100 200]\n[0 1 2 3 20 5 6 7 100 9]\n```\n\n{% endhideBlock %}\n\n\n\n### 特殊切片\n\n根据数组或切片生成新的切片一般使用以下方式\n\n```go\nslice := array[start:end]\n```\n\n这种生成方式没有指定切片的容量，那么这个切片容量就是从`start`开始一直到`array`结束\n\n代码示例\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    arr := [5]int{0, 1, 2, 3, 4}\n    s1 := arr[2:4]\n    fmt.Printf(\"s1: %v, len(s1): %d, cap(s1): %d\\n\", s1, len(s1), cap(s1))\n}\n```\n\n以上代码运行结果\n\n{% hideToggle 运行结果 %}\n\n```\ns1: [2 3], len(s1): 2, cap(s1): 3\n```\n\n{% endhideToggle %}\n\n\n\n根据数组或切片生成切片还有另一种写法，即切片的同时也指定容量\n\n```go\nslice := array[start:end:max]\n```\n\n切片长度和容量的计算公式如下\n\n`len(slice)==end-start`\n\n`cap(slice)==max-start`\n\n三个参数之间满足以下关系\n\n`start<=end<=max<=len(arr)-1`\n\n`max`的值必须大于等于`end`且不能大于底层数组的索引最大值\n\n代码示例\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    arr := [5]int{0, 1, 2, 3, 4}\n    s1 := arr[2:4:5]\n    // 6大于数组的索引最大值，这里编译期就会报错\n    // s2 := arr[2:4:6]\n    fmt.Printf(\"s1: %v, len(s1): %d, cap(s1): %d\\n\", s1, len(s1), cap(s1))\n\n    s1 = make([]int, 0, 10)\n    s1 = append(s1, 0, 1, 2, 3, 4)\n    // s1底层数组长度，即cap为10，所以8没有问题\n    s2 := s1[2:4:8]\n    fmt.Printf(\"s2: %v, len(s2): %d, cap(s2): %d\\n\", s2, len(s2), cap(s2))\n}\n\n```\n\n\n\n{% hideToggle 运行结果 %}\n\n```\ns1: [2 3], len(s1): 2, cap(s1): 3\ns2: [2 3], len(s2): 2, cap(s2): 6\n```\n\n{% endhideToggle %}\n\n\n\n### 切片扩容\n\n\n\n#### 1.17及之前的版本\n\n```go\n// runtime/slice.go\n// growslice handles slice growth during append.\n// It is passed the slice element type, the old slice, and the desired new minimum capacity,\n// and it returns a new slice with at least that capacity, with the old data\n// copied into it.\n// ...\nfunc growslice(et *_type, old slice, cap int) slice {\n    // ...\n    newcap := old.cap\n\tdoublecap := newcap + newcap\n\tif cap > doublecap {\n\t\tnewcap = cap\n\t} else {\n\t\tif old.cap < 1024 {\n\t\t\tnewcap = doublecap\n\t\t} else {\n\t\t\t// Check 0 < newcap to detect overflow\n\t\t\t// and prevent an infinite loop.\n\t\t\tfor 0 < newcap && newcap < cap {\n\t\t\t\tnewcap += newcap / 4\n\t\t\t}\n\t\t\t// Set newcap to the requested cap when\n\t\t\t// the newcap calculation overflowed.\n\t\t\tif newcap <= 0 {\n\t\t\t\tnewcap = cap\n\t\t\t}\n\t\t}\n\t}\n    \n    // ...\n}\n```\n\n##### 函数参数解析\n\n`cap`：期望扩容到的最小容量\n\n```go\ns1 := []int{1}\ns1 = s1.append(s1, 2, 3, 4)\n```\n\n比如这里`s1`需要追加3个元素，容量不足需要触发扩容，新切片的最小容量就是`1+3=4`，故对应`cap`参数为4\n\n\n\n\n\n##### 预估容量\n\n-   如果期望容量（`cap`）大于当前容量的两倍（`doublecap`）就会使用期望容量\n-   如果当前切片的容量（`old.cap`）小于1024就会将容量翻倍\n-   如果当前切片的容量（`old.cap`）大于1024就会每次增加25%的容量，直到新容量大于期望容量（{% label 并不是扩容1/4哦 red %}）\n\n\n\n{% note warning %}\n\n上述扩容逻辑只是确定了切片的大致容量（仅仅是扩容逻辑的上半部分），接下来还需要根据切片中的元素大小对齐内存，根据切片中元素所占字节大小走不同的分支逻辑进行内存对齐\n\n{% endnote %}\n\n\n\n##### 内存对齐\n\n上半部分确定了一个基准的扩容容量，接下来下半部分需要计算内存大小并且判断是否需要内存对齐来确定最终扩容后的容量大小\n\n```go\nfunc growslice(et *_type, old slice, cap int) slice {\n    // ...\n    // 到这已经得到newcap（大致容量）大小，接下来的代码需要根据内存对齐的情况来确定最终的cap大小来创建新的底层数组\n    var overflow bool\n\tvar lenmem, newlenmem, capmem uintptr\n\t// Specialize for common values of et.size.\n\t// For 1 we don't need any division/multiplication.\n\t// For sys.PtrSize, compiler will optimize division/multiplication into a shift by a constant.\n\t// For powers of 2, use a variable shift.\n\tswitch {\n\tcase et.size == 1:\n\t\tlenmem = uintptr(old.len)\n\t\tnewlenmem = uintptr(cap)\n\t\tcapmem = roundupsize(uintptr(newcap))\n\t\toverflow = uintptr(newcap) > maxAlloc\n\t\tnewcap = int(capmem)\n\tcase et.size == sys.PtrSize:\n\t\tlenmem = uintptr(old.len) * sys.PtrSize\n\t\tnewlenmem = uintptr(cap) * sys.PtrSize\n\t\tcapmem = roundupsize(uintptr(newcap) * sys.PtrSize)\n\t\toverflow = uintptr(newcap) > maxAlloc/sys.PtrSize\n\t\tnewcap = int(capmem / sys.PtrSize)\n\tcase isPowerOfTwo(et.size):\n\t\tvar shift uintptr\n\t\tif sys.PtrSize == 8 {\n\t\t\t// Mask shift for better code generation.\n\t\t\tshift = uintptr(sys.Ctz64(uint64(et.size))) & 63\n\t\t} else {\n\t\t\tshift = uintptr(sys.Ctz32(uint32(et.size))) & 31\n\t\t}\n\t\tlenmem = uintptr(old.len) << shift\n\t\tnewlenmem = uintptr(cap) << shift\n\t\tcapmem = roundupsize(uintptr(newcap) << shift)\n\t\toverflow = uintptr(newcap) > (maxAlloc >> shift)\n\t\tnewcap = int(capmem >> shift)\n\tdefault:\n\t\tlenmem = uintptr(old.len) * et.size\n\t\tnewlenmem = uintptr(cap) * et.size\n\t\tcapmem, overflow = math.MulUintptr(et.size, uintptr(newcap))\n\t\tcapmem = roundupsize(capmem)\n\t\tnewcap = int(capmem / et.size)\n\t}\n\n\tif overflow || capmem > maxAlloc {\n\t\tpanic(errorString(\"growslice: cap out of range\"))\n\t}\n\n\tvar p unsafe.Pointer\n\tif et.ptrdata == 0 {\n\t\tp = mallocgc(capmem, nil, false)\n\t\t\n\t\tmemclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem)\n\t} else {\n\t\tp = mallocgc(capmem, et, true)\n\t\tif lenmem > 0 && writeBarrier.enabled {\n\t\t\tbulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem-et.size+et.ptrdata)\n\t\t}\n\t}\n\tmemmove(p, old.array, lenmem)\n\n\treturn slice{p, old.len, newcap}\n}\n```\n\n\n\n\n\n#### 代码分析\n\n\n\n```go\npackage main\n\nimport \"fmt\"\n\n/*\n切片扩容\n*/\n\nfunc main() {\n    s1 := []int{1, 2}\n    fmt.Printf(\"[before] s1: %v, len(s1): %d, cap(s1): %d\\n\", s1, len(s1), cap(s1))\n    s1 = append(s1, 3, 4, 5)\n    fmt.Printf(\"[after] s1: %v, len(s1): %d, cap(s1): %d\\n\", s1, len(s1), cap(s1))\n}\n\n```\n\n\n\n根据上面规则分析，先对容量进行预估\n\n-   `append`之前：`len(s1)==2`，`cap(s1)==2`\n-   `append`之后：由于切片容量已经用完，会触发扩容，扩容后`len(s1)==5`，`cap(s1)==5`\n\n\n\n确定了预估容量为5，即`newcap=5`\n\n\n\n<!-- TODO: 涉及到内存对齐 -->\n\n\n\n{% hideToggle 运行结果 %}\n\n```\n[before] s1: [1 2], len(s1): 2, cap(s1): 2\n[after] s1: [1 2 3 4 5], len(s1): 5, cap(s1): 6\n```\n\n{% endhideToggle %}\n\n\n\n### 切片作为函数参数\n\n`slice`本质是一个结构体，包含三个成员属性：`len`，`cap`，`array`\n\n当`slice`作为函数参数时，就是一个普通的结构体，直接传递`slice`，实参是不会被函数中的操作改变的，但是如果传的是`slice`指针，尽管`Go`并没有引用传递（都是值传递），但是因为指针实际指向的数据相同，所以函数内部的操作会影响实参\n\n\n\n>   什么是值传递，什么是引用传递\n>\n>   先说结论，`Go`语言中只有值传递，没有引用传递\n>\n>   值传递：形参都是实参的拷贝，函数内外参数的地址值是不同的\n>\n>   引用传递：那自然和值传递相反了，形参实参完全相同，就是一份数据\n\n\n\n明确了值传递和引用传递后，再来看以下代码的执行结果\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\n/*\nslice作为函数参数传递\n*/\n\nfunc main() {\n    s := []int{1, 1, 1}\n    // &s: 切片本身地址（指向切片这个结构体的指针）\n    // s: 切片指向的底层数组地址\n    // &s[0]: 切片指向的底层数组地址（数组是一片连续的地址空间，数组地址即为起始元素的地址）\n    fmt.Printf(\"[function main] &s: %p, s: %p, &s[0]: %p\\n\", &s, s, &s[0])\n    f(s)\n    fmt.Println(s)\n}\n\nfunc f(s []int) {\n    fmt.Printf(\"[function f] &s: %p, s: %p, &s[0]: %p\\n\", &s, s, &s[0])\n    for i := range s {\n        s[i] += 1\n    }\n}\n```\n\n\n\n{% hideToggle 运行结果 %}\n\n```\n[function main] &s: 0xc000096060, s: 0xc0000ae078, &s[0]: 0xc0000ae078\n[function f] &s: 0xc000096090, s: 0xc0000ae078, &s[0]: 0xc0000ae078\n[2 2 2]\n```\n\n{% endhideToggle %}\n\n\n\n#### 为什么函数内部的修改生效了\n\n从函数内外对切片地址的打印结果来看，`Go`参数传递就是值传递\n\n那么为什么能对函数外部的切片产生影响？\n\n原因在于切片本身也是保存了底层数组的指针，值传递的过程本质就是一个拷贝（浅拷贝），对于引用类型的（保存指针）的参数来说它的值就是地址（只不过这个地址又是指向的另一个空间/变量）\n\n所以这里的修改对函数外部生效\n\n\n\n包括其他类型，如`map`、`channel`等都是同一个原理\n\n\n\n#### 陷阱\n\n既然是因为底层数组的原因导致的修改生效，那么是否在函数内部触发了扩容（底层数组地址变更），修改对于外部的切片是否可见？\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\n/*\nslice作为函数参数传递\n*/\n\nfunc main() {\n\ts := []int{1}\n\t// &s: 切片本身地址（指向切片这个结构体的指针）\n\t// s: 切片指向的底层数组地址\n\t// &s[0]: 切片指向的底层数组地址（数组是一片连续的地址空间，数组地址即为起始元素的地址）\n\tfmt.Printf(\"[function main] s: %v, &s: %p, &(s->arr): %p, &s[0]: %p\\n\", s[0:cap(s)], &s, s, &s[0])\n\tf(s)\n\tfmt.Printf(\"[function main] s: %v, &s: %p, &(s->arr): %p, &s[0]: %p\\n\", s[0:cap(s)], &s, s, &s[0])\n\n\tfmt.Println()\n\n\t// 有多余空间的切片，验证不扩容情况下是否修改生效\n\ts = make([]int, 1, 4)\n\ts[0] = 1\n\tfmt.Printf(\"[function main] s: %v, &s: %p, &(s->arr): %p, &s[0]: %p\\n\", s[0:cap(s)], &s, s, &s[0])\n\t// 实际上没有扩容发生，所以函数内部打印地址的时候是不变的\n\tf(s)\n\t// 函数内部对于append操作成功修改底层的数组，外部是可以正常感知到的，修改生效\n\tfmt.Printf(\"[function main] s: %v, &s: %p, &(s->arr): %p, &s[0]: %p\\n\", s[0:cap(s)], &s, s, &s[0])\n}\n\nfunc f(s []int) {\n\t// 可以发现s的指针（地址）变化了，实际传递进来的是拷贝的新值（形参与实参的区别）\n\tfmt.Printf(\"[function f, before growing] s: %v, &s: %p, &(s->arr): %p, &s[0]: %p\\n\", s[0:cap(s)], &s, s, &s[0])\n\ts = append(s, 2, 3, 4)\n\tfmt.Printf(\"[function f, after growing] s: %v, &s: %p, &(s->arr): %p, &s[0]: %p\\n\", s[0:cap(s)], &s, s, &s[0])\n}\n\n```\n\n\n\n{% hideToggle 运行结果 %}\n\n```\n[function main] s: [1], &s: 0xc000004078, &(s->arr): 0xc00000a0a8, &s[0]: 0xc00000a0a8\n[function f, before growing] s: [1], &s: 0xc0000040c0, &(s->arr): 0xc00000a0a8, &s[0]: 0xc00000a0a8\n[function f, after growing] s: [1 2 3 4], &s: 0xc0000040c0, &(s->arr): 0xc000010200, &s[0]: 0xc000010200\n[function main] s: [1], &s: 0xc000004078, &(s->arr): 0xc00000a0a8, &s[0]: 0xc00000a0a8\n\n[function main] s: [1 0 0 0], &s: 0xc000004078, &(s->arr): 0xc000010220, &s[0]: 0xc000010220\n[function f, before growing] s: [1 0 0 0], &s: 0xc000004198, &(s->arr): 0xc000010220, &s[0]: 0xc000010220\n[function f, after growing] s: [1 2 3 4], &s: 0xc000004198, &(s->arr): 0xc000010220, &s[0]: 0xc000010220\n[function main] s: [1 2 3 4], &s: 0xc000004078, &(s->arr): 0xc000010220, &s[0]: 0xc000010220\n```\n\n{% endhideToggle %}\n\n\n\n<!-- TODO：和map又有不同？ -->\n\n\n\n### 并发支持\n\n`slice`没有做并发控制，并发环境下是不安全的，但是多个`goroutine`操作可能并不会出现问题\n\n而`map`则不同，运行时若检测到同一个`map`**同时**被多个`goroutine`引用并操作，程序会直接崩溃（如果刚好错开，则不会出现问题）\n\n\n\n## 参考资料\n\n>   [Go 语言数组的实现原理 | Go 语言设计与实现 (draveness.me)](https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-array/)\n>\n>   [Go 语言切片的实现原理 | Go 语言设计与实现 (draveness.me)](https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-array-and-slice/)\n>\n>   [切片的容量是怎样增长的 | Go 程序员面试笔试宝典 (golang.design)](https://golang.design/go-questions/slice/grow/)\n>\n>   [slice_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1hv411x7we?p=2)\n\n\n\n","tags":["Golang","编程语言"],"categories":["编程语言","Golang"]},{"title":"Linux-ps命令的使用","url":"/posts/6f16d83b/","content":"\n## ps\n\n*report a snapshot of the current processes.*\n\n统计当前进程运行情况\n\n\n\n### 概述\n\n`ps`命令的选项有三种风格\n\n>   This version of ps accepts several kinds of options:\n>\n>   ​\t\t1   UNIX options, which may be grouped and must be preceded by a dash.\n>\n>   ​\t\t2   BSD options, which may be grouped and must not be used with a dash.\n>\n>   ​\t\t3   GNU long options, which are preceded by two dashes.\n\n\n\n-   UNIX：可以分组，使用一个破折号（dash）开头\n\n    ```bash\n    $ ps -ef\n    ```\n\n-   BSD：可以分组，不使用破折号（dash）\n\n    ```bash\n    $ ps aux\n    ```\n\n-   GNU：不可以分组，使用两个破折号（dash）开头\n\n    ```bash\n    $ ps --user\n    ```\n\n\n\n#### `ps -aux`和`ps aux`是不一样的\n\n\n\n>   Note that \"ps -aux\" is distinct from \"ps aux\".  The POSIX and UNIX standards require that \"ps -aux\" print all processes owned by a\n>         user named \"x\", as well as printing all processes that would be selected by the -a option.  If the user named \"x\" does not exist, this\n>         ps may interpret the command as \"ps aux\" instead and print a warning.  This behavior is intended to aid in transitioning old scripts\n>         and habits.  It is fragile, subject to change, and thus should not be relied upon.\n\n\n\n`man`手册中明确提到`ps -aux`和`ps aux`是完全不同的\n\n在`POSIX`和`UNIX`标准中`ps -aux`会展示归属于用户`x`的所有的进程，只有在没有用户名为`x`的用户时，`ps -aux`被解释为`ps aux`，此时这两个命令才是等效的\n\n\n\n### 常用选项\n\n\n\n#### `-a`\n\n>   Select all processes except both session leaders (see getsid(2)) and processes not associated with a terminal.\n\n不是全部进程，排除了`session leaders`和那些没有关联到终端的进程\n\n\n\n>   没有关联到终端的进程可以简单理解（不完全正确）为后台进程，不由具体的某个终端前台运行\n\n\n\n```bash\n[root@crayon tmp]# ps -a\n  PID TTY          TIME CMD\n 2199 pts/0    00:00:00 tail\n 2416 pts/2    00:00:00 man\n 2425 pts/2    00:00:00 less\n 2906 pts/1    00:00:00 ps\n```\n\n\n\n`TTY`这行都有值，代表这些都是由具体某个终端\n\n\n\n>   关于**Linux会话、终端与进程组**可以参考\n>\n>   [Linux会话、终端与进程组 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/563471531)\n>\n>   [Linux TTY/PTS概述 - Linux程序员 - SegmentFault 思否](https://segmentfault.com/a/1190000009082089)\n>\n>   [Linux session和进程组概述 - Linux程序员 - SegmentFault 思否](https://segmentfault.com/a/1190000009152815)\n\n\n\n#### `-u`/`U`/`--user`\n\n>   -u userlist\n>                 Select by effective user ID (EUID) or name.  This selects the processes whose effective user name or ID is in userlist.\n>\n>   ​              The effective user ID describes the user whose file access permissions are used by the process (see geteuid(2)).  Identical to\n>   ​              U and --user.\n\n选择归属于指定用户id或用户名的进程\n\n\n\n#### `a`\n\n>   a      Lift the BSD-style \"only yourself\" restriction, which is imposed upon the set of all processes when some BSD-style (without\n>                 \"-\") options are used or when the ps personality setting is BSD-like.  The set of processes selected in this manner is in\n>                 addition to the set of processes selected by other means.  An alternate description is that this option causes ps to list all\n>                 **processes with a terminal (tty), or to list all processes when used together with the x option.**\n\n可以列出不属于当前用户的进程信息（解除**只列出归属于当前用户的进程**的限制）\n\n但是只能列出与终端关联的进程，也就是后台进程不会显示（需要使用`x`/`-x`选项）\n\n\n\n注意`man`手册中的最后一句\n\n>   `a`和`x`/`-x`选项组合使用即可打印所有进程的信息，和`-e`选项效果一样\n\n#### `x`/`-x`\n\n>x      Lift the BSD-style \"must have a tty\" restriction, which is imposed upon the set of all processes when some BSD-style (without\n>              \"-\") options are used or when the ps personality setting is BSD-like.  The set of processes selected in this manner is in\n>              addition to the set of processes selected by other means.  An alternate description is that this option causes ps to list all\n>              processes owned by you (same EUID as ps), or to list all processes when used together with the a option.\n\n可以列出非终端关联的进程信息（解除**只列出与终端关联的进程**的限制）\n\n但是只能列出归属于当前用户的进程，也就是其他用户的进程不会显示（需要使用`a`选项）\n\n\n\n#### `-e`/`-A`\n\n>   -e     Select all processes.  Identical to -A.\n>\n>   -A     Select all processes.  Identical to -e.\n\n列出所有进程信息\n\n\n\n#### `u`\n\n>   u      Display user-oriented format.\n\n`man`手册的原文解释是面向用户的格式化输出\n\n```bash\n[root@crayon tmp]# ps u\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot       681  0.0  0.0 110204   856 tty1     Ss+  14:03   \n...\nroot      3381  0.0  0.0 155448  1868 pts/1    R+   20:40   0:00 ps u\n```\n\n除了`USER`、`PID`外还包含了进程资源占用的信息\n\n\n\n#### `-f`/`-F`\n\n>   -f     Do full-format listing. This option can be combined with many other UNIX-style options to add additional columns.  It also\n>                 causes the command arguments to be printed.  When used with -L, the NLWP (number of threads) and LWP (thread ID) columns will\n>                 be added.  See the c option, the format keyword args, and the format keyword comm.\n>\n>   \n>\n>   -F     Extra full format.  See the -f option, which -F implies.\n\n`man`手册的原文解释是完整格式输出\n\n搭配`-L`选项还可以输出线程信息：`NLWP`线程数和`LWP`线程ID\n\n\n\n#### `-L`\n\n>   -L     Show threads, possibly with LWP and NLWP columns.\n\n显示线程信息\n\n`NLWP`：线程数\n\n`LWP`：线程ID\n\n\n\n#### `f`/`--forest`\n\n>   f      ASCII art process hierarchy (forest).\n>\n>   --forest\n>                 ASCII art process tree.\n\n树形结构输出，这个可以很方便的查看进程层级（父子关系）\n\n和`-H`的区别就是`-H`只是按照空行缩进\n\n而`f`/`--forest`会填充一些字符让结果更好看一点\n\n```bash\n[root@crayon tmp]# ps -ef --forest | head -n 5\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         2     0  0 14:02 ?        00:00:00 [kthreadd]\nroot         4     2  0 14:02 ?        00:00:00  \\_ [kworker/0:0H]\nroot         5     2  0 14:02 ?        00:00:00  \\_ [kworker/u2:0]\nroot         6     2  0 14:02 ?        00:00:03  \\_ [ksoftirqd/0]\n```\n\n\n\n#### `-H`\n\n>   -H     Show process hierarchy (forest).\n\n```bash\n[root@crayon tmp]# ps -efH\nroot      1088     1  0 14:03 ?        00:00:00   /usr/sbin/sshd -D\nroot      1787  1088  0 14:59 ?        00:00:02     sshd: root@pts/0\nroot      1791  1787  0 14:59 pts/0    00:00:00       -bash\nroot      2199  1791  0 15:11 pts/0    00:00:00         tail -f -n 100 /dev/null\nroot      2172  1088  0 15:11 ?        00:00:07     sshd: root@pts/1\nroot      2176  2172  0 15:11 pts/1    00:00:00       -bash\nroot      3413  2176  0 20:59 pts/1    00:00:00         ps -efH\nroot      3414  2176  0 20:59 pts/1    00:00:00         grep --color=auto -C 5 1088\nroot      2295  1088  0 15:30 ?        00:00:06     sshd: root@pts/2\nroot      2299  2295  0 15:30 pts/2    00:00:00       -bash\nroot      3097  2299  0 16:52 pts/2    00:00:00         man ps\nroot      3106  3097  0 16:52 pts/2    00:00:00           less -s\nroot      2371  1088  0 15:39 ?        00:00:01     sshd: root@pts/3\nroot      2375  2371  0 15:39 pts/3    00:00:00       -bash\nroot      1092     1  0 14:03 ?        00:00:07   /usr/sbin/rsyslogd -n\n```\n\n\n\n### 常用组合\n\n#### `ps -ef f`\n\n```bash\n[root@crayon tmp]# ps -ef f\nUID        PID  PPID  C STIME TTY      STAT   TIME CMD\nroot         2     0  0 14:02 ?        S      0:00 [kthreadd]\nroot         4     2  0 14:02 ?        S<     0:00  \\_ [kworker/0:0H]\nroot         5     2  0 14:02 ?        S      0:00  \\_ [kworker/u2:0]\nroot         6     2  0 14:02 ?        S      0:03  \\_ [ksoftirqd/0]\n...\n```\n\n按照进程层级以树形打印出所有进程信息\n\n\n\n#### `ps axuf`\n\n```bash\n[root@crayon tmp]# ps axu\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.0  0.3 128056  6728 ?        Ss   14:02   0:05 /usr/lib/systemd/systemd --switched-root --system --deserialize 22\nroot         2  0.0  0.0      0     0 ?        S    14:02   0:00 [kthreadd]\nroot         4  0.0  0.0      0     0 ?        S<   14:02   0:00 [kworker/0:0H]\nroot         5  0.0  0.0      0     0 ?        S    14:02   0:00 [kworker/u2:0]\n```\n\n按照进程层级以树形打印出所有进程的信息\n\n`ax`选项和`-e`/`-A`等效，都是列出所有的进程\n\n`u`选项面向用户打印出关键信息\n\n`u`和`-f`选项都是控制输出信息，会有冲突，按需选择互斥使用即可\n\n```bash\n[root@crayon tmp]# ps u -f\nerror: conflicting format options\n```\n\n\n\n`u`选项会输出进程资源的使用情况\n\n\n\n\n\n### 参考资料\n\n还有更多的使用细节可以参阅以下文章\n\n>    [较为平滑的 Linux ps 命令入门 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/674077333) \n\n","tags":["Linux"],"categories":["Linux"]},{"title":"Python性能分析实战1","url":"/posts/bf927dad/","content":"\n\n## 前置知识\n\n1. {% label Python green %}基础语法\n2. {% label cProfile purple %}基本使用\n\n\n## 问题\n环境上发现有接口请求的响应时间高达10s以上，严重影响功能的使用\n\n需要分析具体的代码执行耗时，针对问题代码进行优化，优化接口性能\n\n\n### 解决思路\n\n#### 分析代码执行情况\n\n使用 {% label cProfile purple %} 工具，将目标接口的代码执行情况`dump`到文件中\n\n```python\n\nwith cProfile.Profile() as pf:\n  # api business code\n  # ...\n  pf.dump_stats('api.prof')\n\n```\n\n\n获得`dump`文件后，使用 {% label snakeviz green %} 渲染方便查看\n\n```bash\n\nsnakeviz api.prof\n\n```\n执行命令后，{% label snakeviz green %} 会自动打开浏览器显示渲染后的结果\n\n![1705725581868](Python性能分析实战1.assets/1705725581866.png)\n\n\n可以看到接口中调用的`service`方法耗时长达10s左右，根据图示的调用栈可以看到耗时久主要是跟一个`decrypt`方法有关\n\n\n接下来到底下的搜索框过滤出关于`decrypt`相关的执行情况\n\n![1705682582062](Python性能分析实战1.assets/1705682582062.png)\n\n可以看到，`decrypt`相关的方法被调用37次，每次耗时`0.2s`左右\n\n`0.2s`算是比较耗时的操作了，这样耗时的代码逻辑居然还执行了37次，最终导致总耗时有`7s`之多\n\n\n#### 分析问题代码\n\n找到了可能有问题的代码位置，接下来就要看看对应的代码逻辑了\n\n{% note warning %}\n\n本文中代码涉及私密信息，仅以伪代码的方式进行讲解\n\n{% endnote %}\n\n`decrypt`实际上是一个解密的方法，解密算法需要进行大量的运算，这也解释了为什么这个操作单次就需要耗费`0.2s`了\n\n\n**为什么需要这个解密操作**\n\n这里实际上是对需要连接的中间件密码进行解密\n\n伪代码如下：\n\n```python\n\nclass MongoConfig:\n    @property\n    def mongo_password(self):\n        return decrypt(BaseConfig.cipher)\n\n```\n\n生产环境中的密码都是经过加密处理的，所以这里需要解密的操作\n\n那么就是说这个操作不可避免，也没有很大优化空间了\n\n\n这里就有个疑问了，既然只是一个密码解密的操作，且只是一个配置类，为什么需要调用那么多次，只需要在服务启动之时进行一次初始化的操作就可以了\n\n#### 尝试修复\n\n根据查看代码逻辑后分析的原因，尝试将解密的操作放到初始化的流程中，并使用`functools.cached_property`缓存计算结果（这样就可以保证只进行一次计算，后续直接从缓存获取结果）\n\n伪代码如下：\n```python\n\n    @functools.cached_property\n    def mongo_password(self):\n      return decrypt(BaseConfig.cipher)\n\n```\n\n#### 还没结束？\n\n代码修改后再次`dump`查看优化结果\n\n![1705728492283](Python性能分析实战1.assets/1705728492282.png)\n\n看起来优化的效果还是很明显的，但是接口仍然有`2s`的耗时，没有达到预期的效果\n\n分析耗时主要是在`service`中一个查询`instance`的方法，通过`id`查询 {% label Mongo green %}\n\n这里查询数据的操作就耗费了`2s`\n\n{% note info %}\n\n这里按道理如果这是个单独的一次查询，`2s`已经属于慢查询了，但是并没有接到慢查询的告警消息\n\n可以先猜测下原因\n\n{% endnote %}\n\n{% hideBlock 实际结果,, %}\n\n好吧，这里应该已经猜到了大概的原因了\n\n过滤下`mongo`和`cursor`关键字\n\n![1705729070489](Python性能分析实战1.assets/1705729070487.png)\n\n\n从表格的数据可以看到，其实单次的耗时都属于正常范围，问题出在调用次数上\n\n调用次数过多，导致最终累计耗时过长\n\n从`cursor.py`中`_refresh`和`__send_message`方法的调用次数也能看出有猫腻，单次接口（本身该接口并不返回大量数据）访问需要向`Mongo`请求近100次的数据，这显然不太合理\n\n#### 追根问底\n\n定位到问题代码\n\n以下展示伪代码：\n\n> 其实该接口获取`instance`这一步的操作非常简单，只需要根据`id`获取数据，并做一定的数据富化和转换即可\n\n```python\n\nfor id in ids:\n    instance =  InstanceColl().find_instance_by_id(id)\n    # 接下来是数据富化和转换的逻辑\n    # ...\n\n\n```\n\n这里很明显可以看到问题了，为了方便接下来的数据转换，直接对`ids`进行遍历并在循环内初始化`InstanceColl`去查询单个`id`的`instance`数据\n\n这就是为什么需要建立大量`Mongo`连接，多次请求`Mongo`获取数据\n\n\n#### 完成修复\n\n最终将循环单个查询`instance`的代码重写，直接使用`in`查询一次查询所有`instance`再进行数据封装后，接口响应时间优化到`200ms`\n\n\n\n{% endhideBlock %}","tags":["Python"],"categories":["编程语言","Python"]},{"title":"MongoDB副本集搭建","url":"/posts/fd4a1d37/","content":"\n\n## MongoDB副本集搭建\n\n\n### 概述\n> 本文参照 {% label MongoDB green %}官方文档（[https://www.mongodb.com/docs/manual/tutorial/deploy-replica-set/#std-label-server-replica-set-deploy](https://www.mongodb.com/docs/manual/tutorial/deploy-replica-set/#std-label-server-replica-set-deploy)）进行实践\n> 基于单机环境，启动3个`mongod`进程模拟搭建mongo副本集（replica set）\n\n#### 实践环境\n\n> 使用单台机器启动多个`mongod`进程模拟集群\n\n操作系统（OS）：\n```bash\n$ cat /etc/redhat-release \nCentOS Linux release 7.9.2009 (Core)\n```\n\n使用Docker构建Mongo环境\n\nDocker版本：\n\n```bash\n$ docker --version\nDocker version 1.13.1, build 7d71120/1.13.1\n```\n\nMongo镜像版本：\n```bash\n$ docker images | grep mongo\ndocker.io/mongo     4.2-bionic          e301407a044e        6 months ago        388 MB\n```\n\n{% note info %}\nCentOS7安装Docker教程：[https://cloud.tencent.com/developer/article/1701451](https://cloud.tencent.com/developer/article/1701451)\n{% endnote %}\n\n\n### 一些建议\n\n#### Hostnames\n\n{% note warning %}\n官方建议使用 {% label DNS purple %}代替直接使用 {% label IP purple %}地址来配置节点信息\n\n在 {% label MongoDB green %} 5.0开始，如果节点只配置一个 {% label IP purple %}地址则启动时就会校验并且无法启动\n\n{% hideBlock 官方原文,, %}\n> Use hostnames instead of IP addresses to configure clusters across a split network horizon. Starting in MongoDB 5.0, nodes that are only configured with an IP address will fail startup validation and will not start.\n\n{% endhideBlock %}\n{% endnote %}\n\n\n\n### 前置配置\n\n#### 配置域名映射\n分别为3个`mongod`进程的hostname配置域名映射\n\n```bash\n$ vim /etc/hosts\n```\n\n追加以下域名配置\n\n```\n127.0.0.1 mongodb0.example.net\n127.0.0.1 mongodb1.example.net\n127.0.0.1 mongodb2.example.net\n```\n\n\n\n#### 创建目录与文件\n\n##### 创建数据目录\n\n```bash\n$ mkdir /data/mongod0 /data/mongod1 /data/mongod2\n```\n\n##### 创建配置文件\n\n{% hideToggle 样例配置文件,, %}\n取自镜像中的配置模板文件`/etc/mongod.conf.orig`\n\n```yaml\n# mongod.conf\n\n# for documentation of all options, see:\n#   http://docs.mongodb.org/manual/reference/configuration-options/\n\n# Where and how to store data.\nstorage:\n  # 数据目录\n  dbPath: /data/mongod0\n#  engine:\n#  mmapv1:\n#  wiredTiger:\n\n# where to write logging data.\nsystemLog:\n  # 日志保存到文件\n  destination: file\n  # 如果日志文件存在则进行日志追加\n  logAppend: true\n  # 日志文件路径\n  path: /var/log/mongodb/mongod0.log\n\n# network interfaces\nnet:\n  port: 17000\n  bindIp: 0.0.0.0\n  # 和bindIp: ::,0.0.0.0效果相同\n  # bindIpAll: true\n\n# how the process runs\nprocessManagement:\n  # fork子进程的形式启动，此参数用于后台启动服务\n  fork: true\n\nreplication:\n   # 副本集名称，副本集部署必须填写，用于区分所属的副本集\n   replSetName: \"rs-example-0\"\n```\n\n{% endhideToggle %}\n\n\n\n根据模板配置文件，修改`storage.dbpath`、`systemLog.path`、`net.port`，分别给三个不同的`mongod`实例使用，例如：\n\n```bash\n$ ls -lh /etc/mongod\ntotal 12K\n-rw-r--r--. 1 root root 707 Sep 17 07:47 mongod0.conf\n-rw-r--r--. 1 root root 707 Sep 17 07:47 mongod1.conf\n-rw-r--r--. 1 root root 707 Sep 17 07:47 mongod2.conf\n```\n\n\n\n\n\n### 步骤\n\n#### 依次启动mongod进程\n\n\n\n```bash\n# 使用--config或-f参数指定配置文件\n$ mongod -f /etc/mongod/mongod0.conf\nabout to fork child process, waiting until server is ready for connections.\nforked process: 643\nchild process started successfully, parent exiting\n\n$ mongod -f /etc/mongod/mongod1.conf\nabout to fork child process, waiting until server is ready for connections.\nforked process: 692\nchild process started successfully, parent exiting\n\n$ mongod -f /etc/mongod/mongod2.conf\nabout to fork child process, waiting until server is ready for connections.\nforked process: 730\nchild process started successfully, parent exiting\n```\n\n\n\n```bash\n$ ps -ef | grep mongod\nroot       643     0  2 07:42 ?        00:00:12 mongod -f mongod0.conf\nroot       692     0  2 07:49 ?        00:00:00 mongod -f mongod1.conf\nroot       730     0  8 07:49 ?        00:00:01 mongod -f mongod2.conf\nroot       769     6  0 07:50 ?        00:00:00 grep mongod\n```\n\n成功启动三个`mongod`进程\n\n\n\n#### 连接其中一个mongod实例\n\n**Connect mongosh to one of the mongod instances.**\n\n{% note info %}\n\n官网使用`mongosh`的命令行工具进行连接，这里直接使用`mongo`的二进制工具，注意指定连接主机和端口，默认使用27017\n\n{% endnote %}\n\n尝试使用`mongo`命令连接`mongod0`实例\n\n```bash\n$ mongo --host mongodb0.example.net --port 17000\nMongoDB shell version v4.2.24\nconnecting to: mongodb://127.0.0.1:17000/?compressors=disabled&gssapiServiceName=mongodb\nImplicit session: session { \"id\" : UUID(\"f81fbaff-63d9-45fa-8043-8c5c6cf97105\") }\nMongoDB server version: 4.2.24\n...\n```\n\n连接成功\n\n\n\n#### 初始化副本集\n\n**Initiate the replica set.**\n\n{% note warning %}\n\n只需要在其中一个节点执行`rs.initiate()`\n\n{% endnote %}\n\n```bash\n> rs.initiate({\"_id\": \"rs-example-0\", \"members\": [{\"_id\": 0, \"host\": \"mongodb0.example.net:17000\"}]})\n{ \"ok\" : 1 }\nrs-example-0:OTHER> \n\nrs-example-0:PRIMARY> \n```\n\n以上步骤中，将`mongod0`实例加入到名为`rs-example-0`的副本集中，成功后观察到命令行提示符显示角色为 {% label OTHER purple %}，再次回车后则变为 {% label PRIMARY purple %}\n\n\n\n再使用`rs.add()`命令依次添加已有节点加入副本集\n\n```bash\nrs-example-0:PRIMARY> rs.add({\"_id\": 1, \"host\": \"mongodb1.example.net:17001\"})\n{\n        \"ok\" : 1,\n        \"$clusterTime\" : {\n                \"clusterTime\" : Timestamp(1694939436, 1),\n                \"signature\" : {\n                        \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n                        \"keyId\" : NumberLong(0)\n                }\n        },\n        \"operationTime\" : Timestamp(1694939436, 1)\n}\n\nrs-example-0:PRIMARY> rs.add({\"_id\": 2, \"host\": \"mongodb2.example.net:17002\"})\n{\n        \"ok\" : 1,\n        \"$clusterTime\" : {\n                \"clusterTime\" : Timestamp(1694939337, 1),\n                \"signature\" : {\n                        \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n                        \"keyId\" : NumberLong(0)\n                }\n        },\n        \"operationTime\" : Timestamp(1694939337, 1)\n}\n```\n\n\n\n{% note info %}\n\n也可以用`rs.initiate()`传入所有节点信息直接完成初始化\n\n{% endnote %}\n\n\n\n##### 常见问题\n\n###### 空参调用`rs.initiate()`报错，`hostname`配置错误\n\n```bash\n> rs.initiate()\n{\n        \"ok\" : 0,\n        \"errmsg\" : \"No host described in new configuration 1 for replica set rs-example-0 maps to this node\",\n        \"code\" : 93,\n        \"codeName\" : \"InvalidReplicaSetConfig\"\n}\n```\n\n\n\n解析：当空参调用时，mongodb使用本机的`hostname`作为默认的配置，如果`hostname`无法作为DNS解析的话，那么就会报找不到对应的主机\n\n\n\n查询本机`hostname`配置\n\n```bash\n# 当前配置\n$ hostname\nCrayon\n\n# 修改\n$ hostname mongodb0.example.net\n\n# 查看是否修改成功\n$ hostname\nmongodb0.example.net\n```\n\n\n\n再次执行`rs.initiate()`\n\n```bash\n> rs.initiate()\n{\n        \"info2\" : \"no configuration specified. Using a default configuration for the set\",\n        \"me\" : \"mongodb0.example.net:17000\",\n        \"ok\" : 1\n}\n```\n\n\n\n\n\n###### 缺少`members`参数\n\n```bash\n> rs.initiate({_id: \"rs\"})\n{\n        \"ok\" : 0,\n        \"errmsg\" : \"Missing expected field \\\"members\\\"\",\n        \"code\" : 93,\n        \"codeName\" : \"InvalidReplicaSetConfig\"\n}\n```\n\n添加`members`参数即可\n\n\n\n###### `_id`与配置文件中的副本集名称不一致\n\n```bash\n> rs.initiate({_id: \"rs\", \"members\": []})\n{\n        \"ok\" : 0,\n        \"errmsg\" : \"Attempting to initiate a replica set with name rs, but command line reports rs-example-0; rejecting\",\n        \"code\" : 93,\n        \"codeName\" : \"InvalidReplicaSetConfig\"\n}\n```\n\n\n\n###### 副本集节点数不足\n\n```bash\n> rs.initiate({\"_id\": \"rs-example-0\", \"members\": []})\n{\n        \"ok\" : 0,\n        \"errmsg\" : \"Replica set configuration contains 0 members, but must have at least 1 and no more than  50\",\n        \"code\" : 93,\n        \"codeName\" : \"InvalidReplicaSetConfig\"\n}\n```\n\n副本集要求至少1个节点，至多50个节点\n\n\n\n##### 查看副本集配置\n\n**View the replica set configuration.**\n\n使用`rs.conf()`可以查看当前节点所在副本集的配置信息\n\n{% hideToggle 点我展开,, %}\n\n```bash\nrs-example-0:PRIMARY> rs.conf()\n{\n        \"_id\" : \"rs-example-0\",\n        \"version\" : 5,\n        \"protocolVersion\" : NumberLong(1),\n        \"writeConcernMajorityJournalDefault\" : true,\n        \"members\" : [\n                {\n                        \"_id\" : 0,\n                        \"host\" : \"mongodb0.example.net:17000\",\n                        \"arbiterOnly\" : false,\n                        \"buildIndexes\" : true,\n                        \"hidden\" : false,\n                        \"priority\" : 1,\n                        \"tags\" : {\n\n                        },\n                        \"slaveDelay\" : NumberLong(0),\n                        \"votes\" : 1\n                },\n                {\n                        \"_id\" : 2,\n                        \"host\" : \"mongodb2.example.net:17002\",\n                        \"arbiterOnly\" : false,\n                        \"buildIndexes\" : true,\n                        \"hidden\" : false,\n                        \"priority\" : 1,\n                        \"tags\" : {\n\n                        },\n                        \"slaveDelay\" : NumberLong(0),\n                        \"votes\" : 1\n                },\n                {\n                        \"_id\" : 1,\n                        \"host\" : \"mongodb1.example.net:17001\",\n                        \"arbiterOnly\" : false,\n                        \"buildIndexes\" : true,\n                        \"hidden\" : false,\n                        \"priority\" : 1,\n                        \"tags\" : {\n\n                        },\n                        \"slaveDelay\" : NumberLong(0),\n                        \"votes\" : 1\n                }\n        ],\n        \"settings\" : {\n                \"chainingAllowed\" : true,\n                \"heartbeatIntervalMillis\" : 2000,\n                \"heartbeatTimeoutSecs\" : 10,\n                \"electionTimeoutMillis\" : 10000,\n                \"catchUpTimeoutMillis\" : -1,\n                \"catchUpTakeoverDelayMillis\" : 30000,\n                \"getLastErrorModes\" : {\n\n                },\n                \"getLastErrorDefaults\" : {\n                        \"w\" : 1,\n                        \"wtimeout\" : 0\n                },\n                \"replicaSetId\" : ObjectId(\"6506b39ed951f6176dfb632d\")\n        }\n}\n```\n\n{% endhideToggle %}\n\n\n##### 查看副本集状态\n\n使用`rs.status()`可以查看当前副本集状态\n\n{% hideToggle 点我展开,, %}\n\n```bash\nrs-example-0:SECONDARY> rs.status()\n{\n        \"set\" : \"rs-example-0\",\n        \"date\" : ISODate(\"2023-09-17T08:49:41.493Z\"),\n        \"myState\" : 2,\n        \"term\" : NumberLong(1),\n        \"syncingTo\" : \"mongodb0.example.net:17000\",\n        \"syncSourceHost\" : \"mongodb0.example.net:17000\",\n        \"syncSourceId\" : 0,\n        \"heartbeatIntervalMillis\" : NumberLong(2000),\n        \"majorityVoteCount\" : 2,\n        \"writeMajorityCount\" : 2,\n        \"optimes\" : {\n                \"lastCommittedOpTime\" : {\n                        \"ts\" : Timestamp(1694940575, 1),\n                        \"t\" : NumberLong(1)\n                },\n                \"lastCommittedWallTime\" : ISODate(\"2023-09-17T08:49:35.387Z\"),\n                \"readConcernMajorityOpTime\" : {\n                        \"ts\" : Timestamp(1694940575, 1),\n                        \"t\" : NumberLong(1)\n                },\n                \"readConcernMajorityWallTime\" : ISODate(\"2023-09-17T08:49:35.387Z\"),\n                \"appliedOpTime\" : {\n                        \"ts\" : Timestamp(1694940575, 1),\n                        \"t\" : NumberLong(1)\n                },\n                \"durableOpTime\" : {\n                        \"ts\" : Timestamp(1694940575, 1),\n                        \"t\" : NumberLong(1)\n                },\n                \"lastAppliedWallTime\" : ISODate(\"2023-09-17T08:49:35.387Z\"),\n                \"lastDurableWallTime\" : ISODate(\"2023-09-17T08:49:35.387Z\")\n        },\n        \"lastStableRecoveryTimestamp\" : Timestamp(1694940515, 1),\n        \"lastStableCheckpointTimestamp\" : Timestamp(1694940515, 1),\n        \"members\" : [\n                {\n                        \"_id\" : 0,\n                        \"name\" : \"mongodb0.example.net:17000\",\n                        \"health\" : 1,\n                        \"state\" : 1,\n                        \"stateStr\" : \"PRIMARY\",\n                        \"uptime\" : 1144,\n                        \"optime\" : {\n                                \"ts\" : Timestamp(1694940575, 1),\n                                \"t\" : NumberLong(1)\n                        },\n                        \"optimeDurable\" : {\n                                \"ts\" : Timestamp(1694940575, 1),\n                                \"t\" : NumberLong(1)\n                        },\n                        \"optimeDate\" : ISODate(\"2023-09-17T08:49:35Z\"),\n                        \"optimeDurableDate\" : ISODate(\"2023-09-17T08:49:35Z\"),\n                        \"lastHeartbeat\" : ISODate(\"2023-09-17T08:49:41.167Z\"),\n                        \"lastHeartbeatRecv\" : ISODate(\"2023-09-17T08:49:40.819Z\"),\n                        \"pingMs\" : NumberLong(0),\n                        \"lastHeartbeatMessage\" : \"\",\n                        \"syncingTo\" : \"\",\n                        \"syncSourceHost\" : \"\",\n                        \"syncSourceId\" : -1,\n                        \"infoMessage\" : \"\",\n                        \"electionTime\" : Timestamp(1694938014, 2),\n                        \"electionDate\" : ISODate(\"2023-09-17T08:06:54Z\"),\n                        \"configVersion\" : 5\n                },\n                {\n                        \"_id\" : 1,\n                        \"name\" : \"mongodb1.example.net:17001\",\n                        \"health\" : 1,\n                        \"state\" : 2,\n                        \"stateStr\" : \"SECONDARY\",\n                        \"uptime\" : 1178,\n                        \"optime\" : {\n                                \"ts\" : Timestamp(1694940575, 1),\n                                \"t\" : NumberLong(1)\n                        },\n                        \"optimeDate\" : ISODate(\"2023-09-17T08:49:35Z\"),\n                        \"syncingTo\" : \"mongodb0.example.net:17000\",\n                        \"syncSourceHost\" : \"mongodb0.example.net:17000\",\n                        \"syncSourceId\" : 0,\n                        \"infoMessage\" : \"\",\n                        \"configVersion\" : 5,\n                        \"self\" : true,\n                        \"lastHeartbeatMessage\" : \"\"\n                },\n                {\n                        \"_id\" : 2,\n                        \"name\" : \"mongodb2.example.net:17002\",\n                        \"health\" : 1,\n                        \"state\" : 2,\n                        \"stateStr\" : \"SECONDARY\",\n                        \"uptime\" : 1144,\n                        \"optime\" : {\n                                \"ts\" : Timestamp(1694940575, 1),\n                                \"t\" : NumberLong(1)\n                        },\n                        \"optimeDurable\" : {\n                                \"ts\" : Timestamp(1694940575, 1),\n                                \"t\" : NumberLong(1)\n                        },\n                        \"optimeDate\" : ISODate(\"2023-09-17T08:49:35Z\"),\n                        \"optimeDurableDate\" : ISODate(\"2023-09-17T08:49:35Z\"),\n                        \"lastHeartbeat\" : ISODate(\"2023-09-17T08:49:41.167Z\"),\n                        \"lastHeartbeatRecv\" : ISODate(\"2023-09-17T08:49:41.170Z\"),\n                        \"pingMs\" : NumberLong(0),\n                        \"lastHeartbeatMessage\" : \"\",\n                        \"syncingTo\" : \"mongodb0.example.net:17000\",\n                        \"syncSourceHost\" : \"mongodb0.example.net:17000\",\n                        \"syncSourceId\" : 0,\n                        \"infoMessage\" : \"\",\n                        \"configVersion\" : 5\n                }\n        ],\n        \"ok\" : 1,\n        \"$clusterTime\" : {\n                \"clusterTime\" : Timestamp(1694940575, 1),\n                \"signature\" : {\n                        \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n                        \"keyId\" : NumberLong(0)\n                }\n        },\n        \"operationTime\" : Timestamp(1694940575, 1)\n}\n```\n\n{% endhideToggle %}\n\n\n\n#### 关闭mongod进程\n\n##### mongo命令\n\n使用`mongo`命令连接到`mongod`后，使用\n\n```bash\n# 切换到admin库\nrs-example-0:SECONDARY> use admin\nrs-example-0:SECONDARY> db.shutdownServer()\n\n```\n\n{% note info %}\n\n需要先切换到`admin`库\n\n{% endnote %}\n\n\n\n执行完毕后`mongo`命令会自动断开与`mongod`的连接\n\n会有以下日志报错\n\n{% hideToggle 点击展开,, %}\n\n\n\n```bash\n2023-12-23T14:53:57.358+0000 I  NETWORK  [js] DBClientConnection failed to receive message from mongodb2.example.net:17002 - HostUnreachable: Connection closed by peer\nserver should be down...\n2023-12-23T14:53:57.360+0000 I  NETWORK  [js] trying reconnect to mongodb2.example.net:17002 failed\n2023-12-23T14:53:57.360+0000 I  NETWORK  [js] reconnect mongodb2.example.net:17002 failed failed \n> exit\nbye\n2023-12-23T14:53:58.363+0000 I  NETWORK  [js] trying reconnect to mongodb2.example.net:17002 failed\n2023-12-23T14:53:58.363+0000 I  NETWORK  [js] reconnect mongodb2.example.net:17002 failed failed \n2023-12-23T14:53:58.363+0000 I  QUERY    [js] Failed to end session { id: UUID(\"2135374c-738d-4033-be37-87d9292704b4\") } due to SocketException: socket exception [CONNECT_ERROR] server [couldn't connect to server mongodb2.example.net:17002, connection attempt failed: SocketException: Error connecting to mongodb2.example.net:17002 (127.0.0.1:17002) :: caused by :: Connection refused]\n```\n\n\n\n{% endhideToggle %}\n\n\n\n##### mongod命令\n\n直接使用`mongod`命令\n\n```bash\n$ mongod -f [config] --shutdown\n```\n\n{% note info %}\n\n 需要指定`-f`或`--config`参数指定配置文件（`-f`和`--config`等效）\n\n或者`--dbpath` 指定数据库文件路径（其实`-f`/`--config`也是通过读取`dbpath`的参数获取了数据库文件路径）\n\n本质上原理是相同的，都是通过`dbpath`下面的`mongod.lock`文件获取实例进程发送信号退出进程\n\n```bash\n$ cat /data/mongod0/mongod.lock\n276\n```\n\n\n\n\n\n{% endnote %}","tags":["数据库","NoSQL","MongoDB"],"categories":["MongoDB"]},{"title":"LC-17-电话号码的字母组合","url":"/posts/6fe015cf/","content":"\n## 电话号码的字母组合\n\nLeetCode题目链接：[17. 电话号码的字母组合 - 力扣（LeetCode）](https://leetcode.cn/problems/letter-combinations-of-a-phone-number/description/)\n\n难度：{% label 中等 orange %}\n\n\n\n### 分析\n\n本题属于典型的递归回溯的题型，根据数字查找可使用的字母，在进行遍历递归回溯组合出所有可能的组合即可\n\n![1688805900848](LC-17-电话号码的字母组合.assets/1688805900848.png)  \n\n\n### 思路\n\n>   1.  递归纵向遍历数字串（递归过程中当前遍历的索引即可实现递归纵向遍历）\n>   2.  根据数字取出对应的字母集合\n>   3.  遍历该集合组合结果\n>\n>   递归结束条件：当结果集中的字母和所给数字一样多时，即遍历结束\n\n\n\n{% hideToggle 点我展开,, %}\n\n{% tabs 代码 %}\n\n<!-- tab Golang -->\n\n```go\nconst (\n    CHAR_ONE   = '1'\n    CHAR_TWO   = '2'\n    CHAR_THREE = '3'\n    CHAR_FOUR  = '4'\n    CHAR_FIVE  = '5'\n    CHAR_SIX   = '6'\n    CHAR_SEVEN = '7'\n    CHAR_EIGHT = '8'\n    CHAR_NINE  = '9'\n)\n\nvar (\n    ONE_LETTERS   = []uint8{}\n    TWO_LETTERS   = []uint8{'a', 'b', 'c'}\n    THREE_LETTERS = []uint8{'d', 'e', 'f'}\n    FOUR_LETTERS  = []uint8{'g', 'h', 'i'}\n    FIVE_LETTERS  = []uint8{'j', 'k', 'l'}\n    SIX_LETTERS   = []uint8{'m', 'n', 'o'}\n    SEVEN_LETTERS = []uint8{'p', 'q', 'r', 's'}\n    EIGHT_LETTERS = []uint8{'t', 'u', 'v'}\n    NINE_LETTERS  = []uint8{'w', 'x', 'y', 'z'}\n)\n\nvar NUM_LETTERS_COR_MAP = map[uint8][]uint8{\n    CHAR_ONE:   ONE_LETTERS,\n    CHAR_TWO:   TWO_LETTERS,\n    CHAR_THREE: THREE_LETTERS,\n    CHAR_FOUR:  FOUR_LETTERS,\n    CHAR_FIVE:  FIVE_LETTERS,\n    CHAR_SIX:   SIX_LETTERS,\n    CHAR_SEVEN: SEVEN_LETTERS,\n    CHAR_EIGHT: EIGHT_LETTERS,\n    CHAR_NINE:  NINE_LETTERS,\n}\n\nfunc recurve(digits string, ret *[]string, index int, cur []uint8) {\n    if index == len(digits){\n        // 递归结束，加入结果集\n        if len(cur) > 0 {\n            *ret = append(*ret, string(cur))\n        }\n        return\n    }\n\n    digit := digits[index]\n    letters := NUM_LETTERS_COR_MAP[digit]\n    for _, letter := range letters {\n        recurve(digits, ret, index+1, append(cur, letter))\n    }\n}\n\nfunc letterCombinations(digits string) []string {\n    var ret []string\n    recurve(digits, &ret, 0, []uint8{})\n    return ret\n}\n```\n\n<!-- endtab -->\n\n<!-- tab Java -->\n\n```java\n\n```\n\n<!-- endtab -->\n\n{% endtabs %}\n\n{% endhideToggle %}\n\n","tags":["LeetCode","算法-回溯"],"categories":["算法","回溯"]},{"title":"1.1-容器的基本操作和实现原理","url":"/posts/dee5f7cb/","content":"\n## 容器的基本操作和实现原理\n\n### 容器是什么\n镜像就是一个特殊的**文件系统**\n它提供了容器中程序执行需要的所有文件。具体来说就是应用程序想要启动，需要三类文件：\n- 相关的程序可执行文件、库文件和配置文件\n\n这三类文件都被容器打包好了\n这样，在容器运行的时候就不再依赖宿主机上的文件操作系统类型和配置了\n\n从用户使用的角度来看，容器和一台独立的机器或者虚拟机没有什么太大的区别\n但是它和虚拟机相比，却没有各种复杂的**硬件虚拟层**，没有独立的Linux内核\n\n容器的所有进程调度、内存访问、文件读写都是直接跑在宿主机的内核之上的。\n\n### 如何实现的\n两个术语\n1. Namespace\n2. Cgroups\n\n这两项技术可以让程序在一个资源可控的独立（隔离）环境中运行，这个就是容器了。\n\n#### Namespace\n查看docker容器中的进程情况\n```bash\n$ docker exec <containerID> ps -ef\nPID   USER     TIME  COMMAND\n    1 root      0:00 nginx: master process nginx -g daemon off;\n   24 nginx     0:01 nginx: worker process\n   25 root      0:00 ps -ef\n```\n直接在宿主机执行`ps -ef | grep nginx`也可以看到这几个进程\n```bash\n$ ps -ef | grep nginx\nroot       818   760  0 Jan18 ?        00:00:00 nginx: master process nginx -g daemon off;\nsystemd+   921   818  0 Jan18 ?        00:00:01 nginx: worker process\nroot      1305  1276  0 Jan18 ?        00:00:00 nginx: master process nginx -g daemon off;\nroot      1367  1305  0 Jan18 ?        00:00:00 nginx: worker process\n```\n\n![1674991583875](容器实战.assets/1674991583875.png)\n\nLinux在创建容器的时候，就会创建一个`PID Namespace`，会单独对进程进行PID的编号（每个Namespace的PID编号都是从1开始的）。\n在这个`PID Namespace`中是看不到其他Namespace里的进程的。\n\n而在宿主机上的`Host PID Namespace`，它是其他Namespace的父Namespace，可以看到这台机器上的所有进程，不过进程编号不是`Container PID Namespace`里的编号了。\n\nNamespace其实就是一种隔离机制，主要目的是隔离运行在同一个宿主机上的容器，让这些容器之间不能访问彼此的资源。\n\n作用：\n1. 可以充分利用系统的资源，同一台宿主机上可以运行多个用户的容器\n2. 保证安全性，因为不同用户之间不能访问对方的资源\n\nNamespace类型：\n- Cgroup\n- IPC\n- Network\n- Mount\n- PID\n- Time\n- User\n- UTS\n\n![1674992082859](容器实战.assets/1674992082859.png)\n\n\n#### Cgroups\n\nCgroups（Control Groups）\n可以对指定的进程做各种计算机资源的限制，比如限制CPU的使用率、内存使用量、IO设备的流量等等。\n\n> Cgroups定义：\n>\n\n几种常用的Cgroups子系统：\n- cpu子系统，用来限制一个控制组（一组进程，可以理解为一个容器里面的所有进程）可使用的最大CPU\n- memory子系统，用来限制一个控制组最大的内存使用量\n- pids子系统，用来限制一个控制组里最多可以运行多少个进程\n- cpuset子系统，用来限制一个控制组里的进程可以在哪几个物理CPU上运行\n\n> Cgroups有v1和v2两个版本：\n> v1在Linux中很早就实现了，各种子系统比较独立，每个进程在各个Cgroups子系统中独立配置，**可以属于不同的group**。\n> \n> 虽然这样比较灵活，但是会导致**对同一进程的资源协调比较困难**。虽然v1有缺陷，但是生产环境中大部分还是使用的v1。\n\n#### 总结\nNamespace帮助容器来实现各种计算资源的隔离\n\nCgroups主要限制容器能够使用的资源量","tags":["Docker","Linux","Namespace","Cgroups"],"categories":["容器实战"]},{"title":"Windows激活","url":"/posts/22b15887/","content":"\n\n## Windows激活\n\n### Windows7\n\n#### 专业版\n1. 管理员身份启动`cmd`\n2. 输入`slmgr /skms kms.xspace.in`\n3. 输入`slmgr /ipkvk 7jg-NPHTm-C97Jm-9mPgT-3V66T`\n4. 输入`slmgr /ato`\n\n激活成功\n\n#### 企业版\n1. 管理员身份启动`cmd`\n2. 输入`slmgr /skms kms.03k.org`\n3. 输入`slmgr /ipk 33PXH-7Y6KF-2VJC9-XBBR8-HVTHH`\n4. 输入`slmgr /ato`\n\n激活成功","tags":["Windows"],"categories":["待归档"]},{"title":"LC-165-比较版本号","url":"/posts/c4d24896/","content":"\n\n\n## 比较版本号\n\nLeetCode题目链接：[165. 比较版本号 - 力扣（LeetCode）](https://leetcode.cn/problems/compare-version-numbers/description/)\n\n难度：{% label 中等 orange %}\n\n\n\n### 分析\n\n\n\n### 思路\n\n>   直接通过`.`切分字符串，遍历数组，直接使用内置函数将字符串转为数字进行比较，如果相等就继续比较，如果不等就直接返回结果\n>\n>   对于版本号长度不等的情况，只需将缺少的项视为0然后正常进行比较就行\n\n{% hideToggle 点我展开,, %}\n\n{% tabs 代码一, 1 %}\n\n<!-- tab Java -->\n\n```java\nclass Solution {\n    public int compareVersion(String version1, String version2) {\n        String[] arr1 = version1.split(\"\\\\.\");\n        String[] arr2 = version2.split(\"\\\\.\");\n        int ret = 0;\n        for (int i = 0;i < Math.max(arr1.length, arr2.length);i++) {\n            // 默认为0\n            int x = 0;\n            int y = 0;\n            // 没有指定版本号的话就不会走这段逻辑，所以就会用0做默认值参与比较\n            if (i < arr1.length) {\n                x = Integer.parseInt(arr1[i]);\n            }\n            if (i < arr2.length) {\n                y = Integer.parseInt(arr2[i]);\n            }\n            if (x != y) {\n                ret = x > y ? 1 : -1;\n                break;\n            }\n        }\n\n        return ret;\n    }\n}\n```\n\n<!-- endtab -->\n\n<!-- tab Golang -->\n\n```go\nfunc compareVersion(version1 string, version2 string) int {\n    var (\n        slice1 = strings.Split(version1, \".\")\n        slice2 = strings.Split(version2, \".\")\n    )\n    \n    for i := 0;i < len(slice1) || i < len(slice2);i++ {\n        x := 0\n        y := 0\n\n        if i < len(slice1) {\n            // 这里的err需要根据实际情况做异常处理\n            x, _ = strconv.Atoi(slice1[i])\n        }\n\n        if i < len(slice2) {\n            // 这里的err需要根据实际情况做异常处理\n            y, _ = strconv.Atoi(slice2[i])\n        }\n\n        if x > y {\n            return 1\n        }\n        if x < y {\n            return -1\n        }\n    }\n\n    return 0\n}\n```\n\n<!-- endtab -->\n\n{% endtabs %}\n\n{% endhideToggle %}\n\n#### 优化\n\n采用`.`切分字符串需要使用数组来保存切分的结果来遍历\n\n可以使用{% label 双指针 %}直接遍历字符串进行比较\n\n{% hideToggle 点我展开,, %}\n\n{% tabs 代码二, 1 %}\n\n<!-- tab Java -->\n\n```java\nclass Solution {\n    public int compareVersion(String version1, String version2) {\n        int i = 0;\n        int j = 0;\n        while (i < version1.length() || j < version2.length()) {\n            int x = 0;\n            int y = 0;\n\n            while(i < version1.length()) {\n                if (version1.charAt(i) == '.') {\n                    i++;\n                    break;\n                }\n                // 其实也是转成数字进行比较\n                x = 10 * x + version1.charAt(i) - '0';\n                i++;\n            }\n\n            while(j < version2.length()) {\n                if (version2.charAt(j) == '.') {\n                    j++;\n                    break;\n                }\n                y = 10 * y + version2.charAt(j) - '0';\n                j++;\n            }\n\n            if (x > y) {\n                return 1;\n            }\n            if (x < y) {\n                return -1;\n            }\n        }\n\n        return 0;\n    }\n}\n```\n\n<!-- endtab -->\n\n<!-- tab Golang -->\n\n```go\nfunc compareVersion(version1 string, version2 string) int {\n    var (\n        i = 0\n        j = 0\n    )\n\n    for ;i < len(version1) || j < len(version2); {\n        var (\n            x = 0\n            y = 0\n        )\n        for ;i < len(version1) && version1[i] != '.';i++ {\n            x = 10 * x + int(version1[i] - '0')\n        }\n        i++;\n        for ;j < len(version2) && version2[j] != '.';j++ {\n            y = 10 * y + int(version2[j] - '0')\n        }\n        j++;\n\n        if x > y {\n            return 1\n        }\n        if x < y {\n            return -1\n        }\n    }\n    return 0\n}\n```\n\n<!-- endtab -->\n\n{% endtabs %}\n\n{% endhideToggle %}\n\n### 拓展\n\n>   根据国际主流的惯例，我们使用「语义化版本（Semantic Versioning）」的命名方式，有时简称 SemVer。语义化版本号（以下简称「版本号」）的格式是：`<major>.<minor>.<patch>`。即使用三位非负整数，以点号`.`连接。\n>\n>   -   `<major>`即主版本号，俗称大版本升级。改动到主版本号时，标志着 API 发生了巨大变化，包括但不限于新增特性、修改机制、删除功能， 一般不兼容上一个主版本号。\n>   -   `<minor>`即次版本号，俗称小版本升级。当我们进行常规的新增或修改功能时，改动次版本号，但是必须是向前兼容的。这也意味着我们不能直接删除某个功能。如若必要，我们可以在修改日志中标记某项功能为「即将删除（Deprecated）」，然后在下一个大版本中将其彻底删除。\n>   -   `<patch>`即修订号，俗称 bug 修复。顾名思义，如果仅仅为了修复或调整一些小问题，我们就只改动修订号。\n\n参考文章：https://blog.csdn.net/qq_35246620/article/details/78443169\n\n\n\n实际开发中，有时也会给版本号后添加`-<6位commitID>`唯一标识某个版本的提交\n","tags":["LeetCode","算法-字符串","算法-双指针"],"categories":["算法","字符串"]},{"title":"Hexo-Butterfly手册","url":"/posts/1f69cb6c/","content":"\n\n\n\n\n## 图标\nButterfly支持[font-awesome v6](https://fontawesome.com/icons?from=io)图标\n\n![20220831165924991](images/posts-assets/Hexo-Butterfly手册.assets/20220831165924991.jpg)\n\n\n\n![20220831165948029](images/posts-assets/Hexo-Butterfly手册.assets/20220831165948029.jpg)\n\n## 标签外挂\n\n### Note（Bootstrap Callout）\n\n{% note primary no-icon %}\nNote（Bootstrap Callout）\n{% endnote %}\n\n#### 配置参数\n\n| 名称    | 用法                                                         |\n| ------- | ------------------------------------------------------------ |\n| class   | 【可选】标识/颜色，可选值（ `default` / `primary` / `success` / `info` / `warning` / `danger` ） |\n| no-icon | 【可选】填写该项则不显示icon                                 |\n| style   | 【可选】覆盖配置中的style，可选值（ `simple` / `modern` / `flat` / `disabled` ） |\n| color   | 【可选】颜色，可选值（ `default` / `blue` / `pink` / `red` / `purple` / `orange` / `green` ） |\n| icon    | 【可选】可配置自定义 icon (只支持 fontawesome 图标, 也可以配置 no-icon ) |\n\n#### 用法\n\n{% tabs note-grammar %}\n\n<!-- tab 用法1 -->\n\n```bash\n{% note [class] [no-icon] [style] %}\nAny content (support inline tags too.io).\n{% endnote %}\n```\n\n效果：\n\n{% note primary %}\nAny content (support inline tags too.io).\n{% endnote %}\n\n<!-- endtab -->\n\n<!-- tab 用法2 -->\n\n```bash\n{% note [color] [icon] [style] %}\nAny content (support inline tags too.io).\n{% endnote %}\n```\n\n效果：\n\n{% note purple no-icon %}\n\nAny content (support inline tags too.io).\n\n{% endnote %}\n\n<!-- endtab -->\n\n{% endtabs %}\n\n\n\n### 旧Gallery（相册图库）\n\n#### 配置参数\n\n| 名称        | 说明             |\n| ----------- | ---------------- |\n| name        | 名称             |\n| description | 描述             |\n| link        | 链接到的相册地址 |\n| img-url     | 封面地址         |\n\n#### 用法\n\n```html\n<div class=\"gallery-group-main\">\n    {% galleryGroup '壁纸' '收藏的一些壁纸' '/gallery/wallpaper' 'https://i.loli.net/2019/11/10/T7Mu8Aod3egmC4Q.png' %}\n    {% galleryGroup '漫威' '关于漫威的图片' '/gallery/marvel' 'https://i.loli.net/2019/12/25/8t97aVlp4hgyBGu.jpg' %}\n</div>\n```\n\n效果：\n\n<div class=\"gallery-group-main\">\n    {% galleryGroup '壁纸' '收藏的一些壁纸' '/gallery/wallpaper' 'https://i.loli.net/2019/11/10/T7Mu8Aod3egmC4Q.png' %}\n    {% galleryGroup '漫威' '关于漫威的图片' '/gallery/marvel' 'https://i.loli.net/2019/12/25/8t97aVlp4hgyBGu.jpg' %}\n</div>\n\n\n\n### 新Gallery相册\n\n区别于旧Gallery相册，新Gallery会根据图片的长度进行自动排版\n\n#### 用法\n\n```bash\n{% gallery %}\nmarkdown图片格式\n{% endgallery %}\n```\n\n效果：\n\n{% gallery %}\n\n![](https://i.loli.net/2019/11/10/T7Mu8Aod3egmC4Q.png)\n\n![](https://i.loli.net/2019/12/25/8t97aVlp4hgyBGu.jpg)\n\n{% endgallery %}\n\n\n\n### Tag-Hide（隐藏、收缩）\n\n{% hideToggle 用法 %}\n\n{% note warning %}\n\n注意：display中不能包含英文逗号，需要用`&sbquo;`代替\n\n{% endnote %}\n\n{% tabs tag-hide-grammar %}\n\n<!-- tab Inline（隐藏单行文本） -->\n\n只限隐藏文字\n\n用法：\n\n```bash\n{% hideInline content, display, bg, color %}\n```\n\n-   content：文本内容\n-   display：【可选】按钮显示文字\n-   bg：【可选】按钮背景颜色\n-   color：【可选】按钮文字颜色\n\n效果：\n\n{% hideInline 点我, 隐藏内容, blue, #fff %}\n\n<!-- endtab -->\n\n<!-- tab Block（隐藏多行内容） -->\n\n可以隐藏很多内容，包括图片，代码块等等\n\n用法：\n\n```bash\n{% hideBlock display, bg, color %}\ncontent\n{% endhideBlock %}\n```\n\n效果：\n\n{% hideBlock 点我 %}\n\n{% hideInline 点我, 隐藏内容, blue, #fff %}\n\n{% endhideBlock %}\n\n<!-- endtab -->\n\n<!-- tab Toggle（收缩内容） -->\n\n收缩框\n\n用法：\n\n```bash\n{% hideToggle display, bg, color %}\ncontent\n{% endhideToggle %}\n```\n\n效果：\n\n{% hideToggle 点我展开 %}\n收缩默认不展示的内容\n{% endhideToggle %}\n\n<!-- endtab -->\n\n{% endtabs %}\n\n{% endhideToggle %}\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Hexo","Butterfly"],"categories":["待归档"]},{"title":"minikube安装","url":"/posts/f7b5b7db/","content":"\n\n\n## minikube安装\n\nminikube官网地址：[https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)\n\n### 填坑指引\n\n1. [启动报错：DRV_AS_ROOT](#DRV_AS_ROOT)\n2. [启动报错：HOST_HOME_PERMISSION](#HOST_HOME_PERMISSION)\n3. [启动拉取镜像慢](#image_pull_slow)\n\n### 安装过程\n\n1. 确认系统以及对应架构\n\n    ```bash\n    $ uname -a # 查看系统信息\n    Linux crayon 5.4.0-65-generic #73~18.04.1-Ubuntu SMP Tue Jan 19 09:02:24 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\n    \n    $ arch # 查看架构\n    x86_64\n    ```\n\n    选择对应的配置复制下载命令下载`minikube`安装包并安装\n\n    ![1660403658866](images/posts-assets/minikube安装.assets/1660403658866.jpg)\n\n    ```bash\n    curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube_latest_amd64.deb\n    sudo dpkg -i minikube_latest_amd64.deb\n    ```\n\n2. <span id=\"DRV_AS_ROOT\">启动minikube</span>\n\n    官方注明了不要使用`root`权限启动，使用`sudo`或以`root`用户执行命令会报错\n\n    ```bash\n    $ sudo minikube start\n    😄  Ubuntu 18.04 (vbox/amd64) 上的 minikube v1.26.0\n    ✨  自动选择 docker 驱动。其他选项：none, ssh\n    🛑  The \"docker\" driver should not be used with root privileges. If you wish to continue as root, use --force.\n    💡  If you are running minikube within a VM, consider using --driver=none:\n    📘    https://minikube.sigs.k8s.io/docs/reference/drivers/none/\n    \n    ❌  Exiting due to DRV_AS_ROOT: The \"docker\" driver should not be used with root privileges.\n    ```\n\n    \n\n    <span id=\"HOST_HOME_PERMISSION\"></span>此时直接使用`minikube start`命令，但是可能出现以下问题\n\n    ```bash\n    $ minikube start\n    E0731 22:35:25.835507    4817 root.go:88] failed to log command start to audit: failed to open the audit log: open /home/crayon/.minikube/logs/audit.json: permission denied\n    E0731 22:35:25.835958    4817 cloud_events.go:60] unable to write to /home/crayon/.minikube/profiles/minikube/events.json: open /home/crayon/.minikube/profiles/minikube/events.json: permission denied\n    😄  Ubuntu 18.04 (vbox/amd64) 上的 minikube v1.26.0\n    ✨  自动选择 docker 驱动。其他选项：none, ssh\n    \n    🧯  The requested memory allocation of 1987MiB does not leave room for system overhead (total system memory: 1987MiB). You may face stability issues.\n    💡  建议：Start minikube with less memory allocated: 'minikube start --memory=1987mb'\n    \n    📌  Using Docker driver with root privileges\n    👍  Starting control plane node minikube in cluster minikube\n    🚜  Pulling base image ...\n    💾  Downloading Kubernetes v1.24.1 preload ...\n    \n    ❌  Exiting due to HOST_HOME_PERMISSION: Failed to save config: open /home/crayon/.minikube/profiles/minikube/config.json: permission denied\n    💡  建议：Your user lacks permissions to the minikube profile directory. Run: 'sudo chown -R $USER $HOME/.minikube; chmod -R u+wrx $HOME/.minikube' to fix\n    🍿  Related issue: https://github.com/kubernetes/minikube/issues/9165\n    ```\n\n    \n\n    问题在于当前用户的权限不足导致的，原因可能是因为一开始使用了`root`用户执行了命令而以`root`用户创建了相关配置文件导致的，按照命令的提示信息修改文件的权限即可解决\n\n    ```bash\n    # 这里的文件路径默认是在当前用户的home目录下，需要将home目录路径改为你自己的home目录路径\n    $ sudo chown -R crayon /home/crayon/.minikube; chmod -R u+wrx /home/crayon/.minikube\n    ```\n\n    改完权限再次执行启动命令\n\n    ```bash\n    $ minikube start\n    😄  Ubuntu 18.04 (vbox/amd64) 上的 minikube v1.26.0\n    ✨  根据现有的配置文件使用 docker 驱动程序\n    \n    🧯  The requested memory allocation of 1987MiB does not leave room for system overhead (total system memory: 1987MiB). You may face stability issues.\n    💡  建议：Start minikube with less memory allocated: 'minikube start --memory=1987mb'\n    \n    👍  Starting control plane node minikube in cluster minikube\n    ```\n\n    <span id=\"image_pull_slow\"></span>启动之后会去拉去镜像，这个时候会发现镜像拉取的速度极慢\n\n    建议使用中国区镜像拉取地址\n\n    ```bash\n    # 先执行删除\n    $ minikube delete\n    🔥  正在删除 docker 中的“minikube”…\n    🔥  正在删除容器 \"minikube\" ...\n    🔥  正在移除 /home/crayon/.minikube/machines/minikube…\n    💀  Removed all traces of the \"minikube\" cluster.\n    # 再执行start命令\n    $ minikube start --image-mirror-country='cn' # 官方专门为中国用户准备的\n    \n    ```\n\n    \n\n3. minikube start --image-mirror-country='cn' --extra-config=kubelet.cgroup-driver=systemd --driver='docker'\n\n","tags":["Kubernetes","minikube","Ubuntu"],"categories":["待归档"]},{"title":"Hexo-Butterfly添加友链","url":"/posts/5b29ce89/","content":"\n## Hexo-Butterfly添加友链\n\n### 思路\n\n- 友链通过Github仓库的方式对外开放，其他人可通过`Fork`仓库提交`PR`的方式添加友链信息\n- 友链信息仓库集成流水线，实现自动推包到`NPM`仓库\n- 博客站点通过`CDN`方式引用`script`，解析后渲染至页面上\n\n\n\n### 实现\n\n#### 1. 注册NPM账号，初始化项目\n\n [npm (npmjs.com)](https://www.npmjs.com/) \n\n到NPM网站上注册账号\n\n使用以下命令初始化npm项目\n\n```bash\n$ npm init\n# 按照提示填写信息即可，后面可以通过package.json修改\n\n# 设置下镜像源\n$ npm config set registry http://registry.npmjs.org\n\n# 登录账户\n$ npm adduser\nUsername: your name\nPassword: your password\nEmail: your email\n\n# 检查是否登录成功\n$ npm whoami\n# 不成功则重新登陆下\n$ npm login\n```\n\n\n\n`.gitignore`和`.npmignore`文件\n\n`.gitignore`文件用来忽略文件，不上传到Git仓库\n\n`.npmignore`文件用来忽略文件，不随包发布\n\n通过`package.json`里的`files`属性设置发布文件的白名单\n\n优先级：`files` > `.npmignore` > `.gitignore`\n\n```bash\n# 完成内容编写后发布包\n$ npm publish\n# 如果提示包不能为private，需要执行下面的命令\n$ npm publish --access public\n```\n\n\n\n#### 2. 通过CDN访问\n\n这里使用`jsdelivr`\n\n地址格式：`https://cdn.jsdelivr.net/npm/(your packagename)@(version)/(file)`\n\n不写版本号的话默认使用`latest`，即最新版本\n\n\n\n#### 3. 集成Github workflow\n\n文档地址：[关于工作流程 - GitHub Docs](https://docs.github.com/cn/actions/using-workflows/about-workflows) \n\n仓库根目录的`.github/workflows/`目录创建`yaml`文件来定义工作流\n\n现在创建一个名为`blog-friend-link.yaml`的文件定义工作流，该工作流用来自动解析仓库中的友链文件并进行自动发包，这样每次有代码更新即可自动发布最新的`NPM`包，博客通过链接即可获取到最新的友链信息了。\n\n样例文件：\n\n该文件定义了这样一个工作流：在指定branch、tag有pull_request时会触发，也可手动触发，其中包括一个名为publish的job，该job运行在ubuntu-latest系统上，且默认所有的step都在`blog/friend-link`目录下执行，该job包含5个step\n\n1. 使用`actions/checkout@v3`的action检出仓库，这样我们的job才可以访问到\n2. 使用`actions/setup-node@v3`的action初始化了一个`node`环境，便于后续使用npm命令和执行js代码\n3. 包含一条`npm install`的命令行命令，因为第2步已经初始化了`node`环境，所以可以使用`npm install`安装相关的依赖\n4. 执行build.sh脚本构建发包需要的文件\n5. 执行build.sh脚本进行发包\n\n```yaml\n# This is a basic workflow to help you get started with Actions\n\nname: blog-friend-link-CI\n\n# Controls when the workflow will run\non:\n  # Triggers the workflow on push or pull request events but only for the \"master\" branch\n  pull_request:\n    branches: [\"master\", \"v*\", \"release*\"]\n    tags: [\"v*\"]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n  publish:\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n\n    defaults:\n      run:\n        working-directory: blog/friend-link\n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it\n      - uses: actions/checkout@v3\n\n      # Runs a single command using the runners shell\n      - name: Use Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: \"14.x\"\n          registry-url: \"https://registry.npmjs.org\"\n\n      # Runs a set of commands using the runners shell\n      - name: Install dependencies\n        run: npm install\n\n      - name: Run build script\n        run: ./build.sh build\n\n      - name: Publish\n        # if: github.ref_name == 'master'\n        run: ./build.sh publish\n        env:\n          COMMIT_ID: ${{ github.sha }}\n          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n```\n\n\n\n{% note warning %}\n\n注意：\n\n1. 第2步需要指定`registry-url`，不然后续发包会报404\n2. 第5步的发包需要传递NPM_TOKEN，而不是使用命令行登录的方式\n\n{% endnote %}\n\n##### 生成NPM TOKEN\n\n到NPM主页点击右上角头像（未登录请先登录）找到Access Tokens点击进入\n\n![1662042180529](images/posts-assets/Hexo-Butterfly添加友链.assets/1662042180529.jpg)\n\n点击Generate New Token到生成新的Token的页面\n\n![1662042264055](images/posts-assets/Hexo-Butterfly添加友链.assets/1662042264055.jpg)\n\n\n\n生成后返回Token列表会在表格头上显示Token，点击即可复制\n\n\n\n##### 添加NPM TOKEN到Github\n\n到Github仓库页面点击Settings后选择Secrets里的Actions\n\n![1662042405123](images/posts-assets/Hexo-Butterfly添加友链.assets/1662042405123.jpg)\n\n点击New repository secret去添加新的密钥\n\n![1662042461474](images/posts-assets/Hexo-Butterfly添加友链.assets/1662042461474.jpg)\n\n{% note warning %}\n\n注意：这里填写的Name和你在workflow定义文件中的需要一致\n\n{% endnote %}\n\n定义文件中通过`${{secrets.*}}`获取对应的密钥\n\n![1662042506481](images/posts-assets/Hexo-Butterfly添加友链.assets/1662042506481.jpg)\n\n\n\n### 遇到的问题\n\n#### 1. step执行多行命令\n\n```yaml\n- name: Clean install dependencies and build\n  run: |\n    npm ci\n    npm run build\n```\n\n#### 2. 流水线无法切换目录\n\n在流水线里面无法使用`cd`等shell命令切换目录路径，需要使用`working-directory`的方式设置工作路径\n\n流水线的初始路径是仓库的根目录\n\nstep中通过`working-directory`指定工作目录，属于step间不可见的，每个step需要单独设置\n\n```yaml\n- name: Clean temp directory\n  run: rm -rf *\n  working-directory: ./temp\n```\n\n若想要同job里的step都在同一个工作目录下，则可以在job中通过`defaults.run.working-directory`\n\n```yaml\njobs:\n  job1:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        shell: bash\n        working-directory: scripts\n```\n\n#### 3. NPM version不可回退\n\nNPM规定每次发包必须保证版本号比上次的大\n\n具体版本规则参照： [NPM发包版本号规范](https://blog.csdn.net/Corazhang/article/details/111875879) \n\n这里我通过在版本号后追加Git的commitID（前6位）解决\n\n最终版本号样例：`1.0.0-e915db`\n\n{% note info %}\n\n通过流水线使用github上下文对象将commitID设置为环境变量（`COMMIT_ID`），shell脚本通过`${COMMIT_ID:0:6}`即可获取到6位commitID了\n\n{% endnote %}\n\n```yaml\n- name: Publish\n        # if: github.ref_name == 'master'\n        run: ./build.sh publish\n        env:\n          COMMIT_ID: ${{ github.sha }}\n          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n```\n\n通过`github.sha`可获取到提交ID，将其设置到COMMIT_ID的环境变量中\n\nshell脚本中即可引用到该变量\n\n```bash\nsed -i 's/\"version\": \"1.0.0\"/\"version\": \"1.0.0-'\"${COMMIT_ID:0:6}\"'\"/' package.json\n```\n\n使用`sed`命令搜索`package.json`中的version属性，将其替换即可\n\n\n\n#### 4. Shell脚本没有执行权限\n\n上库前执行`git update-index --chmod=+x xxx.sh`添加执行权限后再上库\n\n或者在流水线执行时先执行`chmod +x xxx.sh`的命令赋予执行权限\n\n\n\n\n\n\n\n\n\n","tags":["Hexo","Butterfly"],"categories":["待归档"]},{"title":"Virtualbox-Centos网络配置","url":"/posts/476f1d65/","content":"\n\n\n### Host-Only方式实现主机/虚拟机互通\n\n1. 点击创建Host-Only网卡\n\n    ![1659263422994](images/posts-assets/Virtualbox-Centos网络配置.assets/1659263422994.jpg)\n\n2. 不启用DHCP服务器（方便后续可以使用静态的IP访问虚拟机）\n\n    设置IPv4地址\n\n    ![1659263479379](images/posts-assets/Virtualbox-Centos网络配置.assets/1659263479379.jpg)\n\n3. 虚拟机网络设置\n\n    启用网卡2，连接方式选择仅主机（Host-Only）网络，界面名称选择刚才创建的Host-Only网卡\n\n    ![1659263713203](images/posts-assets/Virtualbox-Centos网络配置.assets/1659263713203.jpg)\n\n4. 启动虚拟机，进行网络配置\n\n    查看网络配置\n\n    ``` bash\n    ifconfig\n    # centos中若没有该命令可以使用ip addr\n    ```\n\n    ![1659264458715](images/posts-assets/Virtualbox-Centos网络配置.assets/1659264458715.jpg)\n\n    > enp0s3、enp0s8等就是网卡的名称\n\n    ```bash\n    # 编辑网卡配置，若没有该文件可以从已有的网卡配置中拷贝后做修改，其他的网卡配置文件形如ifcfg-[网卡名称]\n    vi /etc/sysconfig/network-scripts/ifcfg-enp0s8\n    ```\n\n    修改或添加如下字段\n\n    ```ini\n    # 配置成静态IP\n    BOOTPROTO=\"static\"\n    # 设置的IP应当和网卡处于同一网段\n    IPADDR=\"192.168.56.10\"\n    NETMASK=\"255.255.255.0\"\n    ```\n\n    重启网络服务\n\n    ```bash\n    service network restart\n    ```\n\n    - 附：网卡配置文件与自动配置脚本\n\n        **网卡配置文件**\n\n        ```ini\n        TYPE=\"Ethernet\"\n        PROXY_METHOD=\"none\"\n        BROWSER_ONLY=\"no\"\n        BOOTPROTO=\"static\"\n        DEFROUTE=\"yes\"\n        IPV4_FAILURE_FATAL=\"no\"\n        IPV6INIT=\"yes\"\n        IPV6_AUTOCONF=\"yes\"\n        IPV6_DEFROUTE=\"yes\"\n        IPV6_FAILURE_FATAL=\"no\"\n        IPV6_ADDR_GEN_MODE=\"stable-privacy\"\n        NAME=\"enp0s8\"\n        UUID=\"90e928eb-b2e6-444e-9c43-462513e6d130\"\n        DEVICE=\"enp0s8\"\n        ONBOOT=\"yes\"\n        IPADDR=\"192.168.56.10\"\n        NETMASK=\"255.255.255.0\"\n        ```\n\n        **自动配置脚本**\n\n        ```shell\n        #!/bin/bash\n        name=$1\n        echo 'copy script file'\n        cp ${name} /etc/sysconfig/network-scripts/ifcfg-${name}\n        echo 'restart network service'\n        service network restart\n        ```\n\n        > 脚本使用方式\n        >\n        > 1. 修改权限，使其有执行权限\n        >\n        >     ```bash\n        >     chmod +x [脚本名称]\n        >     ```\n        >\n        > 2. 指定网卡名称，同目录下放网卡配置文件并以网卡名称命名，执行以下命令进行网络自动配置\n        >\n        >     ```bash\n        >     ./[脚本名称] [网卡名称]\n        >     # 例如：./set-network.sh enp0s8\n        >     ```\n        >\n        >     说明：脚本读取同目录下的enp0s8文件，并将该文件的内容拷贝（覆盖）对应的网卡配置文件，示例命令则将`enp0s8`文件拷贝（覆盖）`/etc/sysconfig/network-scripts/ifcfg-enp0s8`文件\n\n5. 宿主机ping测试连通性\n\n    ```bash\n    > ping 192.168.56.10\n    \n    正在 Ping 192.168.56.10 具有 32 字节的数据:\n    来自 192.168.56.10 的回复: 字节=32 时间<1ms TTL=64\n    来自 192.168.56.10 的回复: 字节=32 时间<1ms TTL=64\n    来自 192.168.56.10 的回复: 字节=32 时间<1ms TTL=64\n    来自 192.168.56.10 的回复: 字节=32 时间<1ms TTL=64\n    \n    192.168.56.10 的 Ping 统计信息:\n        数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，\n    往返行程的估计时间(以毫秒为单位):\n        最短 = 0ms，最长 = 0ms，平均 = 0ms\n    ```\n\n6. （可选）配置hosts文件\n\n    hosts文件路径\n\n    Windows：`C:\\Windows\\System32\\drivers\\etc\\hosts`\n\n    Linux：`/etc/hosts`\n\n    添加域名映射\n\n    ```ini\n    192.168.56.10 centos-0\n    ```\n\n    `ping`测试连通性\n\n    ```bash\n    > ping centos-0\n    \n    正在 Ping centos-0 [192.168.56.10] 具有 32 字节的数据:\n    来自 192.168.56.10 的回复: 字节=32 时间<1ms TTL=64\n    来自 192.168.56.10 的回复: 字节=32 时间<1ms TTL=64\n    来自 192.168.56.10 的回复: 字节=32 时间<1ms TTL=64\n    来自 192.168.56.10 的回复: 字节=32 时间<1ms TTL=64\n    \n    192.168.56.10 的 Ping 统计信息:\n        数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，\n    往返行程的估计时间(以毫秒为单位):\n        最短 = 0ms，最长 = 0ms，平均 = 0ms\n    ```\n\n    \n\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Virtualbox","Centos"],"categories":["待归档"]},{"title":"vim常用命令","url":"/posts/8c31560b/","content":"\n\n\n### Vim\n\n[常用命令汇总](#common-use)\n\n#### 简介\n\n\n\n![20220721174326629](images/posts-assets/vim.assets/20220721174326629.jpg)\n\n\n\n#### 模式\n\nvim有3种模式\n\n-   命令模式（Command mode）\n-   输入模式（Insert mode）\n-   底线命令模式（Last line mode）\n\n##### 命令模式\n\n用户一启动vim就进入命令模式\n\n此状态下敲击键盘的动作会被识别为命令\n\n常用命令：\n\n-   `i`切换到输入模式\n-   `x`删除当前光标所在处的字符\n-   `:`切换到底线命令模式\n\n##### 输入模式\n\n##### 底线命令模式\n\n在命令模式下按`:`进入底线命令模式\n\n常用命令：\n\n-   `:q`退出程序\n-   `:q!`强制退出\n-   `:w`保存文件\n\n\n\n![20220721174906379](images/posts-assets/vim.assets/20220721174906379.jpg)\n\n\n\n#### <span id=\"common-use\">常用命令汇总</span>\n\n##### 搜索替换\n\n| 命令  | 说明                                                         |\n| ----- | ------------------------------------------------------------ |\n| /word | 向光标以下寻找一个名称为`word`的字符串                       |\n| ?word | 向光标以上搜索                                               |\n| n     | next，重复前一个搜索动作，如果刚执行了向下搜索，那么就会继续向下搜索，如果刚刚执行的是向上搜索，那么继续向上搜索 |\n| N     | `n`操作的反向操作                                            |\n\n##### 删除、复制、粘贴\n\n| 命令       | 说明             |\n| ---------- | ---------------- |\n| yy         | 复制一行         |\n| dd         | 剪切一行         |\n| p/P        | 粘贴             |\n| u          | undo，回退、撤销 |\n| `[ctrl]`+r | redo，重做       |\n\n\n\n##### 其他\n\n| 命令        | 说明       |\n| ----------- | ---------- |\n| `:set nu`   | 显示行号   |\n| `:set nonu` | 不显示行号 |\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["vim","Linux"],"categories":["常用"]},{"title":"Kafka权威指南","url":"/posts/d2d512ed/","content":"\n## Kafka权威指南\n\n### 序\n\n>   `Kafka`最初是`LinkedIn`的一个内部基础设施系统。我们发现，虽然有很多数据库和系统可\n>   以用来存储数据，但在我们的架构里，刚好缺一个可以帮助**处理持续数据流**的组件。在开\n>   发`Kafka`之前，我们实验了各种现成的解决方案，从消息系统到日志聚合系统，再到 ETL\n>   工具，它们都无法满足我们的需求。\n\n>   我们认为`Kafka`是一个流平台：在这个平台上可以发布和订阅数据流，并把它们保存起来、进行处理。\n>\n>   `Kafka`有点像消息系统，允许发布和订阅消息流（类似于ActiveMQ、RabbitMQ等）。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Kafka"],"categories":["啃书"]},{"title":"Kubernetes实战","url":"/posts/b293d35b/","content":"\n## Kubernetes实战\n\n### 第1部分 Kubernetes基础篇\n\n#### 第1章 Kubernetes介绍\n\n##### 几个概念\n\n>   云计算\n>\n>   狭义上将是指IT基础设施的交付和使用模式，即通过网络以按需、易扩展的方式获取所需资源。\n>\n>   广义上则是指服务的交付和使用模式，通过网络以按需、易扩展的方式获取所需服务。\n>\n>   提供资源的网络被形象地比喻成“云”，其计算能力通常由分布式的大规模集群和虚拟化技术提供的。\n>\n>   “云”好比发电厂，互联网好比输电线路，只不过发电厂对外提供的是**IT服务**\n\n业界根据云计算提供服务资源的类型将其划分为三大类：\n\n-   IaaS（基础设施即服务）\n-   PaaS（平台即服务）\n-   SaaS（软件即服务）\n\n云计算三层架构图\n\n![20220517160200947](images/posts-assets/Kubernetes实战.assets/20220517160200947.jpg)\n\n>   IaaS（基础设施即服务）\n>\n>   白话：卖给你硬件设备，相比与传统的设备更易扩展而已，如云硬盘、云服务器、云主机\n>\n>   通过虚拟化和分布式存储等技术，实现了对包括服务器、存储设备、网络设备等各种物理资源的抽象，从而形成了一个可扩展、可按需分配的虚拟资源池。目前最具代表性的IaaS产品有Amazon AWS，提供虚拟机EC2和云存储S3等服务。\n\n\n\n>   PaaS（平台即服务）\n>\n>   白话：卖给你一些开发组件，如云数据库、或是Tomcat运行环境等（Kubernetes也算在定义范畴内）。PaaS服务一般分为框架类服务和中间件服务，\n>\n>   框架类服务：Tomcat、Websphere、Node.js、Rubyon Rails、Ruby on Rack\n>\n>   中间件服务：数据库(Mysql、mongoDB、Redis)、消息队列(RabbitMQ)、缓存(Memcache)。\n>\n>   \n>\n>   为开发者提供了应用的开发环境和运行环境，将开发者从繁琐的IT环境管理中解放出来，自动化部署和运维，使开发者能够集中精力于应用业务开发，提升应用的开发效率。PaaS主要面向的是软件专业人员，Google的GAE是PaaS的鼻祖。\n\n\n\n>   SaaS（软件即服务）\n>\n>   白话：直接卖软件给你用\n>\n>   面向使用软件的终端用户。一般来说，SaaS将软件功能以特定的接口形式发布，终端用户通过网络浏览器就可以使用软件功能（那不就是Web应用嘛）。SaaS是应用最广的云计算模式，如在线使用的邮箱系统和各种管理系统都可以认为是SaaS的范畴。\n\n![20220517161639971](images/posts-assets/Kubernetes实战.assets/20220517161639971.jpg)\n\n\n\n##### Kubernetes是什么\n\n是Google开源的容器集群管理系统。构建在Docker技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等一整套功能。\n\n特性：\n\n-   容器编排能力\n\n    容器组合、标签选择和服务发现等\n\n-   轻量级\n\n    遵循微服务架构理论，整个系统划分出各个功能独立的组件，组件之间边界清晰，部署简单，可以轻易地运行在各种系统和环境中。同时，Kubernetes中的许多功能都实现了插件化，可以非常方便地进行扩展和替换。\n\n-   开放开源\n\n##### Kubernetes核心概念\n\n###### Pod\n\nPod是若干相关**容器的组合**，Pod包含的容器运行在**同一台宿主机**上，这些容器使用**相同的网络命名空间、IP地址和端口**，相互之间能通过`localhost`来发现和通信。另外，这些容器还可共享一块存储卷空间。在Kubernetes中创建、调度和管理的最小单位是Pod，而不是容器，Pod通过提供更高层次的抽象，提供了更加灵活的部署和管理模式。\n\n-   若干运行在同一台宿主机上的相关容器的组合\n\n-   使用相同网络命名空间、IP地址和端口\n\n-   共享一块存储卷空间\n\n\n\n###### Replication Controller\n\n用来控制管理Pod副本（Replica，或者称为实例），Relication Controller确保任何时候Kubernetes集群中有指定数量的Pod副本在运行。如果少于指定数量的Pod副本，它会启动新的Pod副本，反之会杀死多余的副本以保证数量不变。Replication Controller是弹性伸缩、滚动升级的实现核心。\n\n-   控制副本数量\n-   弹性伸缩、滚动升级的实现核心\n\n###### Service\n\n是真实应用服务的抽象，定义了Pod的逻辑集合和访问这个Pod集合的策略。它将代理Pod对外表现为一个单一访问的接口，外部不需要了解后端Pod如何运行，对扩展和维护有好处，提供了一套简化的服务代理和发现机制。\n\n-   定义了Pod的逻辑集合和访问这个Pod集合的策略\n-   将代理Pod对外表现为一个单一访问的接口\n-   提供服务代理和发现机制\n\n###### Label\n\n用来区分Pod、Service、Replication Controller的Key/Value对，Kubernetes中任意API对象都可以通过Label标识。每个API对象可以有多个Label，但是每个Label的Key只能对应一个Value。Label是Service和Replication Controller运行的基础，它们都通过Label来关联Pod，是一种松耦合关系。\n\n-   Key/Value对，标识API对象\n-   每个API对象可以有多个Label，但是每个Label的Key只能对应一个Value\n\n###### Node\n\nK8s属于主从分布式集群架构，Node运行并管理容器。Node作为K8s的操作单元，用来分配给Pod（或者说容器）进行绑定，Pod最终运行在Node上，Node可以认为是Pod的宿主机。\n\n-   K8s操作单元，分配给Pod进行绑定\n-   可以认为是Pod的宿主机\n\n\n\n#### 第2章 K8s的架构和部署\n\n##### K8s的架构和组件\n\nK8s属于主从分布式架构，节点在角色上分为Master和Node\n\nK8s使用`Etcd`作为存储组件\n\n>   Etcd是一个高可用的键值存储系统，灵感来自ZooKeeper和Doozer，通过Raft一致性算法处理日志复制以保证强一致性。\n\nK8s使用`Etcd`作为系统的配置存储中心，K8s中的重要数据都是持久化在`Etcd`中的，这使得K8s架构的各个组件属于无状态，可以更简单实施分布式集群部署。\n\nK8s Master作为控制节点，调度管理整个系统，包含以下组件\n\n-   K8s API Server：作为K8s系统的入口，其封装了核心对象的增删改查操作，以REST API接口方式提供给外部客户和内部组件调用。它维护的REST对象将持久化到`Etcd`中。\n\n-   K8s Scheduler：负责集群的资源调度，为新建的Pod分配机器。这部分工作分出来一个组件，意味着可以很方便地替换成其他的调度器。\n\n-   K8s Controller Manager：负责执行各种控制器，目前已经实现很多控制器来保证K8s的正常运行\n\n    | 控制器 | 说明 |\n    | ------ | ---- |\n    |        |      |\n    |        |      |\n    |        |      |\n\nK8s Node是运行节点，用于运行管理业务的容器，包含以下组件\n\n-   Kubelet：负责管控容器，Kubelet会从K8s API Server接受Pod的创建请求，启动和停止容器，监控容器运行状态并汇报给K8s API Server。\n-   K8s Proxy：负责为Pod创建代理服务，K8s Proxy会从K8s API Server获取所有的Service，并根据Service信息创建代理服务，实现Service到Pod的请求路由和转发，从而实现K8s层级的虚拟转发网络。\n-   Docker：K8s Node是容器运行节点，需要运行Docker服务，K8s也支持其他容器引擎\n\n##### 部署K8s\n\n###### 环境准备\n\nK8s是一个分布式架构，可以灵活进行安装部署，可以部署在单机，也可以分布式部署。但是需要运行在Linux（x86_64）系统上，至少1核CPU和1GB内存。\n\n（使用4台虚拟机用于部署k8s运行环境，一个etcd、一个K8s Master和三个K8s Node\n\n###### 运行etcd\n\n###### 获取K8s发行包\n\n###### 运行K8s Master组件\n\n###### 运行K8s Node组件\n\n###### 查询K8s的健康状态\n\n###### 创建K8s覆盖网络\n\n##### 安装K8s扩展插件\n\n###### 安装Cluster DNS\n\n`Cluster DNS`用于支持K8s的服务发现机制，主要包含如下几项：\n\n-   SkyDNS：提供DNS解析服务\n-   Etcd：用于SkyDNS的存储\n-   Kube2sky：监听K8s，当有新的Service创建时，生成相应记录到SkyDNS\n\n###### 安装Cluster Monitoring\n\n###### 安装Cluster Logging\n\n###### 安装Kube UI\n\n\n\n#### 第3章 K8s快速入门\n\nK8s是容器集群管理系统，为容器化的应用提供资源调度、部署运行、容灾容错和服务发现等功能。\n\n##### 示例应用Guestbook\n\nGuestbook是一个典型的Web应用\n\n![20220719200349874](images/posts-assets/Kubernetes实战.assets/20220719200349874.jpg)\n\nGuestbook包含两部分\n\n-   Frontend\n\n    Web前端，无状态节点，可以方便伸缩，本例中将运行3个实例\n\n-   Redis\n\n    存储部分，Redis采用主备模式，即运行1个Redis Master、2个Redis Slave，Redis Slave会从Redis Master同步数据\n\nGuestbook提供的功能：在Frontend页面提交数据，Frontend则将数据保存到Redis Master，然后从Redis Slave读取数据显示到页面上。\n\n##### 运行Redis\n\n在K8s上部署Redis，包括Master和Slave\n\n###### 创建Redis Master Pod\n\n`Pod`是K8s的基本处理单元，`Pod`包含一个或多个相关的容器，应用以`Pod`的形式运行在K8s中（本质上是容器）。`Replication Controller`能够控制`Pod`按照指定的副本数目持续运行，一般情况下是通过`Replication Controller`来创建`Pod`来保证`Pod`的可靠性。\n\n定义`redis-master-controller.yaml`\n\n```yaml\napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: redis-master\n  labels:\n    name: redis-master\nspec:\n  replicas: 1\n  selector:\n    name: redis-master\n  template:\n    metadata:\n      labels:\n        name: redis-master\n    spec:\n      containers:\n      - name: master\n        image: redis\n        ports:\n        - containerPort: 6379\n```\n\nK8s中通过文件定义API对象，文件格式支持`JSON`和`YAML`\n\nAPI对象基本属性：\n\n-   API版本（`.apiVersion`）\n\n-   API对象类型（`.kind`）\n\n-   元数据（`.metadata`）\n\n    `redis-master-controller.yaml`定义了V1版本下一个名称为`redis-master`的`Replication Controller`，另外配置了规格（`.spec`），其中设置了`Pod`的副本数（`.spec.replicas`）和`Pod`模板（`.spec.template`）\n\n    `Pod`模板中说明了`Pod`包含了一个容器，该容器使用镜像`redis`，即运行Redis Master，该`Replication Controller`将关联一个这样的`Pod`，而`Replication Controller`和`Pod`的关联是通过`Label`来实现的（`.spec.selector`和`.spec.template.metadata.labels`）\n\n通过定义文件创建`Replication Controller`\n\n```bash\n$ kubectl create -f redis-master-controller.yaml\n```\n\n###### 创建Redis Master Service\n\nK8s中`Pod`是变化的，特别是受到`Replication Controller`控制的时候，当`Pod`发生变化的时候，`Pod`的`IP`也是变化的。\n\n>   由此衍生出一个问题，就是集群中的`Pod`如何互相发现并访问的？\n\nK8s提供`Service`实现服务发现\n\n`Service`是真实应用的抽象，将用来**代理**`Pod`，对外提供固定`IP`作为访问入口，通过访问`Service`来访问相应的`Pod`，访问者只需要知道`Service`的访问地址，而不需要感知`Pod`的变化\n\n{% hideBlock 猜测 %}\n\n猜一下怎么实现的，大概是通过etcd做服务注册，将Pod的IP注册进去，每次Pod的变动都会更新其中注册的IP，Service通过这个注册的IP访问Pod\n\n{% endhideBlock %}\n\n创建Redis Master Service来代理Redis Master Pod\n\nRedis Master Service的定义文件`redis-master-service.yaml`：\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-master\n  labels:\n    name: redis-master\nspec:\n  ports:\n  - port: 6379\n    targetPort: 6379\n  selector:\n    name: redis-master\n```\n\n创建Service\n\n```bash\nkubectl create -f redis-master-service.yaml\n```\n\n\n\n`Service`通过`Label`关联`Pod`，在`Service`的定义中，设置`.spec.selector`为`name=redis-master`将关联`redis master pod`（创建时我们指定了`selector.name`为`redis-master`\n\n通过命令查询`Service`\n\n```bash\n$ kubectl get service redis-master\nNAME CLUSTER_IP EXTERNAL_IP PORT(S) SELECTOR AGE\n...  ...        <none>      ...     ...      ...\n```\n\n`CLUSTER_IP`：K8s分配给`Serivce`的虚拟IP\n\n`PORT(S)`：6379/TCP，是`Service`会转发的端口（通过`Service`定义文件中的`.spec.ports[0].port`指定），K8s会将访问该端口的TCP请求转发到`Redis Master Pod`中，目标端口为6379/TCP（通过`Service`定义文件中的`.spec.ports[0].targetPort`指定）\n\n因为创建Redis Master Service来代理Redis Master Pod，所以Redis Slave Pod通过Service的虚拟IP就可以访问到Redis Master Pod，但是如果只是硬配置Service的虚拟IP到Redis Slave Pod中，还不是真正的服务发现，K8s提供了两种发现Service的方法\n\n-   环境变量\n\n    当Pod运行的时候，K8s会将之前存在的Service的信息通过环境变量写到Pod中，以Redis Master Service为例，它的信息会被写到Pod中：\n\n    ```ini\n    REDIS_MASTER_SERVICE_HOST=10.254.233.212\n    REDIS_MASTER_PORT_6379_TCP_PROTO=tcp\n    REDIS_MASTER_SERVICE_PORT=6379\n    REDIS_MASTER_PORT=tcp://10.254.233.212:6379\n    REDIS_MASTER_PORT_6379_TCP=tcp://10.254.233.212:6379\n    REDIS_MASTER_PORT_6379_TCP_PORT=6379\n    REDIS_MASTER_PORT_6379_TCP_ADDR=10.254.233.212\n    ```\n\n    缺点：Pod必须在Service之后启动，采用DNS方式就没有这种限制\n\n-   DNS\n\n    当有新的Service创建时，就会自动生成一条DNS记录，以Redis Master Service为例，有一条DNS记录：\n\n    `redis-master => 10.254.233.212`\n\n    使用这种方法，K8s需要安装Cluster DNS插件\n\n###### 创建Redis Slave Pod\n\n通过Replication Controller可创建Redis Slave Pod，将创建两个Redis Slave Pod。定义文件`redis-slave-controller.yaml`：\n\n```yaml\napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: redis-slave\n  labels:\n    name:  redis-slave\nspec:\n  replicas: 2\n  selector:\n    name:  redis-slave\n  template:\n    metadata:\n      labels:\n        name: redis-slave\n    spec:\n      containers:\n        - name: worker\n          image: gcr.io/google_samples/gb-redisslave:v1\n          env:\n            - name: GET_HOSTS_FROM\n              value: dns # 若没有安装cluster-dns插件，可以用env替代，但是一定要在service创建之后再创建\n          ports:\n            - containerPort: 6379\n```\n\n定义文件中设置了Pod的副本数为2，Pod模板中包含一个容器，容器使用镜像`gcr.io/google_samples/gb-redisslave:v1`，该镜像实际是基于redis镜像，重写了启动脚本，将其作为Redis Master的备用节点启动，启动脚本如下：\n\n```bash\nif [[ ${GET_HOSTS_FROM:-dns} == \"env\" ]]; then\n\tredis-server --slaveof ${REDIS_MASTER_SERVICE_HOST} 6379\nelse\n\tredis-server --slaveof redis-master 6379\nfi\n```\n\n其实就是通过`GET_HOSTS_FROM`环境变量控制服务发现的\n\n>   扩展：${GET_HOSTS_FROM:-dns}\n>\n>   shell中对变量赋默认值，这里的意思是如果`GET_HOSTS_FROM`未定义或为空串，则赋予默认值dns\n>\n>   语法格式：${变量名:-默认值}\n>\n>   另一种写法是只有未定义才赋予默认值\n>\n>   语法格式：${变量名-默认值}\n\n创建Pod\n\n```bash\nkubectl create -f redis-slave-controller.yaml\n```\n\n\n\n###### 创建Redis Slave Service\n\nredis-slave-service.yaml：\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-slave\n  labels:\n    name:  redis-slave\nspec:\n  selector:\n    name: redis-slave\n  ports:\n  - port: 6379\n    targetPort: 6379\n```\n\n创建Service\n\n```bash\nkubectl create -f redis-slave-service.yaml\n```\n\n\n\n##### 运行Frontend\n\n###### 创建Frontend Pod\n\n通过Frontend Replication Controller来创建Frontend Pod，将创建3个Frontend Pod\n\nfrontend-controller.yaml\n\n```yaml\napiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: frontend\n  labels:\n    name:  frontend\nspec:\n  replicas: 3\n  selector:\n    name: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n        - name: php-redis\n          image: gcr.io/google_samples/gb-frontend:v3\n          env:\n            - name: GET_HOSTS_FROM\n              value: env # 没有装cluster-dns插件，所以用env替代了dns\n          ports:\n            - containerPort: 80\n```\n\n定义文件中设置Pod副本数为3，Pod模板包含一个容器，容器使用镜像`gcr.io/google_samples/gb-frontend:v3`，这是一个PHP实现的Web应用，写数据到Redis Master，并从Redis Slave中读取数据。内部也是通过`GET_HOSTS_FROM`环境变量控制服务发现方式的。\n\n创建Pod\n\n```bash\nkubectl create -f frontend-controller.yaml\n```\n\n###### 创建Frontend Service\n\nfrontend-service.yaml\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\n  labels:\n    name:  frontend\nspec:\n  selector:\n    name: frontend\n  ports:\n  - port: 80\n    targetPort: 80\n```\n\n##### 设置Guestbook外网访问\n\n现在Guestbook已经运行在K8s上了，但是只有内部网络能访问，外部网络的用户是无法访问的，我们需要增加一层网络转发，即外网到内网的转发。实现方式有很多种，我们这里采用`NodePort`的方式实现。\n\n即K8s会在每个节点上设置端口，称为`NodePort`，通过`NodePort`可以访问到`Pod`\n\n修改frontend-service.yaml，设置`.spec.type`为`NodePort`：\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\n  labels:\n    name:  frontend\nspec:\n  type: NodePort # 添加type为NodePort\n  selector:\n    name: frontend\n  ports:\n  - port: 80\n    targetPort: 80\n```\n\n重新创建Service：\n\n```bash\n$ kubectl replace -f front-service.yaml --force\nservice \"frontend\" deleted\nservice/frontend replaced\n$ kubectl get svc\nNAME           TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE\nfrontend       NodePort    10.0.0.69    <none>        80:32443/TCP   2s\nredis-master   ClusterIP   10.0.0.229   <none>        6379/TCP       127m\nredis-slave    ClusterIP   10.0.0.80    <none>        6379/TCP       82m\n```\n\n可以看到frontend的TYPE已经是`NodePort`了，并且可以看到`PORT(S)`有端口映射（80:32443/TCP），外部可以通过32443访问\n\n##### 清理Guestbook\n\n```bash\nkubectl delete rc redis-master redis-slave frontend\nkubectl delete svc redis-master redis-slave frontend\n```\n\n#### 第4章 Pod\n\n##### Hello World\n\n创建一个简单的Hello World Pod，运行一个输出Hello World的容器\n\n定义文件hello-world-pod.yaml：\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-world\nspec:\n  restartPolicy: OnFailure\n  containers:\n  - name: hello-world\n    image: \"ubuntu:18.04\"\n    command: [\"/bin/echo\", \"hello\", \"world\"]\n```\n\n定义文件中描述了Pod的属性和行为\n\n-   `apiVersion`：声明K8s的API版本，目前是v1\n\n-   `kind`：声明API对象的类型，这里的类型是Pod\n\n-   `metadata`：设置Pod的元数据\n\n    -   `name`：指定Pod的名称，Pod的名称必须Namespace内唯一\n\n-   `spec`：配置Pod的具体规格\n\n    -   `restartPolicy`：设置Pod的重启策略\n\n    -   `containers`：设置Pod中容器的规格，数组格式，每一项定义一个容器\n\n        `name`：指定容器名称，在Pod的定义中唯一\n\n        `image`：设置容器镜像\n\n        `command`：设置容器的启动命令\n\n这里的Pod定义效果和以下docker命令运行的容器效果一样\n\n```bash\n$ docker run --name hello-world ubuntu:18.04 /bin/echo 'hello world'\nhello world\n```\n\n需要注意，因为容器输出完之后就会退出，这是一次性执行的，所以Pod的定义中把`.spec.restartPolicy`设置为`OnFailure`，即容器正常退出不会重新创建容器\n\n创建Pod\n\n```bash\n$ kubectl create -f hello-world-pod.yaml\n# 查询Pod输出\n$ kubectl logs hello-world\nhello world\n```\n\n\n\n##### Pod的基本操作\n\n###### 创建Pod\n\nK8s中大部分的API对象都是通过`kubectl create`命令创建的\n\n如果Pod的定义有误，`kubectl create`会打印出错误信息\n\n###### 查询Pod\n\n```bash\nkubectl get pod (pod name)\n```\n\n不指定pod则查询全部pod\n\n字段含义：\n\n-   `NAME`：Pod名称\n-   `READY`：Pod的准备状况，右边的数字表示Pod包含的容器总数，左边的数字表示准备就绪的容器数目\n-   `STATUS`：Pod的状态\n-   `RESTARTS`：Pod的重启次数\n-   `AGE`：Pod的运行时间\n\n其中Pod的准备状况指的是Pod是否准备就绪以接受请求，Pod的准备状况取决于容器，即所有容器都准备就绪了，Pod才准备就绪。这个时候K8s的代理服务才会添加Pod作为分发后端，而一旦Pod的准备状况变为false（至少一个容器的准备状况变为false），K8s会将Pod从代理服务的分发后端移除。\n\n默认情况下，`kubectl get`只显示Pod的简要信息\n\n```bash\nkubectl get pod (pod name) --output json # json格式显示，--output可以简写为-o\nkubectl get pod (pod name) --output yaml # yaml格式显示，--output可以简写为-o\n```\n\n也支持Go Template方式过滤指定的信息，比如查询Pod的运行状态：\n\n```bash\nkubectl get pod (pod name) -o go-template --template={{.status.phase}}\n```\n\n`kubectl describe`查询Pod的状态和生命事件：\n\n```bash\nkubectl describe pod (pod name)\n```\n\n字段含义：\n\n-   `Name`：Pod名称\n-   `Namespace`：Pod的Namespace\n-   `Image(s)`：Pod使用的镜像\n-   `Node`：Pod所在的Node\n-   `Start Time`：Pod的起始时间\n-   `Labels`：Pod的Label\n-   `Status`：Pod的状态\n-   `Reason`：Pod处于当前状态的原因\n-   `Message`：Pod处于当前状态的信息\n-   `IP`：Pod的PodIP\n-   `Replication Controllers`：Pod对应的Replication Controller\n-   `Containers`：Pod中容器的信息\n    -   `Container ID`：容器ID\n    -   `Image`：容器的镜像\n    -   `Image ID`：镜像ID\n    -   `State`：容器的状态\n    -   `Ready`：容器的准备状态\n    -   `Restart Count`：容器的重启次数统计\n    -   `Environment Variables`：容器的环境变量\n-   `Conditions`：Pod的条件，包含Pod的准备状况\n-   `Volumes`：Pod的数据卷\n-   `Events`：与Pod相关的事件列表\n\n###### 删除Pod\n\n```bash\nkubectl delete pod [pod name]\nkubectl delete pod --all\n```\n\n###### 更新Pod\n\n如果想要更新Pod，可以在修改定义文件后执行：\n\n```bash\nkubectl replace [file]\n```\n\n但是很多属性没办法修改，比如容器镜像，这时候可以通过`--force`参数强制更新，等于重建Pod\n\n##### Pod与容器\n\n在Docker中，容器是最小处理单位，隔离是基于Linux Namespace实现的，Linux内核中提供了6种Linux Namespace隔离的系统调用\n\n| Linux Namespace | 系统调用参数  | 隔离内容                   |\n| --------------- | ------------- | -------------------------- |\n| UTS             | CLONE_NEWUTS  | 主机名与域名               |\n| IPC             | CLONE_NEWIPC  | 信号量、消息队列和共享内存 |\n| PID             | CLONE_NEWPID  | 进程编号                   |\n| Network         | CLONE_NEWNET  | 网络设备、网格栈、端口等   |\n| Mount           | CLONE_NEWNS   | 挂载点（文件系统）         |\n| User            | CLONE_NEWUSER | 用户和用户组               |\n\n在K8s中，Pod包含一个或多个相关容器，Pod可以认为是容器的一种延伸扩展，一个Pod也是一个隔离体，而Pod包含的一组容器又是共享的（当前共享的Linux Namespace包括：PID、Network、IPC和UTS）。除此之外，Pod中的容器可以访问共同的数据卷来实现文件系统的共享，所以**K8s的数据卷是Pod级别的**\n\nPod是容器的集合，容器是真正的执行体。Pod的设计不是为了运行同一个应用的多个实例，而是运行一个应用、多个紧密联系的程序。而每个程序运行在单独的容器中，以Pod的形式组合成一个应用。相比于单个容器中运行多个程序，这样设计的好处有：\n\n-   透明性：将Pod内的容器向基础设施可见，底层系统就能向容器提供如进程管理和资源监控等服务\n-   解绑软件的依赖：单个容器可以独立重建和重新部署，实现独立容器的实时更新\n-   易用性：用户不需要运行自己的进程管理器，也不需要负责信号量和退出码的传递等\n-   高效性：因为底层设备负责更多的管理，容器因而更轻量化\n\n在Pod中可以详细配置如何运行一个容器\n\n###### 镜像\n\n运行容器必须先指定镜像，镜像名称遵循Docker的命名规范。\n\n如果镜像不存在，会从Docker镜像仓库下载。K8s中可以选择镜像的下载策略，支持的策略有：\n\n-   Always：每次都下载最新的镜像\n-   Never：只使用本地镜像，从不下载\n-   IfNotPresent：只有本地没有的时候才下载\n\n通过`imagePullPolicy`设置镜像下载策略\n\n```yaml\nname: hello\nimage: 'ubuntu:18.04'\nimagePullPolicy: Always\n```\n\n###### 启动命令\n\n启动命令用来说明容器是如何运行的，在Pod的定义中可以设置容器启动命令和参数\n\n例：\n\n```yaml\n...\ncontainers:\n- name: hello\n  image: 'ubuntu:18.04'\n  command: [\"/bin/echo\", \"hello\", \"world\"]\n...\n```\n\n也可以配置为：\n\n```yaml\n...\ncommand: [\"/bin/echo\"]\nargs: [\"hello\", \"world\"]\n...\n```\n\n在Pod定义中`command`和`args`都是可选项，将和Docker镜像的`ENTRYPOINT`和`CMD`相互作用，生成最终容器的启动命令\n\n规则：\n\n-   只要指定了command，就不会使用镜像中的命令\n-   没指定command，指定了args，则将args作为参数使用，命令使用镜像中的命令\n\n###### 环境变量\n\nPod中可以设置容器运行时的环境变量：\n\n```yaml\nenv:\n- name: PARAMETER_1\n  value: value_1\n- name: PARAMETER_2\n  value: value_2\n```\n\n在一些场景下，Pod中的容器希望获取本身的信息，比如Pod的名称，Pod所在的Namespace等，在K8s中提供了`Downward API`获取这些信息，并且可以通过环境变量告诉容器\n\n-   Pod的名称：metadata.name\n-   Pod的Namespace：metadata.namespace\n-   Pod的PodIP：status.podIP\n\n现在创建一个Pod并通过环境变量获取`Downward API`\n\n定义文件downwardapi-env.yaml：\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: downwardapi-env\nspec:\n  containers:\n  - name: test-container\n    image: \"ubuntu:18.04\"\n    command: [\"/bin/bash\", \"-c\", \"while true; do sleep 5; done\"]\n    env:\n      - name: MY_POD_NAME\n        valueFrom:\n          fieldRef:\n            fieldPath: metadata.name\n      - name: MY_POD_NAMESPACE\n        valueFrom:\n          fieldRef:\n            fieldPath: metadata.namespace\n      - name: MY_POD_IP\n        valueFrom:\n          fieldRef:\n            fieldPath: status.podIP\n```\n\n```bash\n# 创建Pod\n$ kubectl create -f downwardapi-env.yaml\n# 输出Pod内环境变量\n$ kubectl exec downwardapi-env env | grep MY_POD\nMY_POD_NAME=downwardapi-env\nMY_POD_NAMESPACE=default\nMY_POD_IP=10.0.10.103\n```\n\n\n\n###### 端口\n\n在Docker中运行容器通过`-p`/`--publish`参数设置端口映射规则\n\n在Pod的定义中也可以设置端口映射规则\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n      - name: web\n        containerPort: 80\n        protocol: TCP\n        hostIP: 0.0.0.0\n        hostPort: 80\n```\n\n在Pod的定义中，通过`.spec.containers[].ports[]`设置容器的端口，数组形式，参数含义：\n\n-   name：端口名称，Pod内唯一，当只配置一个端口的时候，这是可选的，当配置多个端口的时候，这是必选的\n-   containerPort：**必选**，设置在容器内的端口\n-   protocol：可选，设置端口协议，TCP或UDP，默认是TCP\n-   hostIP：可选，设置在宿主机上的IP，默认绑定到所有可用的IP接口上，即0.0.0.0\n-   hostPort：可选，设置在宿主机上的端口，如果设置则进行端口映射\n\n>   使用宿主机端口需要考虑端口冲突问题，幸运的是，K8s在调度Pod的时候，会检查宿主机端口是否冲突。比如两个Pod都需要使用宿主机80端口，那么调度的时候会将两个Pod调度到不同的Node上。如果所有Node的端口都被占用了，那么Pod调度失败。\n\n###### 数据持久化和共享\n\n容器是临时存在的，如果容器被销毁，容器中的数据将会丢失\n\n为了能够持久化数据以及共享容器间的数据，Docker提出了数据卷（Volume）的概念\n\n数据卷就是目录或者文件，它可以绕过联合文件系统，以正常的文件或者目录的形式存在与宿主机上\n\n使用`docker run`运行容器的时候，我们经常使用参数`--volume`/`-v`创建数据卷，将宿主机上的目录或者文件挂载到容器中。即使容器被销毁，数据卷中的数据仍然保存在宿主机上。\n\n\n\nK8s对Docker数据卷进行了扩展，支持对接第三方存储系统。且K8s中的数据卷是Pod级别的，Pod中的容器可以访问共同的数据卷，实现容器间的数据共享。\n\n我们对HelloWorldPod进行改造：\n\n在Pod中声明创建数据卷，Pod中的两个容器将共享数据卷，容器`write`写入数据，容器`read`读出数据\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-world\nspec:\n  restartPolicy: Never\n  containers:\n  - name: write\n    image: \"ubuntu:18.04\"\n    command:\n      - \"bash\"\n      - \"-c\"\n      - \"echo 'hello world' >> /data/hello\"\n    volumeMounts:\n      - name: data\n        mountPath: /data\n  - name: read\n    image: \"ubuntu:18.04\"\n    command:\n      - \"bash\"\n      - \"-c\"\n      - \"sleep 10; cat /data/hello\"\n    volumeMounts:\n      - name: data\n        mountPath: /data\n  volumes:\n    - name: data\n      hostPath:\n        path: /tmp\n\n```\n\n##### Pod的网络\n\nPod中所有容器网络都是共享的，一个Pod中的所有容器的网络是一致的，它们能够通过本地地址访问其他用户容器的端口\n\nK8s网络模型中，每一个Pod都拥有一个扁平化共享网络命令空间的IP，称为PodIP。\n\n```bash\n$ kubectl get pod my-app --template={{.status.podIP}}\n10.0.10.204\n```\n\n这是Docker为容器进行网络虚拟化隔离而分配的内部IP。也可以设置Pod为Host网络模式，即直接使用宿主机网络，不进行网络虚拟化隔离。Pod的PodIP就是其所在Node的IP。\n\n通过`.spec.hostNetwork`设置Pod为Host网络模式\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: host-network-mode\nspec:\n  containers:\n  - name: host-network-mode\n    image: nginx\n    ports:\n      - containerPort: 80\n        protocol: TCP\n        name: web\n  hostNetwork: true\n```\n\n注意：\n\n1.  不存在网络隔离，所以容易发生端口冲突\n2.  Pod可以直接访问宿主机上的所有网络设备和服务，从安全性上来说是不可控的\n\n##### Pod的重启策略\n\n重启策略通过`.spec.restartPolicy`设置，目前支持3种策略\n\n-   Always：当容器终止退出后，总是重启容器，默认\n-   OnFailure：当容器终止异常退出时，才重启容器\n-   Never：当容器终止退出时，从不重启\n\n>   Pod中的容器重启次数统计，实际并不是非常精确，只能作为一个参考\n\n##### Pod的状态和生命周期\n\n###### 容器状态\n\nPod的本质是一组容器\n\nK8s对Pod中的容器进行了状态的记录\n\n-   Waiting：容器正在等待创建，比如下载镜像\n    -   Reason：等待原因\n-   Running：容器已经创建并且正在运行\n    -   startedAt：容器创建时间\n-   Terminated：容器终止退出\n    -   exitCode：退出码\n    -   signal：容器退出信号\n    -   reason：容器退出原因\n    -   message：容器退出信息\n    -   startedAt：容器创建时间\n    -   finishedAt：容器退出时间\n    -   containerID：容器的ID\n\n```bash\n# 查询Pod状态\n$ kubectl describe pod my-pod\n```\n\n###### Pod的生命周期阶段\n\nPod一旦被分配到Node后，就不会离开这个Node\n\nPod的生命周期阶段：\n\n-   Pending：Pod已经被创建，但是有容器未被创建\n-   Running：Pod已经被调度到Node，所有容器已经创建，并且至少一个容器在运行或者正在重启\n-   Succeeded：Pod中所有容器正常退出\n-   Failed：Pod中所有容器退出，至少一个容器是异常退出的\n\n###### 生命周期回调函数\n\nK8s提供了回调函数，在容器的生命周期的特定阶段执行调用，比如容器在停止前希望执行某项操作，就可以注册相应的钩子函数。\n\n-   PostStart：在容器创建成功后调用\n-   PreStop：在容器被终止前调用\n\n钩子函数的实现方式有以下两种\n\n-   Exec\n\n    执行指定命令\n\n    配置参数：\n\n    command：需要执行的命令，字符串数组\n\n    示例\n\n    ```yaml\n    exec:\n      command:\n      \t- cat\n      \t- /tmp/health\n    ```\n\n-   HTTP\n\n    发起一个HTTP调用请求\n\n    配置参数：\n\n    path：请求的URL路径，可选\n\n    port：请求的端口，必选\n\n    host：请求的IP，可选，默认是Pod的PodIP\n\n    scheme：请求的协议，可选，默认是HTTP\n\n    示例：\n\n    ```yaml\n    httpGet:\n      host: 192.168.1.1\n      path: /notify\n      port: 8080\n    ```\n\n现定义一个Pod，包含一个Java的Web应用服务器，其中设置了PostStart和PreStop回调函数。在容器创建成功后，复制`/sample.war`到`/app`目录。而在容器被终止前，发送HTTP请求到`http://monitor.com:8080/warning`，往监控系统发送一个警告，Pod的定义如下：\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: javaweb\nspec:\n  containers:\n  - name: war\n    image: resouer/sample:v2\n    lifecycle:\n      postStart:\n        exec:\n          command:\n            - \"cp\"\n            - \"/sample.war\"\n            - \"/app\"\n      preStop:\n        httpGet:\n          host: monitor.com\n          path: /warning\n          port: 8080\n          scheme: HTTP\n```\n\n##### 自定义检查Pod\n\n对于Pod是否健康，默认情况下只是检查容器是否正常运行。但有的时候容器正常运行并不代表健康，可能有的应用进程已经阻塞住无法正常处理请求，所以为了提供更加健壮的应用，往往需要定制化的健康检查。\n\nK8s提供`Probe`机制，有两种类型的`Probe`\n\n-   Liveness Probe：用于容器的自定义健康检查，如果检查失败，K8s将会杀死Pod，然后根据重启策略重启Pod\n-   Readiness Probe：用于检查容器的自定义准备状况检查，如果检查失败，K8s会将Pod从服务代理的分发后端移除，即不会分发请求给该Pod\n\n`Probe`支持以下三种检查方法\n\n-   ExecAction\n\n    在容器中执行指定的命令进行检查，当命令执行成功（返回码为0），检查成功。\n\n    配置参数\n\n    command：检查命令，字符串数组\n\n    示例\n\n    ```yaml\n    exec:\n      command:\n        - cat\n        - /tmp/health\n    ```\n\n-   TCPSocketAction\n\n    对Pod中的指定TCP端口进行检查，当TCP端口被占用，检查成功\n\n    配置参数\n\n    port：检查的TCP端口\n\n    示例\n\n    ```yaml\n    tcpSocket:\n      port: 8080\n    ```\n\n-   HTTPGetAction\n\n    发送一个HTTP请求，当返回码介于200~400之间时，检查成功\n\n    配置参数\n\n    path：请求的URI路径，可选\n\n    port：请求的端口，必选\n\n    host：请求的IP，可选，默认为Pod的PodIP\n\n    scheme：请求的协议，可选，默认为HTTP\n\n    示例\n\n    ```yaml\n    httpGet:\n      path: /health\n      port: 8080\n    ```\n\n###### Pod的健康检查\n\n定义一个Pod，使用`Liveness Probe`通过`ExecAction`方式检查容器的健康状态，Pod的定义文件`liveness-exec-pod.yaml`：\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: liveness-exec-pod\n  labels:\n    test: liveness\nspec:\n  containers:\n  - name: liveness\n    image: \"ubuntu:18.04\"\n    command:\n      - \"/bin/sh\"\n      - \"-c\"\n      - \"echo ok > /tmp/health; sleep 60; rm -rf /tmp/health; sleep 600\"\n    livenessProbe:\n      exec:\n        command: [\"cat\", \"/tmp/health\"]\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n```\n\n```bash\n$ kubectl describe pod liveness-exec-pod | grep Unhealthy\n  Warning  Unhealthy  <invalid> (x3 over <invalid>)  kubelet            Liveness probe failed: cat: /tmp/health: No such file or directory\n```\n\n可以看到`Liveness Probe`检查失败并重启了Pod\n\n###### Pod的准备状况检查\n\n定义一个Pod，使用`Readiness Probe`通过ExecAction方式检查容器的准备状况，Pod的定义文件`readiness-exec-pod.yaml`：\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: readiness-exec-pod\n  labels:\n    test: readiness\nspec:\n  containers:\n  - name: readiness\n    image: \"ubuntu:18.04\"\n    command: [\"/bin/sh\", \"-c\", \"echo ok > /tmp/ready; sleep 60; rm -rf /tmp/ready; sleep 600\"]\n    readinessProbe:\n      exec:\n        command: [\"cat\", \"/tmp/ready\"]\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n```\n\n查看Pod，大概一分钟后可以看到Pod的ready数目变为0\n\n```bash\n$ kubectl get pod\nNAME                 READY   STATUS             RESTARTS   AGE\nreadiness-exec-pod   0/1     Running            0          109s\n\n# 查看事件可以看到，Readiness Probe检查失败\n$ kubectl describe pod readiness-exec-pod | grep Unhealthy\n  Warning  Unhealthy  <invalid> (x21 over <invalid>)  kubelet            Readiness probe failed: cat: /tmp/ready: No such file or directory\n```\n\n\n\n##### 调度Pod\n\nPod调度指的是Pod在创建之后分配到哪一个Node上，调度算法分为两个步骤\n\n1.  筛选出符合条件的Node\n2.  选择最优的Node\n\n对于所有的Node，首先K8s通过过滤函数去除不符合条件的Node，K8s v1.1.1支持的过滤函数如下：\n\n-   NoDiskConflict：检查Pod请求的数据卷是否与Node上已存在Pod挂载的数据卷存在冲突，如果存在冲突，则过滤掉该Node\n-   PodFitsResources：检查Node的可用资源（CPU和内存）是否满足Pod的资源请求\n-   PodFitsPorts：检查Pod设置的HostPorts在Node上是否已经被其他Pod占用\n-   PodFitsHost：如果Pod设置了NodeName属性，则筛选出指定的Node\n-   PodSelectorMatches：如果Pod设置了NodeSelector属性，则筛选出符合的Node\n-   CheckNodeLabelPresence：检查Node是否存在`Kubernetes Scheduler`配置的标签\n\n筛选出符合条件的Node来运行Pod，如果存在多个符合条件的Node，那么需要选择出最优的Node。\n\nK8s通过优先级函数来评估出最优的Node，对于每个Node，优先级函数给出一个分数：0~10（10表示最优，0表示最差），每个优先级函数设置有权重值，Node最终分数就是每个优先级函数给出的分数的加权和。\n\nK8s v1.1.1提供的优先级函数有：\n\n-   LeastRequestedPriority：优先选择有最多可用资源的Node\n-   CalculateNodeLabelPriority：优先选择含有指定Label的Node\n-   BalancedResourceAllocation：优先选择资源使用均衡的Node\n\n如何进行Node选择？\n\n-   在定义Pod时通过设置`.spec.nodeSelector`来选择Node\n\n    ```yaml\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: nginx\n      labels:\n        env: test\n    spec:\n      containers:\n        ...\n      nodeSelector:\n        env: test\n    ```\n\n    Pod创建成功后大概率会被分配到有`env=test`标签的Node上\n\n-   在定义Pod时通过`.spec.nodeName`直接指定Node\n\n    ```yaml\n    apiVersion: v1\n    kind: Pod\n    metadata:\n      name: nginx\n      labels:\n        env: test\n    spec:\n      containers:\n        ...\n      nodeName: kube-node-0\n    ```\n\n    {% note warning %}\n\n    还是建议使用`Node Selector`，因为通过`Label`选择是一种弱绑定，而直接指定`Node Name`是一种强绑定，Node失效时会导致`Pod`无法调度\n\n    {% endnote %}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Kubernetes","Docker"],"categories":["啃书"]},{"title":"大型网站技术架构","url":"/posts/499d1db9/","content":"\n\n\n## 大型网站技术架构\n\n### 第1篇 概述\n\n#### 大型网站架构演化\n\n##### 大型网站架构演化发展历程\n\n###### 初始阶段的网站架构\n\n小型网站最开始没有太多人访问，只需要一台服务器就可以了。\n\n![20220517102751693](images/posts-assets/大型网站技术架构.assets/20220517102751693.jpg)\n\n应用程序、数据库、文件等所有的资源都在一台服务器上。\n\n###### 应用服务和数据服务分离\n\n随着网站业务发展，一台服务器逐渐不能满足需求：越来越多的用户访问导致性能越来越差，越来越多的数据导致存储空间不足。这时需要将应用和数据分离。应用和数据分离后整个网站使用三台服务器：应用服务器、文件服务器和数据库服务器。这三台服务器对硬件资源的要求不同，\n\n应用服务器需要处理大量的业务逻辑，所以需要更强大的CPU；\n\n数据库服务器需要快速磁盘检索和数据缓存，所以需要更快的硬盘和更大的内存；\n\n文件服务器需要存储大量用户上传的文件，所以需要更大的硬盘。\n\n![20220517103257768](images/posts-assets/大型网站技术架构.assets/20220517103257768.jpg)\n\n\n\n随着用户逐渐增多，数据库压力太大会导致访问延迟，影响整个网站的性能。\n\n###### 使用缓存改善网站性能\n\n**网站访问特点也遵循二八定律**：80%的业务访问集中在20%的数据上。\n\n淘宝买家浏览的商品集中在少部分成交数多、评价良好的商品上；\n\n百度搜索关键词集中在少部分热门词汇上；\n\n只有经常登录的用户才会发微博、看微博，这部分用户只占总用户数的一小部分。\n\n\n\n把数据缓存在内存中可以减少数据库访问的压力\n\n>   读多写少的情况应该都可以先使用缓存来解决，不管是热门、冷门数据都可以，重点应该是读多写少？\n>\n>   若是写入操作更多，采用缓存的方式需要频繁的更新缓存，如果业务对于一致性有要求，那么需要在更新缓存的方式上做文章，解决一致性的问题；写入操作最终都是要落盘的，即最终一定需要数据库，所以实际上加入缓存并不能很好的缓解数据库的压力。这时候应该要考虑分库分表了。\n\n缓存也分两种：\n\n-   应用服务器上的本地缓存\n\n    访问速度更快，但是内存受限，而且会出现应用程序争用内存的情况\n\n-   分布式缓存服务器上的远程缓存\n\n    可以使用集群的方式，部署大内存的服务器作为专门的缓存服务器，理论上可以做到不受内存容量限制的缓存服务\n\n![20220517143627635](images/posts-assets/大型网站技术架构.assets/20220517143627635.jpg)\n\n使用缓存后，数据访问的压力得到缓解，但是单一应用服务器能够处理的请求连接有限，在访问高峰期，应用服务器成为性能瓶颈。\n\n\n\n###### 使用应用服务器集群改善网站的并发处理能力\n\n当一台服务器的处理能力不足时，不要企图去换更强大的服务器（对于大型网站而言，不管多强大的服务器都不能满足网站持续增长的业务需求）\n\n更恰当的做法是增加服务器的数量来分担压力\n\n![20220517144311935](images/posts-assets/大型网站技术架构.assets/20220517144311935.jpg)\n\n通过负载均衡调度服务器，将用户请求分摊到多台服务器上\n\n>   当负载均衡调度器也成为瓶颈的时候，就需要通过DNS等进行负载均衡了\n\n###### 数据库读写分离\n\n使用缓存之后，大部分的数据读操作可以不通过数据库完成，但是仍有一部分读（缓存未命中、缓存过期）和全部的写操作需要访问数据库，在网站的用户达到一定规模之后，数据库因为负载压力过高而成为网站的瓶颈。\n\n目前大部分的主流数据库都提供主从热备功能，通过配置两台数据库主从关系，可以将一台数据库服务器上的数据更新同步到另一台服务器上。利用这个功能可以实现数据库读写分离。\n\n![20220517145003753](images/posts-assets/大型网站技术架构.assets/20220517145003753.jpg)\n\n应用服务器在写数据的时候，访问主数据库，主数据库将数据同步都从库，应用服务器从从库读取数据。\n\n###### 使用反向代理和CDN加速网站响应\n\n不同地区的用户访问网站时，速度差别还是挺大的，为了有更好的用户体验，需要加速网站访问速度。\n\n主要手段有CDN和反向代理\n\nCDN和反向代理的基本原理都是缓存，区别在于：\n\n-   CDN：部署在网络提供商的机房，用户在请求网站服务时可以从距离自己最近的网络提供商机房获取数据\n-   反向代理：部署在网站的中心机房，当用户请求到达中心机房后，首先访问的服务器是反向代理服务器，如果反向代理服务器中缓存着用户请求的资源，就将其直接返回给用户。\n\n![20220517145615846](images/posts-assets/大型网站技术架构.assets/20220517145615846.jpg)\n\n使用CDN和反向代理的目的在于尽早将数据返回给用户，加快用户访问速度，同时也可以减轻后端服务器的压力。\n\n###### 使用分布式文件系统和分布式数据库系统\n\n**分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用**\n\n更常用的拆分手段是业务分库\n\n![20220517145932862](images/posts-assets/大型网站技术架构.assets/20220517145932862.jpg)\n\n###### 使用NoSQL和搜索引擎\n\n网站业务越来越复杂，对数据存储和检索也越来越复杂，这时候需要采用非关系型数据库和非数据库查询技术如搜索引擎（倒排索引，空间换时间）。\n\n![20220608172046676](images/posts-assets/大型网站技术架构.assets/20220608172046676.jpg)\n\n###### 业务拆分\n\n大型网站根据业务场景，通过分而治之的手段将整个网站业务分成不同的产品线，分归不同的团队负责\n\n具体到技术上，也会根据产品线划分，将一个网站拆分成许多不同的应用，每个应用单独部署维护。\n\n-   通过一个超链接建立关系（首页上的导航链接指向不同的地址）\n-   通过消息队列进行数据分发\n-   访问同一个数据存储系统来构成一个关联的完整系统\n\n>   这部分同下面说的分布式服务的区别在于：仅按业务拆分（拆分成不同的产品线各自独立来开发）会出现许多的冗余，可能每个系统都冗余开发了一套用户管理模块，而分布式服务目的就是为了将这些冗余的业务抽取出来单独部署\n\n![20220608173451442](images/posts-assets/大型网站技术架构.assets/20220608173451442.jpg)\n\n###### 分布式服务\n\n业务拆分导致部署维护越来越困难，且存在许多相同的业务操作，如用户管理、商品管理等，可以将这些共用的业务抽取出来独立部署。\n\n##### 网站架构设计误区\n\n###### 企图用技术解决所有问题\n\n典型的例子就是12306\n\n实际上12306崩溃的原因最大的问题还是在于它的业务架构，12306根本就不应该以窗口售票的模式在网上售票（零点开始出售若干天后的车票）。\n\n后来的改进可能更多的是在业务上进行调整：售票方式上引入排队机制、整点售票调整为分时段售票\n\n\n\n#### 大型网站架构模式\n\n建筑学中对于模式的定义：\n\n>   描述了一个在我们周围不断重复发生的问题及问题解决方案的核心。这样，就能一次又一次地使用该方案而不必重复工作\n\n![20220608175406653](images/posts-assets/大型网站技术架构.assets/20220608175406653.jpg)\n\n##### 网站架构模式\n\n###### 分层\n\n分层时最常见地一种架构模式，将系统在`横向`维度上切分成几个部分，每个部分负责一部分相对比较`单一`的职责，然后通过上层对下层的`依赖`和`调用`组成一个完整的系统。\n\n| 应用层 | 负责具体业务和视图展示，如网站首页及搜索输入和结果展示 |\n| ------ | ------------------------------------------------------ |\n| 服务层 | 为应用层提供服务支持，如用户管理服务，购物车服务等     |\n| 数据层 | 提供数据存储访问服务，如数据库、缓存、文件、搜索引擎等 |\n\n>   是否可以这样理解？\n>\n>   应用层：如前端服务，Vue、React组成的前端项目提供视图展示，具体的数据来源通过Ajax请求后端获取，作为前端项目即可单独部署\n>\n>   服务层：如一个Java-Springboot项目，具体的后端逻辑处理层，暴露接口供前端调用获取数据\n>\n>   数据层：如MySQL、Elasticsearch、Redis等数据存储服务，只做数据存储的功能，具体数据如何使用交给服务层获取后处理\n\n分层架构也有一些挑战，就是必须合理规划层次边界和接口\n\n>   前后端分离开发中需要对前后端联调的接口进行事先规划，才能更好的并行开发\n\n开发过程中严格遵循分层架构的约束，禁止跨层次调用以及逆向调用\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["架构设计"],"categories":["啃书"]},{"title":"Git权威指南","url":"/posts/ca74b95d/","content":"\n## Git权威指南\n\n### 第4章 git初始化\n\n#### 创建版本库及第一次提交\n\n1.   告诉Git当前用户的姓名和邮件地址，配置的用户名和邮件地址将在版本库提交时用到\n\n     ```bash\n     git config --global user.name \"[用户名]\"\n     git config --global user.email \"[邮件地址]\"\n     ```\n\n2.   初始化仓库\n\n     ```bash\n     mkdir demo\n     cd demo\n     git init\n     Initialized empty Git repository in D:/workspace/git/demo/.git/\n     ```\n\n     如果Git版本是1.6.5以上，可以在`git init`命令后面跟上目录名称，会自动完成目录创建\n\n     ```bash\n     git init demo\n     Initialized empty Git repository in D:/workspace/git/demo/.git/\n     ```\n\n至此仓库即创建成功\n\n现在在工作区中创建一个文件welcome.txt\n\n```bash\necho \"Hello.\" > welcome.txt\n```\n\n将新建立的文件添加到版本库\n\n```bash\ngit add welcome.txt\n```\n\n>   Git和大部分其他版本控制系统一样，都需要执行一次提交操作，对于Git来说就是执行`git commit`命令。\n>\n>   在提交过程中需要输入提交说明，这个要求对Git来说是强制性的（不接受空白提交说明），就算在提交时不在命令行提供，Git会自动打开一个编辑器要求输入提交说明的。\n\n使用`-m`参数直接给出提交说明\n\n```bash\ngit commit -m \"initialized.\"\n[master (root-commit) dbda1b1] initialized.\n 1 file changed, 1 insertion(+)\n create mode 100644 welcome.txt\n\n```\n\n-   通过`-m`参数设置提交说明\n-   命令输出显示此次提交在名为master的分支上，且是该分支的第一次提交（root-commit），提交ID是dbda1b1。\n-   此次提交修改了一个文件，包含一行插入（新增）\n-   此次提交创建了新文件welcome.txt\n\n如果之前没有设置用户名和邮箱，则会出现如下内容：\n\n```bash\nAuthor identity unknown\n\n*** Please tell me who you are.\n\nRun\n\n  git config --global user.email \"you@example.com\"\n  git config --global user.name \"Your Name\"\n\nto set your account's default identity.\nOmit --global to set the identity only in this repository.\n\nfatal: unable to auto-detect email address (got 'User@8-sri0091.(none)')\n\n```\n\n#### 思考：为什么工作区根目录有一个.git目录\n\n初始化仓库之后，会在根目录出现名为`.git`的隐藏目录\n\nWindows用户需要通过如下方式设置后才可以看到\n\n![20220516153036140](images/posts-assets/Git权威指南.assets/20220516153036140.jpg)\n\nLinux用户通过以下命令可查看\n\n```bash\nls -a\n./  ../  .git/\n\n```\n\nGit以及其他分布式版本控制系统的一个共同的显著特点是，版本库位于工作区的根目录下。对Git来说就是`.git`目录，且仅此一处，没有任何其他跟踪文件或目录了。\n\n传统集中式版本控制系统的版本库和工作区是分开的，甚至是在不同的主机上，因此必须建立工作区和版本库的对应。\n\nGit将版本库（`.git`目录）放在工作区根目录下，那么Git的相关操作一定要在工作区根目录下执行吗？换句话说，当工作区中包含子目录，并在子目录中执行Git命令，如何定位到版本库的？\n\n实际上，当在Git工作区的某个子目录下执行操作的时候，会在工作区目录中依次向上递归查找`.git`目录，找到的`.git`目录就是工作区对应的版本库了。\n\n例如在非Git工作区执行`git`命令时会因为找不到`.git`目录报错\n\n```bash\ncd /d/workspace/git\ngit status\nfatal: not a git repository (or any of the parent directories): .git\n\n```\n\n使用`strace`命令去跟踪执行`git status`命令时的磁盘访问，可以看到沿目录依次向上递归的过程。\n\n```bash\nstrace -e 'trace=file' git status\n```\n\n\n\n显示版本库`.git`目录所在位置\n\n```bash\ngit rev-parse --git-dir\nD:/workspace/git/demo/.git\n\n```\n\n显示工作区根目录\n\n```bash\ngit rev-parse --show-toplevel\nD:/workspace/git/demo\n\n```\n\n相对于工作区根目录的相对目录\n\n```bash\ngit rev-parse --show-prefix\na/b/c/\n\n```\n\n显示从当前目录后退到工作区根目录的深度\n\n```bash\ngit rev-parse --show-cdup\n../../../\n\n```\n\n#### 思考：git config命令的各参数区别\n\nGit的配置文件分别是版本库级别、全局（用户主目录下，用户级）和系统级别。\n\n`--global`：全局级别\n\n`--system`：系统级别\n\n\n\n### 第5章 git暂存区\n\n#### 修改不能直接提交吗\n\n首先进行文件追加\n\n```bash\necho \"Nice to meet you.\" >> welcome.txt\n```\n\n```bash\ngit diff\ndiff --git a/welcome.txt b/welcome.txt\nindex 18832d3..fd3c069 100644\n--- a/welcome.txt\n+++ b/welcome.txt\n@@ -1 +1,2 @@\n Hello.\n+Nice to meet you.\n\n```\n\n需要执行`git add`命令将文件修改添加到暂存区之后才可以进行提交\n\n如果直接执行提交操作\n\n```bash\ngit commit -m \"Append a nice line.\"\nOn branch master\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n        modified:   welcome.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\n```\n\n\n\n#### 理解Git暂存区（stage）\n\n在版本库`.git`目录下有一个index文件，下面针对这个文件做一个实验\n\n1.   撤销工作区中对welcome.txt文件尚未提交的更改\n\n     ```bash\n     git checkout -- welcome.txt # 撤销工作区中对welcome.txt文件尚未提交的更改\n     git status -s # 如果git版本小于1.7.3，执行git diff\n     ```\n\n     \n\n2.   查看.git/index文件\n\n     ```bash\n     ls --full-time .git/index\n     -rw-r--r-- 1 User 197121 145 2022-05-16 19:17:16.292820100 +0800 .git/index\n     \n     ```\n\n3.   再次执行\n\n     ```bash\n     git status -s # 再次执行\n     ls --full-time .git/index\n     -rw-r--r-- 1 User 197121 145 2022-05-16 19:17:16.292820100 +0800 .git/index\n     \n     ```\n\n     可以看到时间戳不变\n\n4.   现在修改下welcome.txt的时间戳，但是不改变它的内容\n\n     ```bash\n     ls --full-time welcome.txt\n     -rw-r--r-- 1 User 197121 25 2022-05-16 19:18:32.223701400 +0800 welcome.txt\n     touch welcome.txt\n     ls --full-time welcome.txt # 可以看到时间戳更新了\n     -rw-r--r-- 1 User 197121 25 2022-05-16 19:24:35.298879700 +0800 welcome.txt\n     git status -s\n     ls --full-time .git/index # 时间戳更新了\n     -rw-r--r-- 1 User 197121 145 2022-05-16 19:25:20.322562900 +0800 .git/index\n     \n     ```\n\n实验说明`git status`命令是先根据.git/index文件中记录的（用于跟踪工作区文件的）时间戳、长度等信息判断工作区文件是否改变，如果工作区文件的时间戳改变了，说明文件的内容可能被改变了，需要打开文件，读取文件内容进行比较。如果文件内容没变，则将该文件的新时间戳记录到.git/index文件中。因为如果要判断文件是否更改，使用时间戳、文件长度等信息进行比较要比通过文件内容比较要快得多，这也是Git高效的原因之一。\n\n文件.git/index实际就是一个包含文件索引的目录数，记录了文件名和文件的状态信息（时间戳和文件长度等）。文件内容保存在.git/objects目录中\n\n![20220516193323223](images/posts-assets/Git权威指南.assets/20220516193323223.jpg)\n\n-   左侧为工作区，右侧为版本库。在版本库中标记为index的区域是暂存区，标记为master的是master分支所代表的目录树。\n-   此时HEAD实际是指向master分支的一个“游标”，所以图示的命令中出现HEAD的地方可以用master替换。\n-   图中的objects为Git对象库，实际位于.git/objects目录下。\n-   当对工作区修改（或新增）的文件执行`git add`命令时，暂存区的目录树将被更新，同时工作区修改（或新增）的文件内容会被写入对象库中的一个新的对象中，而该对象的ID被记录在暂存区的文件索引中。\n-   当执行`git commit`时，暂存区的目录树会写到版本库（对象库）中，master分支会做相应的更新，即master最新指向的目录树就是提交时原暂存区的目录树。\n-   当执行`git reset HEAD`命令时，暂存区的目录树会被重写，会被master分支指向的目录树所替换，但是工作区不受影响。\n-   当执行`git rm --cached <file>`命令时，会直接从暂存区删除文件，工作区不做出改变。\n-   当执行`git checkout .`或`git checkout -- <file>`命令时，会用暂存区全部文件或指定文件替换工作区文件。这个操作很危险，会清除工作区中未添加到暂存区的改动。\n-   当执行`git checkout HEAD .`或`git checkout HEAD <file>`命令时，会用HEAD指向的master分支中的全部或部分文件替换暂存区和工作区中的文件。这个命令极其危险，因为不但会清楚工作区中未提交的改动，也会清除暂存区中未提交的改动。\n\n栗子：\n\n```bash\ntouch new.txt # 创建新文件\ngit status\nOn branch master\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n        new.txt\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n\ngit add new.txt # 添加到暂存区\ngit status\nOn branch master\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n        new file:   new.txt\n\necho \"new line.\" >> new.txt # 更新文件\ngit status\nOn branch master\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n        new file:   new.txt\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n        modified:   new.txt\n# 此时工作区中有更改未提交（新增数据的更改）到暂存区，暂存区也有更改未提交（新增文件）到版本库\ngit checkout -- new.txt\ngit status\nOn branch master\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n        new file:   new.txt\n# 此时工作区中未提交的修改已经被清除了\ncat new.txt\n# 查看new.txt的内容，没有发现新增的数据\n# 重新将文件更改，这里就省略了\ngit reset HEAD\ngit status\nOn branch master\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n        new.txt\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n# 可以看到暂存区未提交的更改被清除，new.txt变成了未追踪状态了\n# 工作区中的内容不受影响\ncat new.txt\nnew line.\n# 重新恢复下状态，这里省略了\ngit status\nOn branch master\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n        new file:   new.txt\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n        modified:   new.txt\n\ngit rm --cached new.txt\nerror: the following file has staged content different from both the\nfile and the HEAD:\n    new.txt\n(use -f to force removal)\n# 此时三个区域的状态均不同，所以不允许此操作，可以使用-f参数强制执行\ngit rm --cached -f new.txt\ngit status\nOn branch master\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n        new.txt\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n# 此时暂存区中文件被删除了，所以new.txt变成了未追踪状态，工作区中文件不变\n# 恢复下状态，这里省略了\ngit status\nOn branch master\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n        new file:   new.txt\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n        modified:   new.txt\n\ngit commit -m \"add new.txt\" # 将新增的new.txt提交到版本库\ngit status\nOn branch master\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n        modified:   new.txt\n# new.txt新增数据的更新还在工作区中\ngit add new.txt\necho \"new new line.\" >> new.txt\ngit status\nOn branch master\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n        modified:   new.txt\n\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n        modified:   new.txt\n\n git checkout master new.txt # 此操作将清空工作区和暂存区的更改\n git status\n On branch master\nnothing to commit, working tree clean\ncat new.txt\n# 最终new.txt中没有内容，被替换成了版本库中的版本了\n```\n\n#### git diff\n\n**工作区、暂存区和版本库的目录树浏览**\n\n直观地查看暂存区及HEAD中的目录树？\n\n对于HEAD（版本库中当前提交）指向的目录树，可以使用Git底层命令`ls-tree`查看\n\n```bash\ngit ls-tree -l HEAD\n100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391       0    new.txt\n100644 blob fd3c069c1de4f4bc9b15940f490aeb48852f3c42      25    welcome.txt\n\n```\n\n-   `-l`参数可以显示文件的大小\n\n`git ls-files`命令可以显示暂存区目录树\n\n```bash\ngit ls-files -s\n100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 0       new.txt\n100644 9ac7e0760066ad8d06a0d952c4e1260e628551b4 0       welcome.txt\n\n```\n\n第三列不是文件大小，而是文件编号\n\n\n\n**git diff**\n\n1.   工作区与暂存区比较\n\n     ```bash\n     git diff\n     diff --git a/new.txt b/new.txt\n     index e69de29..2595e07 100644\n     --- a/new.txt\n     +++ b/new.txt\n     @@ -0,0 +1 @@\n     +new line.\n     \n     ```\n\n2.   暂存区和HEAD比较\n\n     ```bash\n     git diff --cached\n     index fd3c069..9ac7e07 100644\n     --- a/welcome.txt\n     +++ b/welcome.txt\n     @@ -1,2 +1,3 @@\n      Hello.\n      Nice to meet you.\n     +Bye bye.\n     \n     ```\n\n3.   工作区和HEAD比较\n\n     ```bash\n     git diff HEAD\n     diff --git a/new.txt b/new.txt\n     index e69de29..2595e07 100644\n     --- a/new.txt\n     +++ b/new.txt\n     @@ -0,0 +1 @@\n     +new line.\n     diff --git a/welcome.txt b/welcome.txt\n     index fd3c069..9ac7e07 100644\n     --- a/welcome.txt\n     +++ b/welcome.txt\n     @@ -1,2 +1,3 @@\n      Hello.\n      Nice to meet you.\n     +Bye bye.\n     \n     ```\n\n### 第6章 git对象\n\n#### Git对象库\n\n```bash\ngit log -1 --pretty=raw\ncommit 86343253f0d44b3a002b11423c02587fd3040e07 # 这些数字实际上是SHA1哈希值，这是本次提交的唯一标识\ntree f341012ebeaf74262be6892be96ecce373a68ef3 # 这是本次提交所对应的目录树\nparent ca04d27bdf1a442d67c379fd5803f5b85c868bd5 # 这是本次提交的父提交（上一次提交）\nauthor Crayon <614820984@qq.com> 1652703487 +0800\ncommitter Crayon <614820984@qq.com> 1652703487 +0800\n\n    add new.txt\n\n```\n\n研究Git对象ID可以使用`git cat-file`命令\n\n```bash\ngit cat-file -t <ID> # 查看ID类型\ngit cat-file -p <ID> # 查看文件内容\n```\n\n#### SHA1哈希值是什么\n\n哈希是一种摘要算法（散列算法），可以将任意长度的输入经过散列运算转换为固定长度的输出。\n\n比较著名的摘要算法有MD5和SHA1\n\nLinux下使用`sha1sum`命令可以生成摘要\n\n```bash\nprintf Git | sha1sum\n5819778898df55e3a762f0c5728b457970d72cae *-\n\n```\n\n提交的SHA1哈希值是如何生成的\n\n-   查看HEAD对应的提交内容\n\n    ```bash\n    git cat-file commit HEAD\n    tree f341012ebeaf74262be6892be96ecce373a68ef3\n    parent ca04d27bdf1a442d67c379fd5803f5b85c868bd5\n    author Crayon <614820984@qq.com> 1652703487 +0800\n    committer Crayon <614820984@qq.com> 1652703487 +0800\n    \n    add new.txt\n    \n    ```\n\n-   提交信息中总共包含个210字符\n\n    ```bash\n    git cat-file commit HEAD | wc -c\n    210\n    \n    ```\n\n-   在提交信息的前面加上内容commit 210\\<null>（\\<null>为空字符），然后执行SHA1算法\n\n    ```bash\n    (printf \"commit 210\\000\"; git cat-file commit HEAD) | sha1sum\n    86343253f0d44b3a002b11423c02587fd3040e07 *-\n    \n    git rev-parse HEAD\n    86343253f0d44b3a002b11423c02587fd3040e07\n    \n    ```\n\n文件内容的SHA1哈希值是如何生成的\n\n-   查看版本库中welcome.txt的内容\n\n    ```bash\n    git cat-file blob HEAD:welcome.txt\n    Hello.\n    Nice to meet you.\n    \n    ```\n\n-   文件总共包含25字节的内容\n\n    ```bash\n    git cat-file blob HEAD:welcome.txt | wc -c\n    25\n    \n    ```\n\n-   在文件内容的前面加上blob 25\\<null>，然后执行SHA1算法\n\n    ```bash\n    (printf \"blob 25\\000\"; git cat-file blob HEAD:welcome.txt) | sha1sum\n    fd3c069c1de4f4bc9b15940f490aeb48852f3c42 *-\n    git rev-parse HEAD:welcome.txt\n    fd3c069c1de4f4bc9b15940f490aeb48852f3c42\n    \n    ```\n\n\n\n>   HEAD代表版本库中最近一次提交\n>\n>   符号`^`可以用于指代父提交。例如：\n>\n>   -   `HEAD^`代表版本库中的上一次提交，即最近一次提交的父提交\n>   -   `HEAD^^`则代表`HEAD^`的父提交\n>\n>   对于一个提交有很多个父提交，可以在符号`^`后面用数字表示第几次提交。例如：\n>\n>   -   `a573106^2`的含义是提交`a573106`的多个父提交中的第二个父提交（日志分支图体现在横向）（不是祖先提交！）[例子](#8.2.multi-parent)\n>   -   `HEAD^1`相当于`HEAD^`\n>\n>   符号`~<n>`也可以用于指代祖先提交（日志分支图体现在纵向）。例如：\n>\n>   `a573106~5`相当于`a573106^^^^^`\n\n\n\n### 第7章 git重置\n\nmaster分支在版本库的引用目录（.git/refs）中体现为一个引用文件`.git/refs/heads/master`，其内容就是分支中最新提交的提交ID\n\n```bash\ncat .git/refs/heads/master\n86343253f0d44b3a002b11423c02587fd3040e07\n\n```\n\n\n\n添加新文件，查看ID\n\n```bash\ntouch new-commit.txt\ngit add new-commit.txt\ncat .git/refs/heads/master\n724d3845eb776ded300fedf37e8642b81c6f8b54\n\n```\n\n引用`refs/heads/master`就像一个游标，在有新的提交的时候指向了新的提交\n\n`git reset`命令可以将“游标”指向任意一个存在的提交ID\n\n重置之后如果没有记住提交ID，通过浏览历史记录是找不到的\n\n#### 用reflog挽救错误的重置\n\n如果没有重置前master分支指向的提交ID，想要重置回原来的提交似乎是一件麻烦的事（去对象库中一个一个地找）。\n\n`.git/logs`目录下日志文件记录了分支变更情况。默认非裸版本库（带有工作区）都提供分支日志功能，这是因为带有工作区的版本库都有如下设置：\n\n```bash\ngit config core.logallrefupdates\ntrue\n\n```\n\n查看master分支的日志文件`.git/logs/refs/heads/master`中的内容\n\n```bash\ntail -5 .git/logs/refs/heads/master\n86343253f0d44b3a002b11423c02587fd3040e07 33d9b1023f6be2ae49454973d071be2b28e1facb Crayon <614820984@qq.com> 1652790561 +0800    commit: new commit\n33d9b1023f6be2ae49454973d071be2b28e1facb 86343253f0d44b3a002b11423c02587fd3040e07 Crayon <614820984@qq.com> 1652790577 +0800    reset: moving to HEAD~1\n86343253f0d44b3a002b11423c02587fd3040e07 724d3845eb776ded300fedf37e8642b81c6f8b54 Crayon <614820984@qq.com> 1652790678 +0800    reset: moving to 724d3845eb776ded300fedf37e8642b81c6f8b54\n724d3845eb776ded300fedf37e8642b81c6f8b54 86343253f0d44b3a002b11423c02587fd3040e07 Crayon <614820984@qq.com> 1652790709 +0800    reset: moving to HEAD~1\n86343253f0d44b3a002b11423c02587fd3040e07 724d3845eb776ded300fedf37e8642b81c6f8b54 Crayon <614820984@qq.com> 1652790722 +0800    reset: moving to 724d3845eb776ded300fedf37e8642b81c6f8b54\n\n\n```\n\n第一列表示原指向，第二列表示变更后指向，文件最后是最新的记录\n\nGit提供`git reflog`命令\n\n```bash\ngit reflog show master | head -5 # head -5表示取前五行\n724d384 HEAD@{0}: reset: moving to 724d3845eb776ded300fedf37e8642b81c6f8b54\n8634325 HEAD@{1}: reset: moving to HEAD~1\n724d384 HEAD@{2}: reset: moving to 724d3845eb776ded300fedf37e8642b81c6f8b54\n8634325 HEAD@{3}: reset: moving to HEAD~1\n33d9b10 HEAD@{4}: commit: new commit\n\n```\n\n与日志文件不同，这里输出的第一行即为最新版本\n\n`git reflog`命令在输出中提供了一个方便易记的表达式：\\<refname>@{\\<n>}\n\n这个表达式的含义是引用\\<refname>之前第\\<n>次改变时的SHA1哈希值\n\n-   重置master为两次改变之前的值\n\n    ```bash\n    git reset --hard master@{2}\n    ```\n\n    重置后就能成功回到被撤销的版本了\n\n#### 深入了解`git reset`命令\n\n`git reset`命令有两种用法\n\n```bash\n$ git reset [-q] [<commit>] [--] <paths>...\n$ git reset [--soft | --mixed | --hard | --merge | --keep] [-q] [<commit>]\n```\n\n<span id=\"7.2.reset-default\">上述两种用法中，其中\\<commit>都是可选项，可以使用引用或提交ID，如果省略\\<commit>则相当于使用HEAD的指向作为提交ID。</span>\n\n第一种用法在命令中包含路径\\<paths>，为了避免和提交ID同名而发生冲突，可以在\\<paths>前用两个连续的`-`作为分隔。\n\n>   第一种用法不会重置引用，更不会改变工作区，而是用指定的提交状态下的文件替换掉暂存区中的文件。\n>\n>   例子：\n>\n>   ```bash\n>   # 先往new.txt添加新内容\n>   echo \"new line.\" >> new.txt\n>   git add new.txt\n>   git status\n>   On branch master\n>   Changes to be committed:\n>     (use \"git restore --staged <file>...\" to unstage)\n>           modified:   new.txt\n>   \n>   git reset -- new.txt\n>   Unstaged changes after reset:\n>   M       new.txt\n>   \n>   git status\n>   On branch master\n>   Changes not staged for commit:\n>     (use \"git add <file>...\" to update what will be committed)\n>     (use \"git restore <file>...\" to discard changes in working directory)\n>           modified:   new.txt\n>   # 可以看到刚刚的提交被撤销了\n>   ```\n\n第二种用法则会重置引用，而且根据参数的不同可以对工作区或暂存区进行重置\n\n![20220518160543182](images/posts-assets/Git权威指南.assets/20220518160543182.jpg)\n\n命令格式：`git reset [--soft | --mixed | --hard] [<commit>]`\n\n-   `--hard`参数：会执行上图中的全部动作①、②、③，即：\n    1.   替换引用的指向。引用指向新的提交ID。\n    2.   替换暂存区。替换后，暂存区的内容和引用指向的目录树一致。\n    3.   替换工作区。替换后，工作区的内容变得和暂存区一致，也和HEAD所指向的目录树一致。\n-   `--soft`参数：会执行动作①。即只更改引用的指向，不改变暂存区和工作区。\n-   `--mixed`参数或不加参数（默认`--mixed`）：会执行动作①、②。即更改引用的指向并重置暂存区，但是不改变工作区。\n\n例子：\n\n-   `git reset`（同`git reset HEAD`）\n\n    用HEAD指向的目录树重置暂存区，工作区不会受到影响。\n\n    >   相当于将之前用`git add`命令添加到暂存区的内容撤出\n\n-   `git reset --soft HEAD^`\n\n    工作区和暂存区不做改变，但是引用回退一次。当对最新提交的提交说明或提交更改不满意的时候，撤销最新的提交以便重新提交。\n\n    >   `git commit --amend`用于对最新的提交进行重新提交以修补错误的提交说明或提交文件。\n    >\n    >   相当于执行了下面两条命令\n    >\n    >   ```bash\n    >   git reset --soft HEAD^\n    >   git commit -e -F .git/COMMIT_EDITMSG # .git/COMMIT_EDITMSG保存了上次的提交日志\n    >   ```\n\n-   `git reset HEAD^`同（`git reset --mixed HEAD^`）\n\n    工作区不变，将暂存区和引用回退一次\n\n-   `git reset --hard HEAD^`\n\n    彻底撤销最近的提交。工作区、暂存区、引用全部回退。\n\n### 第8章 git检出\n\n重置命令的一个用途就是修改引用的游标指向。\n\n~~重置命令没有使用任何参数对所要重置的分支名进行设置，这是因为重置命令针对的是头指针`HEAD`。~~\n\n重置命令没有改变头指针`HEAD`的内容是因为HEAD指向了一个引用`rerf/heads/master`，所以重置命令体现为分支“游标”的变更，`HEAD`本身一直指向的是`refs/heads/master`，并没有在重置时改变。\n\n#### HEAD的重置即检出\n\n`HEAD`可以理解为“头指针”，是当前工作区的“基础版本”，当执行提交时，将指向最新的提交\n\n查看当前`HEAD`的指向\n\n```bash\n$ cat .git/HEAD\nref: refs/heads/master\n$ git branch -v\n* master 8634325 add new.txt\n```\n\n用`git checkout`命令检出该ID的父提交\n\n```bash\n$ git checkout 8634325^\nNote: switching to '8634325^'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c <new-branch-name>\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at ca04d27 Append a nice line.\n\n```\n\n出现大段的输出，意思就是现在处于“分离头指针”的状态，在这个状态下执行另一个`checkout`命令检出则会丢弃在此状态下的修改和提交，如果想要保留此状态下的修改和提交，使用`-b`参数调用`checkout`命令来创建新的跟踪分支，如：\n\n`git checkout -b new_branch_name`\n\n\n\n查看`HEAD`的内容可以发现头指针指向了一个具体的提交\n\n```bash\n$ cat .git/HEAD\nca04d27bdf1a442d67c379fd5803f5b85c868bd5\n```\n\n使用`reflog`命令也可以看到头指针被更改了\n\n```bash\n$ git reflog -1\nca04d27 (HEAD) HEAD@{0}: checkout: moving from master to 8634325^\n```\n\n>   `reflog`的内容是`HEAD`头指针的变迁记录，而不是`master`分支\n\n```bash\n$ git rev-parse HEAD master\nca04d27bdf1a442d67c379fd5803f5b85c868bd5\n86343253f0d44b3a002b11423c02587fd3040e07\n```\n\n可以看到`HEAD`和`master`指向不同的提交\n\n`checkout`和`reset`命令不同，分支（`master`）的指向没有改变，还是指向的原有提交的ID\n\n试着做一次更改，并加入到暂存区\n\n```bash\n$ touch detached-commit.txt\n$ git add detached-commit.txt\n$ git status\nHEAD detached at ca04d27\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n        new file:   detached-commit.txt\n```\n\n执行提交并查看头指针指向\n\n```bash\n$  git commit -m \"commit in detached HEAD mode\"\n[detached HEAD ccedb9c] commit in detached HEAD mode\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 detached-commit.txt\n \n $ cat .git/HEAD\nccedb9c816bd52920c9ba001c04067c935363f83\n```\n\n头指针指向最新的提交\n\n查看日志也可以发现新的提交建立在之前的提交基础之上\n\n```bash\n$ git log --graph --oneline\n* ccedb9c (HEAD) commit in detached HEAD mode\n* ca04d27 Append a nice line.\n* 6e314b7 empty commit\n* dbda1b1 initialized.\n```\n\n>   记下新的提交ID（ccedb9c）\n\n以`master`分支名作为参数执行`checkout`命令将分支切换到`master`上\n\n```bash\n$ git checkout master\nWarning: you are leaving 1 commit behind, not connected to\nany of your branches:\n\n  ccedb9c commit in detached HEAD mode\n\nIf you want to keep it by creating a new branch, this may be a good time\nto do so with:\n\n git branch <new-branch-name> ccedb9c\n\nSwitched to branch 'master'\n\n```\n\n通过日志已经看不到之前的提交了，但是仍然存在于对象库中（但是因为这个提交没有被任何分支跟踪到，所以不保证这个提交会永久存在）\n\n```bash\n$ git log --graph --pretty=oneline\n* 86343253f0d44b3a002b11423c02587fd3040e07 (HEAD -> master) add new.txt\n* ca04d27bdf1a442d67c379fd5803f5b85c868bd5 Append a nice line.\n* 6e314b7f5526662dd54dc3c7e2058010557ccb5b empty commit\n* dbda1b1f8b84a477531578bd15917da5686ee8f2 initialized.\n```\n\n#### 挽救分离头指针\n\n刚才分离头指针状态下的提交只能通过提交ID访问到，如果使用`reset`虽然可以将`master`分支重置到该提交，但是就会丢到当前`master`的最新提交（`reset`命令体现出来的就是分支游标的改变）\n\n这个时候需要使用`merge`（合并）操作\n\n将`ccedb9c`这个提交合并到当前分支上\n\n```bash\n$ git merge ccedb9c\nMerge made by the 'ort' strategy.\n detached-commit.txt | 0\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 detached-commit.txt\n\n```\n\n查看日志可以看到不一样的分支图\n\n```bash\n$ git log --graph --oneline\n*   b06ad0b (HEAD -> master) Merge commit 'ccedb9c'\n|\\\n| * ccedb9c commit in detached HEAD mode\n* | 8634325 add new.txt\n|/\n* ca04d27 Append a nice line.\n* 6e314b7 empty commit\n* dbda1b1 initialized.\n\n```\n\n查看最新提交的信息，可以看到该提交有<span id=\"8.2.multi-parent\">两个父提交</span>\n\n```bash\n$ git cat-file -p HEAD\ntree d8102c804d8cbf350b31dc6a38fe384ed5586559\nparent 86343253f0d44b3a002b11423c02587fd3040e07\nparent ccedb9c816bd52920c9ba001c04067c935363f83\nauthor Crayon <614820984@qq.com> 1655277888 +0800\ncommitter Crayon <614820984@qq.com> 1655277888 +0800\n\nMerge commit 'ccedb9c'\n\n```\n\n#### 深入了解`git checkout`命令\n\n三种用法\n\n```bash\n$ git checkout [-q] [<commit>] [--] <paths>...\n$ git checkout [<branch>]\n$ git checkout [-m] [[-b|--orphan] <new_branch>] [<start_point>]\n```\n\n第一种用法的`--`主要是用来避免引用和路径同名发生冲突\n\n-   第一种用法的\\<commit>是可选项，如果省略则相当于从暂存区进行检出，这和[重置命令](#7.2.reset-default)不同（重置默认值是`HEAD`）\n\n    重置一般用于重置暂存区（除非使用`--hard`参数，否则不重置工作区），而检出命令主要是覆盖工作区（如果\\<commit>不省略，也会替换暂存区中的相应文件）\n\n-   第一种用法（包含\\<paths>的用法）不会改变`HEAD`头指针，主要用于指定版本的文件覆盖工作区中对应的文件。如果省略\\<commit>，则会用暂存区中的文件覆盖工作区的文件，否则用指定提交中的文件覆盖暂存区和工作区中对应的文件\n\n    ```bash\n    # 查看当前版本下的文件内容\n    $ cat welcome.txt\n    Hello.\n    Nice to meet you.\n    \n    # 追加一行，并添加到暂存区\n    $ echo 'new line.' >> welcome.txt\n    $ git add welcome.txt\n    \n    # 再次追加一行内容\n    $ echo 'new new line.' >> welcome.txt\n    \n    # 此时的文件内容\n    $ cat welcome.txt\n    Hello.\n    Nice to meet you.\n    new line.\n    new new line.\n    \n    # 通过使用暂存区文件内容覆盖工作区文件内容实现撤销修改的目的\n    $ git checkout -- welcome.txt\n    \n    # 此时的文件内容\n    $ cat welcome.txt\n    Hello.\n    Nice to meet you.\n    new line.\n    \n    # 将修改提交\n    $ git commit -m \"append new line to welcome.txt\"\n    \n    # 追加一行并添加到暂存区\n    $ echo 'new new line.' >> welcome.txt\n    $ git add welcome.txt\n    \n    # 使用指定版本的文件内容覆盖当前工作区与暂存区中的文件内容实现单个文件版本回退的效果\n    $ git checkout 095d003 -- welcome.txt\n    \n    $ git status\n    On branch master\n    nothing to commit, working tree clean\n    \n    $ cat welcome.txt\n    Hello.\n    Nice to meet you.\n    new line.\n    \n    # 可以看到暂存区和工作区的内容都被清空\n    # 若是已经提交的更改的情况\n    $ echo 'new new line.' >> welcome.txt\n    $ git add welcome.txt\n    $ git commit -m \"append new new line to welcome.txt\"\n    [master 7402a4e] append new new line to welcome.txt\n     1 file changed, 1 insertion(+)\n    \n    $ git checkout 095d003 -- welcome.txt\n    # 工作区回退\n    $ cat welcome.txt\n    Hello.\n    Nice to meet you.\n    new line.\n    # 暂存区生成新的暂存文件信息，随时可以提交修改\n    $ git status\n    On branch master\n    Changes to be committed:\n      (use \"git restore --staged <file>...\" to unstage)\n            modified:   welcome.txt\n    \n    ```\n\n-   第二种用法则会改变`HEAD`头指针。\\<branch>指代切换到哪个分支，如果不指定分支名则会进入“分离头指针”的状态\n\n-   第三种用法主要用来创建和切换到新分支（\\<new_branch>），新的分支从\\<start_point>指定的提交开始创建\n\n    ```bash\n    # 通过日志查到祖先提交的ID\n    $ git log --graph --oneline\n    *   b06ad0b (HEAD -> master) Merge commit 'ccedb9c'\n    |\\\n    | * ccedb9c commit in detached HEAD mode\n    * | 8634325 add new.txt\n    |/\n    * ca04d27 Append a nice line.\n    * 6e314b7 empty commit\n    * dbda1b1 initialized.\n    \n    # 创建一个从祖先提交开始的分支\n    $ git checkout -b parent-parent ca04d27\n    Switched to a new branch 'parent-parent'\n    \n    # 再次查看日志可以发现分支指向祖先提交\n    $ git log --graph --oneline\n    * ca04d27 (HEAD -> parent-parent) Append a nice line.\n    * 6e314b7 empty commit\n    * dbda1b1 initialized.\n    \n    ```\n\n    >   一条特别危险的命令：\n    >\n    >   `git checkout -- .`或`git checkout .`\n    >\n    >   `.`代表通配，也就是指所有文件\n    >\n    >   它会取消所有本地修改，使用暂存区覆盖工作区\n\n### 第9章 恢复进度\n\n>   `git stash`命令的使用\n>\n>   [stash单词释义](https://dict.youdao.com/w/stash/#keyfrom=dict2.top)\n\n`git stash`用于保存进度与恢复进度\n\n查看保存的进度\n\n```bash\n$ git stash list\nstash@{0}: WIP on master: 8634325 add new.txt\n```\n\n```bash\n# 保存当前工作进度，会分别对暂存区和工作区的状态进行保存\n$ git stash\n# git stash的完整版\n# --patch会显示工作区和HEAD的差异，通过对差异文件的编辑决定最终要保存的工作区内容\n# -k或--keep-index会在进度保存后将暂存区重置。默认会将暂存区和工作区强制重置\n$ git stash [save [--patch] [-k|--[no-]keep-index] [-q|--quiet] [<message>]\n# 显示进度列表\n$ git stash list\n# 恢复进度\n# 如果不使用任何参数，会恢复最新保存的进度，并将恢复的工作进度从存储的工作进度列表中清除\n# --index会尝试恢复暂存区\n# stash是显示进度列表时提供的stash标识，恢复指定进度\n$ git stash pop [--index] [<stash>]\n# 和pop区别在于恢复后不删除进度\n$ git stash apply [--index] [<stash>]\n# 删除一个进度，默认删除最新进度\n$ git stash drop [<stash>]\n# 删除所有进度\n$ git stash clear\n# 基于进度创建分支\n$ git stash branch <branchname> <stash>\n```\n\n\n\n#### 探秘`git stash`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Git"],"categories":["啃书"]},{"title":"从Paxos到Zookeeper分布式一致性原理与实践","url":"/posts/20597ff2/","content":"\n\n\n## 从Paxos到Zookeeper分布式一致性原理与实践\n\n### 第1章 分布式结构\n\n#### 从集中式到分布式\n\n##### 集中式的特点\n\n由一台或多台主计算机组成的中心节点，数据集中存储于这个中心节点中，并且整个系统的所有业务单元都集中部署在这个中心节点上，系统的所有功能均由其集中处理。也就是说，在集中式系统中，每个终端或客户端机器仅仅负责数据的录入和输出，而数据的存储与控制处理完全交由主机完成。\n\n特点：部署结构简单，不用考虑多节点部署带来的分布式协作问题\n\n\n\n##### 分布式的特点\n\n>   《分布式系统概念与设计》中对分布式系统的定义：\n>\n>   分布式系统是一个硬件或软件组件分布在不同的**网络**计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。\n\n分布式系统在没有任何特定业务逻辑约束的情况下，都会有如下几个特征：\n\n1.   分布性\n\n     分布式系统中的多台计算机都会在空间上随意分布，同时，机器的分布情况也会随时变动\n\n     >   节点上下线\n\n2.   对等性\n\n     分布式系统中的计算机没有主/从之分的，所有计算机节点是对等的。\n\n     副本（Replica）是分布式系统最常见的概念之一，指的是分布式系统对数据和服务提供的一种冗余方式。\n\n     在分布式系统中为了对外提供高可用的服务，往往会对数据和服务进行副本处理。\n\n     >   副本分两类\n     >\n     >   1.   数据副本\n     >   2.   服务副本\n\n     **数据副本**是指在不同的节点上持久化同一份数据，当某一个节点上存储的数据丢失时，可以从副本上读取到该数据，这是解决分布式系统数据丢失问题最为有效的手段\n\n     >   涉及到副本就肯定会出现数据不一致的问题\n\n     另一类副本是**服务副本**，指多个节点提供同样的服务，每个节点都有能力接受来自外部的请求并进行相应的处理。\n\n3.   并发性\n\n     同一个分布式系统中的多个节点可能会并发地操作一些共享的资源，如数据库或分布式存储等\n\n4.   缺乏全局时钟\n\n     分布式系统中很难定义两个事件的先后，因为分布式系统缺乏一个全局的时钟序列控制\n     \n5.   故障总是会发生\n\n     组成分布式系统的所有计算机，都有可能发生任何形式的故障。\n\n     任何在设计阶段考虑到的异常情况，一定会在系统实际运行中发生，并且在系统实际运行过程中还会遇到很多在设计时未能考虑到的异常故障。所以，除非需求指标允许，在系统设计时不能放过任何异常情况。\n\n\n\n##### 分布式环境的各种问题\n\n###### 通信异常\n\n分布式系统需要在各个节点之间进行网络通信，由于网络本身的不可靠性，会导致最终分布式系统无法顺利完成一次网络通信。\n\n即使能够正常进行通信，延时也会远大于单机操作。通常单机内存访问的延时在纳秒级别（通常是10ns左右），而正常的一次网络通信的延时在0.1\\~1ms左右（相当于内存访问延时的105\\~106倍），延时大也会影响消息的收发过程，因此消息丢失和消息延迟变得非常普遍。\n\n###### 网络分区\n\n当网络由于发生异常情况，导致分布式系统中部分节点之间的网络延时不断增大，最终导致组成分布式系统的所有节点中，只有部分节点之间能够正常通信，而另一些节点不能——这个现象称为网络分区，也就是俗称的脑裂。\n\n网络分区出现的时候，分布式系统会出现局部小集群，在极端情况下，这些局部小集群会独立完成原本需要整个分布式系统才能完成的功能，包括对数据的事务处理。\n\n###### 三态\n\n传统的单机系统中，应用程序在调用一个函数之后，能够得到一个非常明确的响应：成功或失败。而在分布式系统中，由于网络是不可靠的，虽然在绝大部分情况下，网络通信也能够接受到成功或失败的响应，但是当网络出现异常的情况下，就可能会出现超时现象：\n\n1.   由于网络原因，该请求并没有被成功地发送到接收方，而是在发送过程中就发生了消息丢失现象。\n2.   该请求成功地被接收方接收后，并进行了处理，但是将响应反馈给发送方的过程中，发生了消息丢失现象。\n\n>   1.   接受方甚至都没有收到请求\n>   2.   接收方处理完并反馈，但是发送方没接收到\n\n当出现这样的超时现象时，网络通信的发起方是无法确定当前请求是否被成功处理的。\n\n###### 节点故障\n\n指的是组成分布式系统的服务器节点出现宕机或“僵死”现象\n\n\n\n#### 从ACID到CAP/BASE\n\n##### ACID\n\n##### 分布式事务\n\n##### CAP和BASE理论\n\n###### CAP定理\n\nCAP理论告诉我们，一个分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中的两项。\n\n-   一致性\n\n    指数据在多个副本是否能够保持一致的特性。在一致性需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致状态。\n\n    对于一个将数据副本分布在不同分布式节点上的系统来说，如果对第一个节点的数据进行了更新操作并且更新成功后，却没有使得第二节点上的数据得到相应的更新，于是在对第二个节点的数据进行读取操作时，获取的依然是老数据（或称为脏数据），这就是典型的分布式数据不一致的情况。\n\n    在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有用户都可以读取到其最新的值，那么这样的系统被认为具有**强一致性**（或严格一致性）。\n\n-   可用性\n\n    指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。\n\n    “返回结果”是可用性的另一个非常重要的指标，他要求系统在完成对用户请求的处理后，返回一个正常的响应结果（就是能够反映出对请求的处理结果，即成功或失败，而不是一个让用户感到困惑的返回结果）\n\n-   分区容错性\n\n    分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非整个网络都发生故障。\n    \n    >   网络分区：在分布式系统中，不同的节点分布在不同的子网络（机房或异地网络等）中，由于一些特殊的原因导致这些子网络之间出现网络不连通的情况，但是子网络内部通信正常，从而导致整个系统的网络环境被切分成若干个孤立的区域。\n    >\n    >   需要注意的是，组成分布式系统的每个节点的加入与退出都可以看作是一个特殊的网络分区。\n\n![20220516094438424](images/posts-assets/从Paxos到Zookeeper分布式一致性原理与实践.assets/20220516094438424.jpg)\n\n1.   ~~CA（放弃P）~~\n\n     如果希望能够避免系统出现分区，一种简单的做法是将所有的数据（或者仅仅将那些与事务相关的数据）都放在一个分布式节点上，这样虽然无法100%保证系统不会出错，但至少不会碰到由于网络分区带来的负面影响。\n\n     注意：放弃P也就意味着放弃了系统的可扩展性，可以说就不是分布式系统了。\n\n2.   CP（放弃A）\n\n     一旦发生网络分区或其他故障，受到影响的服务需要等待一定的时间，因为在这段期间系统无法对外提供正常的服务，即不可用\n\n3.   AP（放弃C）\n\n     注意：这里说的放弃一致性并不是完全放弃一致性（没有一致性的系统没意义）\n\n     放弃一致性指的是放弃强一致性，但是保留数据的最终一致性。\n\n     即系统无法保证数据一定是实时同步的，但是能够保证数据最终会达到一个一致的状态。\n\n     这就引入了一个时间窗口的概念，具体多久取决于系统设计，主要包括**数据副本在不同节点之间的复制时间长短**\n\n对于一个分布式系统而言，分区容错性是最基本的要求。\n\n因为既然是一个分布式系统，那么分布式系统中的组件必然需要被部署到不同的节点，就必然出现子网络。\n\n###### BASE理论\n\n1.   Basically Available（基本可用）\n2.   Soft state（软状态）\n3.   Eventually consistent（最终一致性）\n\n核心思想：即使无法做到强一致性（Strong consistency），但是每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventually consistency）。\n\n-   基本可用\n\n    指分布式系统在出现不可预知故障的时候，允许损失部分可用性（不等价于系统不可用！）\n\n    以下两个就是“基本可用”的典型例子：\n\n    -   响应时间上的损失：正常情况下，一个搜索引擎需要在0.5秒之内返回给用户结果，但是由于故障，查询时间可能增加到1~2秒。\n    -   功能上的损失：正常情况下，消费者几乎能在购物网站顺利完成每一笔订单，但是节日大促活动时，消费者购物行为激增，为了保护系统的稳定性，部分消费者可能会被引导到一个降级页面。\n\n-   软状态（弱状态）\n\n    和硬状态相比，指允许系统中的数据存在中间状态，并认为该中间状态的存在不影响系统的整体可用性，即**允许系统在不同节点的数据副本之间进行数据同步的过程存在延时**。\n\n-   最终一致性\n\n    最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。\n\n    >   保证最终数据能够达到一致，不需要实时保证系统数据的强一致性\n\n    实际工程实践中，最终一致性存在五类主要变种\n\n    1.   因果一致性（Causal consistency）\n\n         如果进程A在更新完某个数据项后通知了进程B，那么进程B之后对该数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B要对该数据项进行更新操作的话，务必基于进程A更新后的最新值，即不能发生丢失更新的情况。与此同时，与进程A无因果关系的进程C的数据访问则没有这样的限制。\n\n    2.   读己之所写（Read your writes）\n\n         进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者来说，其读取到的数据，一定不会比自己上次写入的值旧。因此可以看作是一种特殊的因果一致性。\n\n    3.   会话一致性（Session consistency）\n\n         对系统数据的访问过程框定在一个会话当中：系统能够保证在同一个有效的会话中实现“读己之所写”的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。\n\n    4.   单调读一致性（Monotonic read consistency）\n    \n         如果一个进程从系统中读取出一个数据项的一个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。\n    \n    5.   单调写一致性（Monotonic write consistency）\n    \n         一个系统需要能够保证来自同一个进程的写操作被顺序执行。\n    \n    实际系统实践中，可以将若干种一致性变种互相结合\n    \n    最终一致性并不是只有大型分布式系统才涉及的特性，许多现代的关系型数据库都采用了最终一致性模型。采用同步和异步方式来实现主备数据复制。在同步方式中，数据的复制过程通常是更新事务的一部分，因此事务完成后，主备数据库的数据就会达到一致。而在异步方式中，备库的更新往往会存在延时，这取决于事务日志在主备数据库之间传输的时间长短，如果传输时间过长或者甚至是日志传输过程中出现异常导致无法及时将事务应用到备库上，此时就会出现数据不一致的情况。无论是采用重试还是人为订正，关系型数据库还是能够保证最终数据一致性。\n\n\n\n### 第2章 一致性协议\n\n#### 2PC与3PC\n\n在分布式系统中，每一个机器节点虽然都能明确知道自己在进行事务操作过程中的结果是成功还是失败，但是却无法直接获取到其他分布式节点的操作结果。因此当一个事务操作需要跨越多个分布式节点的时候，为了保持事务处理的ACID特性，就需要引入一个称为“**协调者**（Coordinator）”的组件来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点则被称为“**参与者**（Participant）”。\n\n协调者负责调度参与者的行为，并最终决定这些参与者是否要把事务真正进行提交。\n\n基于这个思想衍生出二阶段提交和三阶段提交两种协议。\n\n##### 2PC\n\nTwo-Phase Commit（二阶段提交），是为了使基于分布式系统架构下的所有节点在进行事务处理过程中能够保持原子性和一致性而设计的一种算法。也被认为是一种一致性协议，用来保证分布式系统数据的一致性。\n\n###### 协议说明\n\n二阶段提交协议就是将事务的提交过程分成了两个阶段来进行处理，其执行流程如下\n\n###### 阶段一：提交事务请求\n\n1.   事务询问\n\n     协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应。\n\n2.   执行事务\n\n     各参与者节点执行事务操作，并将Undo和Redo信息记入事务日志中。\n\n3.   各参与者向协调者反馈事务询问的响应\n\n     如果参与者成功执行了事务操作，那么就反馈给协调者Yes响应，表示事务可以执行；\n\n     如果参与者没有成功执行事务，那么就反馈给协调者No响应，表示事务不可以执行。\n\n由于上述内容在形式上近似协调者组织各参与者对一次事务操作的投票表态过程，因此二阶段提交协议的阶段一也被称为“投票阶段”，即各参与者投票表明是否要继续执行接下来的事务提交操作。\n\n###### 阶段二：执行事务提交\n\n协调者根据各参与者的反馈情况来决定最终是否可以进行事务提交操作，正常情况下包含以下两种可能：\n\n-   执行事务提交\n\n    加入协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务提交。\n\n    1.   发送提交请求\n\n         协调者向所有参与者节点发出Commit请求。\n\n    2.   事务提交\n\n         参与者接收到Commit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源。\n\n    3.   反馈事务提交结果\n\n         参与者在完成事务提交之后，向协调者发送Ack消息。\n\n    4.   完成事务\n\n         协调者接收到所有参与者反馈的Ack消息后，完成事务。\n\n-   中断事务\n\n    假如出现了一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者无法接收到所有参与者的反馈响应，那么就会中断事务。\n\n    1.   发送回滚请求\n\n         协调者向所有参与者节点发送Rollback请求。\n\n    2.   事务回滚\n\n         参与者接收到Rollback请求后，会利用在阶段一中记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。\n\n    3.   反馈事务回滚结果\n\n         参与者在完成事务回滚之后，向协调者发送Ack消息。\n\n    4.   中断事务\n\n         协调者接收到所有参与者反馈的Ack消息后，完成事务中断。\n\n二阶段提交将事务处理过程分为**投票**和**执行**阶段，其核心是对每个事务都采用先尝试后提交的处理方式，因此也可以将二阶段提交看作是一个强一致性的算法。\n\n事务提交：\n\n![20220516120609153](images/posts-assets/从Paxos到Zookeeper分布式一致性原理与实践.assets/20220516120609153.jpg)\n\n事务中断：\n\n![20220516120734800](images/posts-assets/从Paxos到Zookeeper分布式一致性原理与实践.assets/20220516120734800.jpg)\n\n###### 优缺点\n\n优点：原理简单，实现方便\n\n缺点：同步阻塞，单点问题，脑裂，太过保守\n\n**同步阻塞**\n\n各个参与者在等待其他参与者响应的过程中将无法进行其他操作\n\n**单点问题**\n\n协调者的角色之重要，一旦出现问题，其他参与者将会一直处于锁定事务资源的状态，无法继续完成事务操作\n\n**数据不一致**\n\n在阶段二，当协调者向所有参与者发送Commit请求之后，发生了局部网络异常或者是协调者在尚未发送完Commit请求之前自身发生了崩溃，导致最终只有部分参与者收到了Commit请求。于是，这部分收到了Commit请求的参与者就会进行事务的提交，而其他没有收到Commit请求的参与者则无法进行事务提交，于是整个分布式系统出现数据不一致性现象\n\n**太过保守**\n\n协调者指示参与者进行事务提交询问的过程中，如果参与者出现故障的话，协调者依靠的自身的超时机制来判断是否需要中断事务，这样的策略比较保守，没有较为完善的重试机制，任意一个节点的失败都会导致事务失败\n\n##### 3PC\n\n###### 协议说明\n\n2PC的改进版，其将二阶段提交协议的“提交事务请求”过程一分为二，形成由`CanCommit`、`PreCommit`和`doCommit`三个阶段组成的事务处理协议\n\n![20220601184902017](images/posts-assets/从Paxos到Zookeeper分布式一致性原理与实践.assets/20220601184902017.jpg)\n\n###### 阶段一：CanCommit\n\n1.   事务询问\n\n     协调者向所有的参与者发送一个包含事务内容的`canCommit`请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。\n\n2.   各参与者向协调者反馈事务询问的响应\n\n     参与者在接收到来自协调者的`canCommit`请求后，正常情况下，如果其自身认为可以顺利执行事务，那么就会反馈Yes响应，并进入预备状态，否则反馈No响应。\n\n###### 阶段二：PreCommit\n\n协调者会根据反馈情况来决定是否可以进行事务的`PreCommit`操作，正常情况下，包含两种可能。\n\n-   执行事务预提交\n\n    所有的参与者反馈都是Yes，那么执行事务预提交\n\n    1.   发送预提交请求\n\n         协调者向所有参与者发送`preCommit`请求，并进入`Prepared`阶段\n\n    2.   事务预提交\n\n         参与者接收到后会执行事务操作，并将Undo和Redo信息记录到事务日志中\n\n    3.   各参与者向协调者反馈事务执行响应\n\n         如果参与者成功执行事务，那么就会反馈给协调者Ack响应，同时等待最终的指令：提交（commit）或中止（abort）\n\n-   中断事务\n\n    有任何一个参与者反馈No，或者在等待超时之后，那么就会中断事务\n\n    1.   发送中断请求\n\n         协调者发送`abort`请求\n\n    2.   中断事务\n\n         无论是收到协调者的`abort`请求，还是等待协调者请求超时，参与者都会中断事务\n\n###### 阶段三：doCommit\n\n真正进行事务提交，存在两种情况\n\n-   执行提交\n\n    1.   发送提交请求\n\n         假设协调者处于正常状态，并且收到了所有参与者的Ack响应，那么它将从“预提交”转换到“提交”状态，并向所有参与者发送`doCommit`请求\n\n    2.   事务提交\n\n         参与者接收到`doCommit`请求后，会正式执行事务提交操作，并在完成提交之后释放资源\n\n    3.   反馈事务提交结果\n\n         向协调者发送Ack\n\n    4.   完成事务\n\n         协调者接收到所有参与者反馈的Ack后完成事务\n\n-   中断事务\n\n    假设协调者处于正常状态，并且有任意一个参与者向协调者发送了No响应，或者等待超时，那么就会中断事务\n\n    1.   发送中断请求\n\n         协调者向所有参与者节点发送`abort`请求\n\n    2.   事务回滚\n\n         参与者接收到`abort`请求后，会利用阶段二中记录的Undo信息进行事务回滚，之后释放资源\n\n    3.   反馈事务回滚结果\n\n         向协调者发送Ack\n\n    4.   中断事务\n\n         协调者接收所有参与者反馈的Ack后中断事务\n\n>   注意：一旦进入阶段三，可能会存在以下故障\n>\n>   -   协调者出现问题\n>   -   协调者和参与者之间的网络出现故障\n\n无论哪种，最终都会导致参与者无法接收到协调者的`doCommit`或`abort`请求，参与者会在等待超时之后继续进行事务提交\n\n###### 优缺点\n\n相较于二阶段，最大的优点就是降低参与者的阻塞范围，并且能够在出现单点故障后继续达成一致\n\n>   ???\n\n缺点：参与者在接收到`PreCommit`消息后，如果出现网络分区，此时协调者所在的节点和参与者无法进行正常的网络通信，这种情况下参与者仍然会进行事务提交，这会造成数据不一致性\n\n\n#### Paxos算法\n\nPaxos[ˈpæksoʊs]\n\n基于消息传递且具有高度容错特性的一致性算法\n\n##### 拜占庭将军问题\n\n![20220607100552312](images/posts-assets/从Paxos到Zookeeper分布式一致性原理与实践.assets/20220607100552312.jpg)\n\n理论上来说试图在异步系统和不可靠的通道上来达到一致性状态是不可能的，因此对于一致性的研究都是假设信道是可靠的。\n\n-   大多数系统都是部署在局域网内的，因此消息被篡改的情况非常罕见\n-   由于硬件和网络原因而造成的消息不完整问题只需要一套简单的校验算法即可避免\n\n所以在实际工程实践中，可以假设不存在拜占庭将军问题\n\n![20220607101012024](images/posts-assets/从Paxos到Zookeeper分布式一致性原理与实践.assets/20220607101012024.jpg)\n\n##### Paxos算法详解\n\n###### 问题描述\n\n假设有一组可以提出提案的进程集合，那么对于一个一致性算法来说需要保证以下几点：\n\n-   在这些被提出的提案中，只有一个会被选定\n-   如果没有提案被提出，那么就不会有被选定的提案\n-   当一个提案被选定后，进程应该可以获取被选定的提案信息\n\n对于一致性来说，安全性（Safety）需求如下：\n\n-   只有被提出的提案才能被选定\n-   只能有一个值被选定\n-   如果某个进程认为某个提案被选定了，那么这个提案必须是真的被选定的那个\n\n在`Paxos`算法中，有三种参与角色，用`Proposer`、`Acceptor`和`Learner`表示\n\n在具体实现中，一个进程可能充当不止一种角色，我们不关心进程如何映射到各种角色。\n\n假设不同参与者之间可以通过收发消息来进行通信，那么：\n\n-   每个参与者以任意的速度执行，可能会因为出错而停止，也可能会重启。同时，即使一个提案被选定后，所有的参与者也都有可能失败或重启，因此除非那些失败或重启的参与者可以记录某些信息，否则将无法确定最终的值。\n-   消息在传输过程中可能会出现不可预知的延迟，也可能会重复或丢失，但是消息不会被损坏，即消息内容不会被篡改（拜占庭式问题）\n\n###### 提案的选定\n\n**单一Acceptor**\n\n要选定唯一提案的最简单的方式就是只允许一个`Acceptor`存在，这样`Proposer`只能发送提案给这个`Acceptor`，`Acceptor`会选择它接收到的第一个提案作为被选定提案。\n\n这种方式很简单，但是一旦这个`Acceptor`出现问题，整个系统就无法工作\n\n**多个Acceptor**\n\n使用多个`Acceptor`避免单点问题\n\n`Proposer`向一个`Acceptor`集合发送提案，集合中的每个`Acceptor`都可能会批准该提案，当有足够多的`Acceptor`批准这个提案的时候（比如说半数以上？）我们就认为该提案被选定了。\n\n>   什么是足够多？\n>\n>   假定足够多的`Acceptor`是整个`Acceptor`集合的子集，并且让这个子集大得可以包含`Acceptor`集合中的大多数成员，因为任意两个包含大多数`Acceptor`的子集至少有一个公共成员。另外再规定每个`Acceptor`最多只能批准一个提案，那么就能保证只有一个提案被选定了。\n\n**推导过程**\n\n在没有失败和消息丢失的情况下，如果我们希望即使在只有一个提案被提出的情况下，仍然可以选出一个提案，这就暗示了一个需求：\n\n>   P1：一个`Acceptor`必须批准它收到的第一个提案\n\n但是这个需求会引出另一个问题：如果多个提案被不同的`Proposer`同时提出，这可能会导致虽然每个`Acceptor`都批准了它收到的第一个提案，但是没有一个提案是由多数人都批准的\n\n![20220607205041955](images/posts-assets/从Paxos到Zookeeper分布式一致性原理与实践.assets/20220607205041955.jpg)\n\n另外，即使只有两个提案被提出，如果每个提案都被差不多一半的`Acceptor`批准，此时即使只有一个`Acceptor`出错，都有可能导致无法确定该选定哪个提案\n\n![20220607205238893](images/posts-assets/从Paxos到Zookeeper分布式一致性原理与实践.assets/20220607205238893.jpg)\n\n在`P1`的基础上，再加上一个提案被选定需要由半数以上的`Acceptor`批准的需求，暗示着一个`Acceptor`必须能够批准不止一个提案。在这里用全局的编号来唯一标识每一个被`Acceptor`批准的提案，当一个具有某Value值的提案被半数以上的`Acceptor`批准后，我们就认为该Value被选定了，此时我们也认为该提案被选定了。\n\n>   此处讲的提案已经和Value不是同一个概念了，提案变成了由编号和Value组成的组合体，即`[编号, Value]`来表示一个提案\n\n虽然允许多个提案被选定，但同时必须要保证所有被选定的提案都具有相同的Value值，结合提案的编号，该约定可以定义如下：\n\n>   P2：如果编号为M~0~、Value值为V~0~的提案（即[M~0~, V~0~]）被选定了，那么所有比编号M~0~更高的，且被选定的提案，其Value值必须也是V~0~\n\n### 第4章 ZooKeeper与Paxos\n\n#### 初识ZooKeeper\n\n##### ZooKeeper中的基本概念\n\n###### 集群角色\n\n>   通常在分布式系统中，构成一个集群的每一台机器都有自己的角色，最典型的就是主从模式（Maste/Slave）。\n>\n>   -   Master机器：能够处理所有写操作\n>   -   Slave机器：通过异步复制方式获取最新数据，并提供读服务的机器\n\n但是在ZooKeeper中，它没有沿用传统的Master/Slave概念，而是引入Leader、Follower和Observer三种角色。\n\n-   所有机器通过Leader选举过程来选定一台Leader机器，Leader服务器为客户端提供读和写服务\n-   Follower和Observer都能提供读服务，区别在于Observer不参与Leader选举过程，也不参与写操作的“过半写成功”策略，因此`Observer可以在不影响写性能的情况下提升集群的读性能`\n\n###### 会话（Session）\n\n指客户端会话，ZooKeeper中一个客户端连接是与服务器之间的`TCP长连接`。客户端启动的时候与服务器建立TCP连接，从第一次连接建立开始，客户端会话的生命周期就开始了，客户端通过`心跳检测`与服务器保持有效的会话。\n\nSession的`sessionTimeout`用来设置客户端会话超时时间，当由于服务器压力太大、网络故障或是客户端主动断开连接等原因导致客户端连接断开，只要在sessionTimeout规定时间内重连，那么之前创建的会话仍然有效。\n\n###### 数据节点（ZNode）\n\nZooKeeper中的节点分为两类\n\n-   构成集群的机器，称为机器节点\n-   数据模型中的数据单元，称为数据节点——ZNode\n\nZooKeeper将所有数据存储在内存中，数据模型是一颗树（ZNode Tree），由斜杠（/）进行分割的路径，就是一个ZNode。每个ZNode上会保存自己的数据内容，同时还会保存一系列属性信息。\n\n**数据节点分类**\n\n-   持久节点\n\n    一旦创建，除非主动移除，否则会一直保存在ZooKeeper中\n\n-   临时节点\n\n    生命周期与客户端会话绑定，一旦客户端会话失效，这个客户端创建的临时节点就会被移除\n\n    ZooKeeper还允许用户为每个节点添加一个特殊的属性：SEQUENTIAL。一旦节点被标记这个属性，那么这个节点创建的时候会自动在节点名后面追加上一个整型数字，这个整型数字是由父节点维护的自增数字\n\n###### 版本\n\nZooKeeper的每个ZNode上都会存储数据，ZooKeeper会维护一个叫作`Stat`的数据结构，Stat中记录了这个ZNode的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点版本）和aversion（当前ZNode的ACL版本）\n\n###### Watcher\n\n事件监听器，ZooKeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发时，ZooKeeper会将事件通知到感兴趣的客户端上\n\n###### ACL\n\nAccess Control Lists，一种权限控制策略，类似于UNIX文件系统的权限控制。ZooKeeper定义了5种权限\n\n-   CREATE：创建子节点权限\n-   READ：获取节点数据和子节点列表的权限\n-   WRITE：更新节点数据的权限\n-   DELETE：删除子节点的权限\n-   ADMIN：设置节点ACL的权限\n\n>   注意：CREATE和DELETE都是针对子节点的权限控制\n\n\n\n\n\n#### ZooKeeper的ZAB协议\n\n### 第5章 使用ZooKeeper\n\n#### 安装部署\n\n1.   安装JRE\n\n     -   yum安装\n\n         ```bash\n         yum search java\n         ...\n         java-1.8.0-openjdk.x86_64 : OpenJDK 8 Runtime Environment\n         java-1.8.0-openjdk-accessibility.i686 : OpenJDK accessibility connector\n         java-1.8.0-openjdk-accessibility.x86_64 : OpenJDK accessibility connector\n         java-1.8.0-openjdk-demo.i686 : OpenJDK Demos 8\n         java-1.8.0-openjdk-demo.x86_64 : OpenJDK 8 Demos\n         java-1.8.0-openjdk-devel.i686 : OpenJDK Development Environment 8\n         java-1.8.0-openjdk-devel.x86_64 : OpenJDK 8 Development Environment\n         java-1.8.0-openjdk-headless.i686 : OpenJDK Headless Runtime Environment 8\n         java-1.8.0-openjdk-headless.x86_64 : OpenJDK 8 Headless Runtime Environment\n         java-1.8.0-openjdk-javadoc.noarch : OpenJDK 8 API documentation\n         java-1.8.0-openjdk-javadoc-zip.noarch : OpenJDK 8 API documentation compressed in a single archive\n         java-1.8.0-openjdk-src.i686 : OpenJDK Source Bundle 8\n         java-1.8.0-openjdk-src.x86_64 : OpenJDK 8 Source Bundle\n         ...\n         ```\n\n         从描述可以看出各个包的区别，选择jre安装就行了\n\n         `yum install java-1.8.0-openjdk.x86_64`\n\n     -   apt安装\n\n     -   源码安装\n\n2.   安装ZooKeeper\n\n     1.   官网下载地址：[https://zookeeper.apache.org/releases.html](https://zookeeper.apache.org/releases.html)\n\n          清华镜像地址：[https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper](https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper)\n\n          ```bash\n          wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.7.1/apache-zookeeper-3.7.1-bin.tar.gz\n          ###可能出现###\n          Resolving mirrors.tuna.tsinghua.edu.cn (mirrors.tuna.tsinghua.edu.cn)... 101.6.15.130, 2402:f000:1:400::2\n          Connecting to mirrors.tuna.tsinghua.edu.cn (mirrors.tuna.tsinghua.edu.cn)|101.6.15.130|:443... connected.\n          ERROR: cannot verify mirrors.tuna.tsinghua.edu.cn's certificate, issued by '/C=US/O=Let\\'s Encrypt/CN=R3':\n            Issued certificate has expired.\n          To connect to mirrors.tuna.tsinghua.edu.cn insecurely, use `--no-check-certificate'.\n          \n          \n          加上 --no-check-certificate 选项即可\n          # wget --no-check-certificate https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.7.1/apache-zookeeper-3.7.1-bin.tar.gz\n          ```\n\n     2.   解包\n\n          ```bash\n          tar -zxvf apache-zookeeper-3.7.1-bin.tar.gz\n          # 参数解释\n          # -z: 通过gzip指令压缩/解压缩文件，文件名最好为*.tar.gz\n          # -x: 从归档文件中提取文件\n          # -v: 显示指令执行过程\n          # -f: 指定备份（压缩）文件\n          ```\n\n     3.   拷贝配置文件\n\n          `conf`目录下有个样例配置，拷贝一份重命名为`zoo.cfg`\n\n          ```bash\n          cd apache-zookeeper-3.7.1-bin\n          cd conf\n          cp zoo_sample.cfg zoo.cfg\n          ```\n\n     4.   启动服务端\n\n          ```bash\n          # 回退到bin目录\n          cd ../bin\n          ./zkServer.sh start\n          ```\n\n     可能出现的问题：\n\n     ```bash\n     /usr/bin/java\n     ZooKeeper JMX enabled by default\n     Using config: /opt/apache-zookeeper-3.7.1/bin/../conf/zoo.cfg\n     Starting zookeeper ... FAILED TO START\n     \n     # 使用前台运行查看日志信息\n     ./zkServer.sh start-foreground\n     /usr/bin/java\n     ZooKeeper JMX enabled by default\n     Using config: /opt/apache-zookeeper-3.7.1/bin/../conf/zoo.cfg\n     Error: Could not find or load main class org.apache.zookeeper.server.quorum.QuorumPeerMain\n     # 可以看到原因在于找不到主类\n     ```\n\n     解决方案：要下载名字带`bin`的压缩包，不带`bin`的属于源码包，需要自行进行编译，缺少了`jar`包当然就找不到主类了\n\n     左图为源码包，右图为`bin`包\n\n     ![20220606202341162](images/posts-assets/从Paxos到Zookeeper分布式一致性原理与实践.assets/20220606202341162.jpg)\n\n     源码编译参照`README_packaging.md`文档操作就可以了\n\n     -   源码安装（TODO）\n\n     \n\n     查看服务端状态\n\n     ```bash\n     ./zkServer.sh status\n     /usr/bin/java\n     ZooKeeper JMX enabled by default\n     Using config: /opt/apache-zookeeper-3.7.1-bin/bin/../conf/zoo.cfg\n     Client port found: 2181. Client address: localhost. Client SSL: false.\n     Mode: standalone\n     ```\n\n\n**参数配置**\n\n-   集群模式下，集群中的每台机器都需要感知到整个集群是由哪几台机器组成的\n\n    `server.id=host:port:port`\n\n    `id`为Server ID，用来标识机器在集群中的机器序号。同时在每台机器上，需要在数据目录创建一个`myid`文件，里面写入机器的`id`，需要确保每个机器的`myid`文件中的数字不同，数字范围在1~255。\n\n    如：\n    \n    ```properties\n    server.1=IP1:2888:3888\n    server.2=IP2:2888:3888\n    server.3=IP3:2888:3888\n    ```\n    \n    ```bash\n    # 查看状态\n    ./zkServer.sh status\n    /usr/bin/java\n    ZooKeeper JMX enabled by default\n    Using config: /opt/apache-zookeeper-3.7.1-bin/bin/../conf/zoo.cfg\n    Client port found: 2181. Client address: localhost. Client SSL: false.\n    Mode: follower # 可以看到该机器属于follower\n    ```\n\n#### 客户端脚本\n\n`bin`目录下的`zkCli.sh`和`zkCli.cmd`就是客户端脚本\n\n执行脚本即可连接至ZooKeeper服务端\n\n```bash\nbin/zkCli.sh\n```\n\n成功连接时会有以下输出\n\n```bash\nWatchedEvent state:SyncConnected type:None path:null\n[zk: localhost:2181(CONNECTED) 0]\n```\n\n如果没有显示指定服务器地址，默认连接的是本地ZooKeeper服务器\n\n```bash\n# 该命令可以连接指定ZooKeeper服务器\nbin/zkCli.sh -server ip:port\n```\n\n##### 创建\n\n`create`命令用于创建一个ZooKeeper节点\n\n```bash\ncreate [-s] [-e] path data acl\n```\n\n>   说明：\n>\n>   -s：顺序节点\n>\n>   -e：临时节点\n>\n>   path：节点路径，必须以`/`开头\n>\n>   data：节点的值\n>\n>   acl：节点权限信息，不是必须的，缺省情况下不做任何权限控制\n\n```bash\n[zk: localhost:2181(CONNECTED) 0] create /crayon 0\nCreated /crayon\n```\n\n##### 读取\n\n与读取相关的命令有三个，分别是`ls`、`get`和`stat`\n\n`ls`\n\n可以列出ZooKeeper指定节点下的所有子节点（第一级子节点）\n\n```bash\nls path [watch]\n```\n\n>   说明：\n>\n>   path：节点路径\n>\n>   watch：监听节点\n\n```bash\n[zk: localhost:2181(CONNECTED) 1] ls /\n[crayon, zookeeper]\n```\n\n`get`\n\n可以获取ZooKeeper指定节点的数据内容\n\n```bash\nget path [watch]\n```\n\n```bash\n[zk: localhost:2181(CONNECTED) 2] get /crayon\n0\n```\n\n`stat`\n\n获取节点的属性信息\n\n```bash\nstat path [watch]\n```\n\n```bash\n[zk: localhost:2181(CONNECTED) 9] stat /crayon\ncZxid = 0x4\nctime = Thu Jun 09 15:09:52 CST 2022\nmZxid = 0x4\nmtime = Thu Jun 09 15:09:52 CST 2022\npZxid = 0x4\ncversion = 0\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 1\nnumChildren = 0\n```\n\n##### 更新\n\n使用`set`命令，可以更新指定节点的数据内容\n\n```bash\nset path data [version]\n```\n\n>   说明：\n>\n>   path：节点路径\n>\n>   data：要更新的数据内容\n>\n>   version：指定本次更新操作是基于ZNode的哪一个数据版本进行的\n\n```bash\n[zk: localhost:2181(CONNECTED) 11] stat /crayon\ncZxid = 0x4\nctime = Thu Jun 09 15:09:52 CST 2022\nmZxid = 0x5\nmtime = Thu Jun 09 15:32:42 CST 2022\npZxid = 0x4\ncversion = 0\ndataVersion = 1 # 数据版本从0变为1\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 1\nnumChildren = 0\n```\n\n##### 删除\n\n使用`delete`命令可以删除ZooKeeper上的指定节点\n\n```bash\ndelete path [version]\n```\n\n>   version参数与`set`命令中的version参数作用一致\n\n```bash\n[zk: localhost:2181(CONNECTED) 14] delete /crayon\n```\n\n如果节点存在子节点则会删除失败\n\n```bash\n[zk: localhost:2181(CONNECTED) 25] delete /crayon\nNode not empty: /crayon\n```\n\n#### Java客户端API使用\n\n##### 创建会话\n\n通过`new ZooKeeper()`创建一个连接\n\n该过程是异步的，构造方法在处理完成客户端初始化工作后立即返回，生命周期进入`CONNECTING`状态\n\n在真正建立连接之后，服务端会发送给客户端一个事件通知，此时才算真正建立了会话\n\n```java\n/**\n * @author Crayon\n * @date 2022/6/9 16:18\n * 客户端连接\n */\npublic class ZooKeeperConnectTest {\n    @Test\n    public void test() throws IOException, InterruptedException {\n        final CountDownLatch latch = new CountDownLatch(1);\n        ZooKeeper zooKeeper = new ZooKeeper(\"localhost:2181\", 4000, new Watcher() {\n            public void process(WatchedEvent watchedEvent) {\n                if (watchedEvent.getState() == Event.KeeperState.SyncConnected) {\n                    // 如果收到了服务端的响应事件：连接成功\n                    latch.countDown();\n                    System.out.println(\"connected!\");\n                }\n            }\n        });\n        System.out.println(\"waiting...\");\n        latch.await();\n        System.out.println(\"State: \" + zooKeeper.getState());\n    }\n}\n```\n\n\n\n**携带Session进行连接**\n\n```java\n/**\n * @author Crayon\n * @date 2022/6/10 10:46\n * 携带Session信息进行连接\n */\npublic class ZooKeeperConnectWithSessionIdTest {\n    private static class DefaultWatch implements Watcher {\n        private final String name;\n        private final CountDownLatch latch;\n\n        public DefaultWatch(String name, CountDownLatch latch) {\n            this.name = name;\n            this.latch = latch;\n        }\n\n        public void process(WatchedEvent event) {\n            System.out.printf(\"name: %s, event: %s\\n\", name, event);\n            latch.countDown();\n        }\n    }\n\n    @Test\n    public void test() throws IOException, InterruptedException {\n        String connectString = \"localhost:2181\";\n        int sessionTimeout = 4000;\n        int count = 2;\n        CountDownLatch latch0 = new CountDownLatch(1);\n        CountDownLatch latch = new CountDownLatch(count);\n        ZooKeeper zooKeeper0 = new ZooKeeper(connectString, sessionTimeout, new DefaultWatch(\"zookeeper0\", latch0));\n        latch0.await();\n        long sessionId = zooKeeper0.getSessionId();\n        byte[] sessionPasswd = zooKeeper0.getSessionPasswd();\n        ZooKeeper zooKeeper1 = new ZooKeeper(connectString, sessionTimeout, new DefaultWatch(\"zookeeper1\", latch), 1, \"error-password\".getBytes());\n        ZooKeeper zooKeeper2 = new ZooKeeper(connectString, sessionTimeout, new DefaultWatch(\"zookeeper2\", latch), sessionId, sessionPasswd);\n        System.out.println(\"waiting...\");\n        latch.await();\n        System.out.printf(\"zookeeper0 => sessionId: %d\\n\", sessionId);\n        System.out.printf(\"zookeeper2 => sessionId: %d\\n\", zooKeeper2.getSessionId());\n    }\n}\n```\n\n##### 创建节点\n\n通过`create`方法可以进行节点的创建，分别`同步`和`异步`两种方式\n\n-   同步方式\n\n    ```java\n    /**\n     * @author Crayon\n     * @date 2022/6/10 11:11\n     * 同步节点创建\n     */\n    public class SyncCreateNodeTest {\n        public ZooKeeper getConnect() throws InterruptedException, IOException {\n            final CountDownLatch latch = new CountDownLatch(1);\n            ZooKeeper zooKeeper = ZooKeeperConnectTest.getConnect(new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    if (event.getState() == Event.KeeperState.SyncConnected) {\n                        System.out.println(\"connected!\");\n                        latch.countDown();\n                    }\n                }\n            });\n            latch.await();\n            return zooKeeper;\n        }\n    \n        public ZooKeeper getConnect(long sessionId, byte[] sessionPasswd) throws InterruptedException, IOException {\n            final CountDownLatch latch = new CountDownLatch(1);\n            ZooKeeper zooKeeper = ZooKeeperConnectTest.getConnect(sessionId, sessionPasswd, new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    if (event.getState() == Event.KeeperState.SyncConnected) {\n                        System.out.println(\"connected!\");\n                        latch.countDown();\n                    }\n                }\n            });\n            latch.await();\n            return zooKeeper;\n        }\n    \n        @Test\n        public void test() throws InterruptedException, IOException, KeeperException {\n            ZooKeeper zooKeeper = getConnect();\n            byte[] data = \"crayon-data\".getBytes(\"utf-8\");\n            String path = zooKeeper.create(\"/crayon\", data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);\n            System.out.println(\"path: \" + path);\n            ZooKeeper zooKeeper1 = getConnect(zooKeeper.getSessionId(), zooKeeper.getSessionPasswd());\n            Stat stat = zooKeeper1.exists(\"/crayon\", false);\n            byte[] nodeData = zooKeeper1.getData(\"/crayon\", false, stat);\n            System.out.println(\"data: \" + new String(nodeData, \"utf-8\"));\n        }\n    }\n    ```\n\n    临时节点属于会话级别，当连接断开后，在会话过期时间内携相同的会话信息重连的话，临时节点依然存在\n\n-   异步方式，通过异步回调的方式进行通知\n\n    ```java\n    /**\n     * @author Crayon\n     * @date 2022/6/10 11:11\n     * 异步节点创建\n     */\n    public class AsyncCreateNodeTest {\n        @Test\n        public void test() throws IOException, InterruptedException, KeeperException {\n            final CountDownLatch latch = new CountDownLatch(1);\n            ZooKeeper zooKeeper = SyncCreateNodeTest.getConnect();\n            byte[] data = \"crayon-data\".getBytes(\"utf-8\");\n            zooKeeper.create(\"/crayon\", data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL, new AsyncCallback.StringCallback() {\n                @Override\n                public void processResult(int rc, String path, Object ctx, String name) {\n                    System.out.println(\"rc: \" + rc);\n                    System.out.println(\"path: \" + path);\n                    System.out.println(\"ctx: \" + ctx);\n                    System.out.println(\"name: \" + name);\n                    latch.countDown();\n                }\n            }, \"ctx\");\n            latch.await();\n        }\n    }\n    \n    ```\n\n    和同步接口不同的是，异步接口本身不会抛出异常，而是以回调函数中的响应码（rc字段）体现，而同步接口对于失败的情况会抛出异常\n\n    回调的参数说明：\n\n    ![20220610115820746](images/posts-assets/从Paxos到Zookeeper分布式一致性原理与实践.assets/20220610115820746.jpg)\n\n    \n\n##### 删除节点\n\n同样有同步与异步两种方式\n\nZooKeeper只允许删除叶子节点\n\n-   同步方式\n\n    -   \n\n    ```java\n    /**\n     * @author Crayon\n     * @date 2022/6/14 16:36\n     * 同步删除节点\n     */\n    public class SyncDeleteNodeTest {\n        @Test\n        public void test() throws IOException, InterruptedException, KeeperException {\n            ZooKeeper zooKeeper = SyncCreateNodeTest.getConnect();\n            // 删除不存在的节点，version为-1表示匹配任意version\n            zooKeeper.delete(\"/inexist-node\", -1);\n            // 删除存在的节点，但是version不对应\n            zooKeeper.delete(\"/crayon\", 1);\n            // 删除存在的节点，version对应\n            zooKeeper.delete(\"/crayon\", 0);\n        }\n    }\n    ```\n\n    操作不成功则会抛出异常\n\n    节点不存在：`org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /inexist-node`\n\n    节点版本不对应：`org.apache.zookeeper.KeeperException$BadVersionException: KeeperErrorCode = BadVersion for /crayon`\n\n    \n\n-   异步方式\n\n    异步方式通过状态码来判断结果\n\n    ```java\n    /**\n     * @author Crayon\n     * @date 2022/6/14 16:36\n     * 同步删除节点\n     */\n    public class AsyncDeleteNodeTest {\n        @Test\n        public void test() throws IOException, InterruptedException {\n            ZooKeeper zooKeeper = SyncCreateNodeTest.getConnect();\n            final CountDownLatch latch = new CountDownLatch(3);\n            AsyncCallback.VoidCallback cb = new AsyncCallback.VoidCallback() {\n                @Override\n                public void processResult(int rc, String path, Object ctx) {\n                    latch.countDown();\n                    switch (KeeperException.Code.get(rc)) {\n                        case OK:\n                            System.out.println(\"请求成功\");\n                            break;\n                        case NONODE:\n                            System.out.println(\"节点不存在\");\n                            break;\n                        case BADVERSION:\n                            System.out.println(\"节点版本不对应\");\n                            break;\n                        default:\n                    }\n                    System.out.println(\"result code: \" + rc);\n                    System.out.println(\"path: \" + path);\n                    System.out.println(\"context: \" + ctx);\n                }\n            };\n            // 删除不存在的节点，version为-1表示匹配任意version\n            zooKeeper.delete(\"/inexist-node\", -1, cb, \"operation-0\");\n            // 删除存在的节点，但是version不对应\n            zooKeeper.delete(\"/crayon\", 1, cb, \"operation-1\");\n            // 删除存在的节点，version对应\n            zooKeeper.delete(\"/crayon\", 0, cb, \"operation-2\");\n    \n            latch.await();\n        }\n    }\n    \n    ```\n\n##### 读取数据\n\n###### getChildren\n\n-   同步\n\n    ```java\n/**\n     * @author Crayon\n     * @date 2022/6/14 16:33\n     * 同步获取节点数据\n     */\n    public class SyncGeChildrenTest {\n        @Test\n        public void test() throws IOException, InterruptedException, KeeperException, BrokenBarrierException {\n            final CountDownLatch latch = new CountDownLatch(2);\n            final ZooKeeper zooKeeper = SyncCreateNodeTest.getConnect();\n            System.out.println(zooKeeper.getChildren(\"/\", false));\n            Watcher watcher = new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    if (event.getState() == Event.KeeperState.SyncConnected) {\n                        if (event.getType() == Event.EventType.NodeChildrenChanged) {\n                            try {\n                                System.out.println(\"re-get children: \" + zooKeeper.getChildren(event.getPath(), true));\n                            } catch (Exception e) {\n                                e.printStackTrace();\n                            } finally {\n                                latch.countDown();\n                            }\n                        }\n                    }\n                }\n            };\n            zooKeeper.getChildren(\"/\", watcher);\n            zooKeeper.delete(\"/crayon0\", -1);\n            zooKeeper.delete(\"/crayon1\", -1);\n            latch.await();\n        }\n    }\n    ```\n    \n    >   `Watcher`是一次性的，在监听到一次通知并执行之后就没用了，监听下次通知需要重新注册`Watcher`\n\n-   异步\n\n    ```java\n    /**\n     * @author Crayon\n     * @date 2022/6/14 16:33\n     * 异步获取节点数据\n     */\n    public class AsyncGeChildrenTest {\n        @Test\n        public void test() throws IOException, InterruptedException, KeeperException, BrokenBarrierException {\n            final CountDownLatch latch = new CountDownLatch(2);\n            final ZooKeeper zooKeeper = SyncCreateNodeTest.getConnect();\n            System.out.println(zooKeeper.getChildren(\"/\", false));\n            Watcher watcher = new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    if (event.getState() == Event.KeeperState.SyncConnected) {\n                        if (event.getType() == Event.EventType.NodeChildrenChanged) {\n                            try {\n                                System.out.println(\"re-get children: \" + zooKeeper.getChildren(event.getPath(), true));\n                            } catch (Exception e) {\n                                e.printStackTrace();\n                            } finally {\n                                latch.countDown();\n                            }\n                        }\n                    }\n                }\n            };\n            zooKeeper.getChildren(\"/\", watcher, new AsyncCallback.ChildrenCallback() {\n                @Override\n                public void processResult(int rc, String path, Object ctx, List<String> children) {\n                    System.out.println(\"result code: \" + rc);\n                    System.out.println(\"path: \" + path);\n                    System.out.println(\"ctx: \" + ctx);\n                    System.out.println(\"children: \" + children);\n                    latch.countDown();\n                }\n            }, null);\n            zooKeeper.delete(\"/crayon0\", -1);\n            latch.await();\n        }\n    }\n    ```\n\n###### getData\n\n-   同步\n\n    ```java\n    /**\n     * @author Crayon\n     * @date 2022/6/15 11:04\n     * 同步获取节点数据\n     */\n    public class SyncGetDataTest {\n        @Test\n        public void test() throws IOException, InterruptedException, KeeperException {\n            ZooKeeper zooKeeper = SyncCreateNodeTest.getConnect();\n            final CountDownLatch latch = new CountDownLatch(1);\n            zooKeeper.create(\"/crayon\", \"crayon\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);\n            System.out.println(new String(zooKeeper.getData(\"/crayon\", new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    if (event.getState() == Event.KeeperState.SyncConnected) {\n                        if (event.getType() == Event.EventType.NodeDataChanged) {\n                            System.out.println(\"node data changed!\");\n                            latch.countDown();\n                        }\n                    }\n                }\n            }, new Stat())));\n            zooKeeper.setData(\"/crayon\", \"crayon\".getBytes(), -1);\n            latch.await();\n        }\n    }\n    ```\n\n    尽管内容没有改变，但是数据版本号变了，所以ZooKeeper也认为节点数据变化了\n\n-   异步\n\n    ```java\n    /**\n     * @author Crayon\n     * @date 2022/6/15 11:04\n     * 异步获取节点数据\n     */\n    public class AsyncGetDataTest {\n        @Test\n        public void test() throws IOException, InterruptedException, KeeperException {\n            ZooKeeper zooKeeper = SyncCreateNodeTest.getConnect();\n            final CountDownLatch latch = new CountDownLatch(2);\n            zooKeeper.create(\"/crayon\", \"crayon\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);\n            zooKeeper.getData(\"/crayon\", new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    if (event.getState() == Event.KeeperState.SyncConnected) {\n                        if (event.getType() == Event.EventType.NodeDataChanged) {\n                            System.out.println(\"node data changed!\");\n                            latch.countDown();\n                        }\n                    }\n                }\n            }, new AsyncCallback.DataCallback() {\n                @Override\n                public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {\n                    System.out.println(\"result code: \" + rc);\n                    System.out.println(\"path: \" + path);\n                    System.out.println(\"context: \" + ctx);\n                    System.out.println(\"data: \" + new String(data));\n                    System.out.println(\"stat: \" + stat);\n                    latch.countDown();\n                }\n            }, null);\n            zooKeeper.setData(\"/crayon\", \"crayon\".getBytes(), -1);\n            latch.await();\n        }\n    }\n    ```\n\n##### 更新数据\n\n更新节点数据是可以携带数据版本的，指定数据版本进行更新，但是读取数据的接口并没有提供指定数据版本的功能？\n\n>   CAS：通过携带一个预期值进行比较，满足的情况下就可以进行修改\n>\n>   如：使用CAS将1修改为2，那么就需要携带预期值1，通过与现值比较看是否数据被并发修改过，相同则可以判定没有被并发修改，那么修改操作才可成功\n>\n>   实际上这种CAS策略有个ABA问题，也就是如果多个并发修改后结果不变，那么这种方式是无法感知到的\n>\n>   如：线程1：1 --> 2\n>\n>   线程2：2 --> 1\n>\n>   此时线程3无法感知到并发修改的存在，因为数据值与预期值（1）相同\n>\n>   解决这个问题的版本就是通过版本号来区分，每次修改都会递增版本号\n>\n>   这个数据版本就是根据CAS衍化而来的，携带的`version`参数作为CAS的预期值，可以通过这个`version`判断数据是否被并发修改了\n>\n>   使用这个功能可以实现分布式锁服务\n\n-   同步\n\n    ```java\n    /**\n     * @author Crayon\n     * @date 2022/6/15 11:36\n     * 同步更新数据\n     */\n    public class SyncSetDataTest {\n        @Test\n        public void test() throws IOException, InterruptedException, KeeperException {\n            ZooKeeper zooKeeper = SyncCreateNodeTest.getConnect();\n            zooKeeper.create(\"/crayon\", \"crayon\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);\n            zooKeeper.getData(\"/crayon\", false, null);\n            // -1不是一个特定的版本号，而是表示基于最新版本进行更新，对数据版本没有要求的情况可以使用\n            Stat stat = zooKeeper.setData(\"/crayon\", \"crayon-modifyed\".getBytes(), -1);\n            System.out.println(stat.getCzxid());\n            System.out.println(stat.getMzxid());\n            System.out.println(stat.getVersion());\n        }\n    }\n    \n    ```\n\n-   异步\n\n    ```java\n    /**\n     * @author Crayon\n     * @date 2022/6/15 11:36\n     * 异步更新数据\n     */\n    public class AsyncSetDataTest {\n        @Test\n        public void test() throws IOException, InterruptedException, KeeperException {\n            ZooKeeper zooKeeper = SyncCreateNodeTest.getConnect();\n            final CountDownLatch latch = new CountDownLatch(1);\n            zooKeeper.create(\"/crayon\", \"crayon\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);\n            zooKeeper.getData(\"/crayon\", false, null);\n            zooKeeper.setData(\"/crayon\", \"crayon-modifyed\".getBytes(), -1, new AsyncCallback.StatCallback() {\n                @Override\n                public void processResult(int rc, String path, Object ctx, Stat stat) {\n                    System.out.println(\"result code: \" + rc);\n                    System.out.println(\"path: \" + path);\n                    System.out.println(\"context: \" + ctx);\n                    System.out.println(stat.getCzxid());\n                    System.out.println(stat.getMzxid());\n                    System.out.println(stat.getVersion());\n                    latch.countDown();\n                }\n            }, null);\n            latch.await();\n        }\n    }\n    ```\n\n##### 检测节点是否存在\n\n\n\n##### 权限控制\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Paxos","Zookeeper","分布式"],"categories":["啃书"]}]